data_UL16_postVFPF:
  count: 311677.0
  cutFlowFourTag:
    all: 311677.0
    passFourTag: 7206.0
    passFourTag_btagSF: 0
    passHLT: 295861.0
    passJetMult: 287117.0
    passNoiseFilter: 311464.0
    pass_ttbar_filter: 6846.0
  cutFlowFourTagUnitWeight:
    all: 311677
    passFourTag: 7206
    passFourTag_btagSF: 0
    passHLT: 295861
    passJetMult: 287117
    passNoiseFilter: 311464
    pass_ttbar_filter: 6846
  cutFlowThreeTag:
    all: 311677.0
    passFourTag: 7206.0
    passFourTag_btagSF: 0
    passHLT: 295861.0
    passJetMult: 287117.0
    passNoiseFilter: 311464.0
    pass_ttbar_filter: 6846.0
  cutFlowThreeTagUnitWeight:
    all: 311677
    passFourTag: 7206
    passFourTag_btagSF: 0
    passHLT: 295861
    passJetMult: 287117
    passNoiseFilter: 311464
    pass_ttbar_filter: 6846
  files:
  - root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/data_UL16_postVFPF/picoAOD_seed0.root
  kFactor:
  - 1.0
  - 1.0
  - 1.0
  lumi:
  - 16500.0
  - 16500.0
  - 16500.0
  reproducible:
    args: Namespace(test=False, output_file='picoaod_datasets_declustered_data_Run2_seed0.yml',
      processor='skimmer/processor/make_declustered_data_4b.py', configs='skimmer/metadata/declustering_seed_0.yml',
      metadata='metadata/datasets_HH4b.yml', output_path='skimmer/metadata/', years=['UL17',
      'UL18', 'UL16_preVFP', 'UL16_postVFP'], datasets=['data'], era=['A', 'B', 'C',
      'D', 'E', 'F', 'G', 'H'], systematics=False, skimming=True, run_dask=False,
      condor=False, debug=False, githash='', gitdiff='')
    date: '2024-09-19 11:11:51'
    diff: 'b''diff --git a/.ci-workflows/synthetic-dataset-analyze-all.sh b/.ci-workflows/synthetic-dataset-analyze-all.sh\nindex
      40fa0ce..39596eb 100644\n--- a/.ci-workflows/synthetic-dataset-analyze-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-analyze-all.sh\n@@ -14,7 +14,9 @@ cd python/\n
      # fi\n # echo "############### Modifying dataset file with skimmer ci output"\n
      # cat metadata/datasets_ci.yml\n-python metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml
      -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml -o metadata/datasets_synthetic_seed0.yml\n+#python
      metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml
      -o metadata/datasets_synthetic_seed0.yml\n+\n+#python metadata/make_synthetic_yaml_datasets.py
      -m metadata/datasets_HH4b.yml -d skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed5.yml
      -o metadata/datasets_synthetic_seed0.yml\n \n # echo "############### Changing
      metadata"\n # sed -e "s/apply_FvT.*/apply_FvT: false/" -e "s/apply_trig.*/apply_trigWeight:
      false/" -e "s/run_SvB.*/run_SvB: false/"  analysis/metadata/HH4b.yml > analysis/metadata/tmp.yml\ndiff
      --git a/.ci-workflows/synthetic-dataset-make-dataset-all.sh b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\nindex
      37e4cd5..8b8f317 100644\n--- a/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n@@ -5,8 +5,13 @@ voms-proxy-info\n
      echo "############### Moving to python folder"\n cd python/\n echo "###############
      Running test processor"\n-time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering.yml -y UL17 UL18 UL16_preVFP UL16_postVFP -d
      data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed0.yml
      -m metadata/datasets_HH4b.yml   # --dask\n+\n+new_seed=0\n+\n+sed -e "s/declustering_rand_seed:
      [0-9]/declustering_rand_seed: $new_seed/" skimmer/metadata/declustering.yml
      > skimmer/metadata/declustering_seed_${new_seed}.yml\n+cat skimmer/metadata/declustering_seed_${new_seed}.yml\n+time
      python runner.py -s -p skimmer/processor/make_declustered_data_4b.py -c skimmer/metadata/declustering_seed_${new_seed}.yml
      -y UL17 UL18 UL16_preVFP UL16_postVFP -d data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed${new_seed}.yml
      -m metadata/datasets_HH4b.yml   # --dask\n # time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering_signal.yml -y UL17 UL18 UL16_preVFP UL16_postVFP
      -d GluGluToHHTo4B_cHHH1 -op skimmer/metadata/ -o picoaod_datasets_declustered_GluGluToHHTo4B_cHHH1_Run2_seed17.yml
      -m metadata/datasets_HH4b.yml\n \n-ls -R skimmer/\n+#ls -R skimmer/\n cd ../\ndiff
      --git a/python/analysis/metadata/HH4b_rerun_SvB.yml b/python/analysis/metadata/HH4b_rerun_SvB.yml\nindex
      7ea596b..8fbde86 100644\n--- a/python/analysis/metadata/HH4b_rerun_SvB.yml\n+++
      b/python/analysis/metadata/HH4b_rerun_SvB.yml\n@@ -6,7 +6,6 @@ config:\n   JCM:
      \''analysis/weights/JCM/2023/dataRunII/jetCombinatoricModel_SB_00-00-02.yml\''\n   blind:
      false\n   apply_FvT: false\n-  \n   apply_trigWeight: true\n   apply_btagSF:
      true\n   apply_boosted_veto: false\ndiff --git a/python/analysis/metadata/HH4b_synthetic_data.yml
      b/python/analysis/metadata/HH4b_synthetic_data.yml\nindex 0a930d7..8fbde86 100644\n---
      a/python/analysis/metadata/HH4b_synthetic_data.yml\n+++ b/python/analysis/metadata/HH4b_synthetic_data.yml\n@@
      -13,6 +13,6 @@ config:\n   run_systematics: false\n   SvB   : \''analysis/weights/pytorch_models/2024_HHUL/SvB_HCR_8_np753_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n   SvB_MA:
      \''analysis/weights/pytorch_models/2024_HHUL/SvB_MA_HCR+attention_8_np1061_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n-  top_reconstruction_override:
      "fast"\n-  isSyntheticData : True\n+  top_reconstruction_override: fast\n+\n   \ndiff
      --git a/python/analysis/processors/processor_HH4b.py b/python/analysis/processors/processor_HH4b.py\nindex
      a95e196..6201a25 100644\n--- a/python/analysis/processors/processor_HH4b.py\n+++
      b/python/analysis/processors/processor_HH4b.py\n@@ -60,7 +60,6 @@ class analysis(processor.ProcessorABC):\n         top_reconstruction_override:
      bool = False,\n         run_systematics: list = [],\n         make_classifier_input:
      str = None,\n-        isSyntheticData: bool = False,\n         subtract_ttbar_with_weights:
      bool = False,\n         friend_trigWeight: str = None,\n     ):\n@@ -84,7 +83,6
      @@ class analysis(processor.ProcessorABC):\n         self.make_classifier_input
      = make_classifier_input\n         self.top_reconstruction_override = top_reconstruction_override\n         self.subtract_ttbar_with_weights
      = subtract_ttbar_with_weights\n-        self.isSyntheticData = isSyntheticData\n         self.friend_trigWeight
      = friend_trigWeight\n \n         if self.friend_trigWeight:\n@@ -134,6 +132,11
      @@ class analysis(processor.ProcessorABC):\n         self.isMixedData    = not
      (self.dataset.find("mix_v") == -1)\n         if self.isMixedData:\n             self.isMC
      = False\n+\n+        self.isSyntheticData  = not (self.dataset.find("syn_v")
      == -1)\n+        if self.isSyntheticData:\n+            self.isMC = False\n+\n         self.isDataForMixed
      = not (self.dataset.find("data_3b_for_mixed") == -1)\n         self.isTTForMixed   =
      not (self.dataset.find("TTTo") == -1) and not ( self.dataset.find("_for_mixed")
      == -1 )\n \n@@ -189,8 +192,8 @@ class analysis(processor.ProcessorABC):\n             self.do_lepton_jet_cleaning  =
      False\n \n \n-        logging.debug(f\''{self.chunk} isData={False}, isMC={self.isMC},
      isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed}, isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData},
      isPSData={self.isPSData} for file {fname}\\n\'')\n-        logging.debug(f\''{self.chunk}
      isMC {self.isMC}, isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n+        logging.info(f\''{self.chunk}
      isData={False}, isMC={self.isMC}, isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed},
      isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData}, isPSData={self.isPSData}
      for file {fname}\\n\'')\n+        logging.info(f\''{self.chunk} isMC {self.isMC},
      isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n
      \n \n \ndiff --git a/python/metadata/datasets_HH4b.yml b/python/metadata/datasets_HH4b.yml\nindex
      bda9189..4707db1 100644\n--- a/python/metadata/datasets_HH4b.yml\n+++ b/python/metadata/datasets_HH4b.yml\n@@
      -720,3 +720,48 @@ datasets:\n         files_template:\n         - root://cmseos.fnal.gov//store/user/jda102/condor/ZH4b/ULTrig/mixed2018_3bDvTMix4bDvT_vXXX/picoAOD_3bDvTMix4bDvT_4b_wJCM_vXXX_newSBDef.root\n     nSamples:
      15\n+\n+\n+\n+  synthetic_data:\n+    nSamples: 1\n+    UL16_postVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPF/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_postVFP/picoAOD_PSData.root      \n+          -
      /srv/python/skimmer/test/data_UL16_postVFPG/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPH/picoAOD_seedXXX.root\n+    UL16_preVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPB/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPC/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPD/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPE/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_preVFP/picoAOD_PSData.root      \n+    UL17:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL17C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17D/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL17E/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17F/picoAOD_seedXXX.root      \n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL17/picoAOD_PSData.root      \n+    UL18:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL18A/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18B/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL18C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18D/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL18/picoAOD_PSData.root      \n+\ndiff
      --git a/python/runner.py b/python/runner.py\nindex f6a92fa..a4dc28c 100644\n---
      a/python/runner.py\n+++ b/python/runner.py\n@@ -163,6 +163,7 @@ if __name__
      == \''__main__\'':\n \n     if \''all\'' in args.datasets:\n         metadata[\''datasets\''].pop("mixeddata")   #
      AGE: this is temporary\n+        metadata[\''datasets\''].pop("synthetic_data")   #
      AGE: this is temporary\n         metadata[\''datasets\''].pop("data_3b_for_mixed")   #
      AGE: this is temporary\n         args.datasets = metadata[\''datasets\''].keys()\n
      \n@@ -181,7 +182,7 @@ if __name__ == \''__main__\'':\n                     f"{year}
      name not in metadatafile for {dataset}")\n                 continue\n \n-            if
      dataset in [\''data\'', \''mixeddata\'', \''data_3b_for_mixed\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n+            if dataset in [\''data\'',
      \''mixeddata\'', \''data_3b_for_mixed\'', \''synthetic_data\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n                 xsec = 1.\n             elif
      isinstance(metadata[\''datasets\''][dataset][\''xs\''], float):\n                 xsec
      = metadata[\''datasets\''][dataset][\''xs\'']\n@@ -203,10 +204,11 @@ if __name__
      == \''__main__\'':\n                                          }\n             isData
      = (dataset == \''data\'')\n             isMixedData = (dataset == \''mixeddata\'')\n+            isSyntheticData
      = (dataset == \''synthetic_data\'')\n             isDataForMix = (dataset ==
      \''data_3b_for_mixed\'')\n             isTTForMixed = (dataset in [\''TTToHadronic_for_mixed\'',
      \''TTToSemiLeptonic_for_mixed\'', \''TTTo2L2Nu_for_mixed\''])\n \n-            if
      not ( isData or isMixedData or isDataForMix or isTTForMixed):\n+            if
      not ( isData or isSyntheticData or isMixedData or isDataForMix or isTTForMixed):\n                 logging.info("\\nConfig
      MC")\n                 if config_runner[\''data_tier\''].startswith(\''pico\''):\n                     if
      \''data\'' not in dataset:\n@@ -249,6 +251,31 @@ if __name__ == \''__main__\'':\n                     logging.info(\n                         f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n \n+            elif
      isSyntheticData:\n+                logging.info("\\nConfig Synthetic Data ")\n+\n+                nSyntheticSamples
      = metadata[\''datasets\''][dataset]["nSamples"]\n+                synthetic_config
      = metadata[\''datasets\''][dataset][year][config_runner[\''data_tier\'']]\n+                logging.info(f"\\nNumber
      of synthetic samples is {nSyntheticSamples}")\n+                for v in range(nSyntheticSamples):\n+\n+                    synthetic_name
      = f"syn_v{v}"\n+                    idataset = f\''{synthetic_name}_{year}\''\n+\n+                    metadata_dataset[idataset]
      = copy(metadata_dataset[dataset])\n+                    metadata_dataset[idataset][\''processName\'']
      = synthetic_name\n+                    # metadata_dataset[idataset][\''FvT_name\'']
      = synthetic_config[\''FvT_name_template\''].replace("XXX",str(v))\n+                    #
      metadata_dataset[idataset][\''FvT_file\''] = synthetic_config[\''FvT_file_template\''].replace("XXX",str(v))\n+                    synthetic_files
      = [f.replace("XXX",str(v)) for f in synthetic_config[\''files_template\'']]\n+                    fileset[idataset]
      = {\''files\'': list_of_files(synthetic_files,\n+                                                                test=args.test,
      test_files=config_runner[\''test_files\''],\n+                                                                allowlist_sites=config_runner[\''allowlist_sites\'']),\n+                                         \''metadata\'':
      metadata_dataset[idataset]}\n+\n+                    logging.info(\n+                        f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n+\n+\n             elif
      isDataForMix:\n                 logging.info("\\nConfig Data for Mixed ")\n
      \n'''
    hash: be7beff9ac9b123dfb8bdeb2581a74ef06734cdb
  saved_events: 6846
  source:
    root://cmseos.fnal.gov//store/user/algomez/XX4b/20231115/data2016F/picoAOD.root:
    - !!python/tuple
      - 0
      - 103893
    - !!python/tuple
      - 103893
      - 207786
    - !!python/tuple
      - 207786
      - 311677
  total_events: 311677
  total_jet: 38864
  xs:
  - 1.0
  - 1.0
  - 1.0
data_UL16_postVFPG:
  count: 877903.0
  cutFlowFourTag:
    all: 877903.0
    passFourTag: 21394.0
    passFourTag_btagSF: 0
    passHLT: 840289.0
    passJetMult: 816919.0
    passNoiseFilter: 877397.0
    pass_ttbar_filter: 20379.0
  cutFlowFourTagUnitWeight:
    all: 877903
    passFourTag: 21394
    passFourTag_btagSF: 0
    passHLT: 840289
    passJetMult: 816919
    passNoiseFilter: 877397
    pass_ttbar_filter: 20379
  cutFlowThreeTag:
    all: 877903.0
    passFourTag: 21394.0
    passFourTag_btagSF: 0
    passHLT: 840289.0
    passJetMult: 816919.0
    passNoiseFilter: 877397.0
    pass_ttbar_filter: 20379.0
  cutFlowThreeTagUnitWeight:
    all: 877903
    passFourTag: 21394
    passFourTag_btagSF: 0
    passHLT: 840289
    passJetMult: 816919
    passNoiseFilter: 877397
    pass_ttbar_filter: 20379
  files:
  - root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/data_UL16_postVFPG/picoAOD_seed0.root
  kFactor:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  lumi:
  - 16500.0
  - 16500.0
  - 16500.0
  - 16500.0
  - 16500.0
  - 16500.0
  - 16500.0
  - 16500.0
  - 16500.0
  reproducible:
    args: Namespace(test=False, output_file='picoaod_datasets_declustered_data_Run2_seed0.yml',
      processor='skimmer/processor/make_declustered_data_4b.py', configs='skimmer/metadata/declustering_seed_0.yml',
      metadata='metadata/datasets_HH4b.yml', output_path='skimmer/metadata/', years=['UL17',
      'UL18', 'UL16_preVFP', 'UL16_postVFP'], datasets=['data'], era=['A', 'B', 'C',
      'D', 'E', 'F', 'G', 'H'], systematics=False, skimming=True, run_dask=False,
      condor=False, debug=False, githash='', gitdiff='')
    date: '2024-09-19 11:11:52'
    diff: 'b''diff --git a/.ci-workflows/synthetic-dataset-analyze-all.sh b/.ci-workflows/synthetic-dataset-analyze-all.sh\nindex
      40fa0ce..39596eb 100644\n--- a/.ci-workflows/synthetic-dataset-analyze-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-analyze-all.sh\n@@ -14,7 +14,9 @@ cd python/\n
      # fi\n # echo "############### Modifying dataset file with skimmer ci output"\n
      # cat metadata/datasets_ci.yml\n-python metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml
      -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml -o metadata/datasets_synthetic_seed0.yml\n+#python
      metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml
      -o metadata/datasets_synthetic_seed0.yml\n+\n+#python metadata/make_synthetic_yaml_datasets.py
      -m metadata/datasets_HH4b.yml -d skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed5.yml
      -o metadata/datasets_synthetic_seed0.yml\n \n # echo "############### Changing
      metadata"\n # sed -e "s/apply_FvT.*/apply_FvT: false/" -e "s/apply_trig.*/apply_trigWeight:
      false/" -e "s/run_SvB.*/run_SvB: false/"  analysis/metadata/HH4b.yml > analysis/metadata/tmp.yml\ndiff
      --git a/.ci-workflows/synthetic-dataset-make-dataset-all.sh b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\nindex
      37e4cd5..8b8f317 100644\n--- a/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n@@ -5,8 +5,13 @@ voms-proxy-info\n
      echo "############### Moving to python folder"\n cd python/\n echo "###############
      Running test processor"\n-time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering.yml -y UL17 UL18 UL16_preVFP UL16_postVFP -d
      data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed0.yml
      -m metadata/datasets_HH4b.yml   # --dask\n+\n+new_seed=0\n+\n+sed -e "s/declustering_rand_seed:
      [0-9]/declustering_rand_seed: $new_seed/" skimmer/metadata/declustering.yml
      > skimmer/metadata/declustering_seed_${new_seed}.yml\n+cat skimmer/metadata/declustering_seed_${new_seed}.yml\n+time
      python runner.py -s -p skimmer/processor/make_declustered_data_4b.py -c skimmer/metadata/declustering_seed_${new_seed}.yml
      -y UL17 UL18 UL16_preVFP UL16_postVFP -d data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed${new_seed}.yml
      -m metadata/datasets_HH4b.yml   # --dask\n # time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering_signal.yml -y UL17 UL18 UL16_preVFP UL16_postVFP
      -d GluGluToHHTo4B_cHHH1 -op skimmer/metadata/ -o picoaod_datasets_declustered_GluGluToHHTo4B_cHHH1_Run2_seed17.yml
      -m metadata/datasets_HH4b.yml\n \n-ls -R skimmer/\n+#ls -R skimmer/\n cd ../\ndiff
      --git a/python/analysis/metadata/HH4b_rerun_SvB.yml b/python/analysis/metadata/HH4b_rerun_SvB.yml\nindex
      7ea596b..8fbde86 100644\n--- a/python/analysis/metadata/HH4b_rerun_SvB.yml\n+++
      b/python/analysis/metadata/HH4b_rerun_SvB.yml\n@@ -6,7 +6,6 @@ config:\n   JCM:
      \''analysis/weights/JCM/2023/dataRunII/jetCombinatoricModel_SB_00-00-02.yml\''\n   blind:
      false\n   apply_FvT: false\n-  \n   apply_trigWeight: true\n   apply_btagSF:
      true\n   apply_boosted_veto: false\ndiff --git a/python/analysis/metadata/HH4b_synthetic_data.yml
      b/python/analysis/metadata/HH4b_synthetic_data.yml\nindex 0a930d7..8fbde86 100644\n---
      a/python/analysis/metadata/HH4b_synthetic_data.yml\n+++ b/python/analysis/metadata/HH4b_synthetic_data.yml\n@@
      -13,6 +13,6 @@ config:\n   run_systematics: false\n   SvB   : \''analysis/weights/pytorch_models/2024_HHUL/SvB_HCR_8_np753_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n   SvB_MA:
      \''analysis/weights/pytorch_models/2024_HHUL/SvB_MA_HCR+attention_8_np1061_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n-  top_reconstruction_override:
      "fast"\n-  isSyntheticData : True\n+  top_reconstruction_override: fast\n+\n   \ndiff
      --git a/python/analysis/processors/processor_HH4b.py b/python/analysis/processors/processor_HH4b.py\nindex
      a95e196..6201a25 100644\n--- a/python/analysis/processors/processor_HH4b.py\n+++
      b/python/analysis/processors/processor_HH4b.py\n@@ -60,7 +60,6 @@ class analysis(processor.ProcessorABC):\n         top_reconstruction_override:
      bool = False,\n         run_systematics: list = [],\n         make_classifier_input:
      str = None,\n-        isSyntheticData: bool = False,\n         subtract_ttbar_with_weights:
      bool = False,\n         friend_trigWeight: str = None,\n     ):\n@@ -84,7 +83,6
      @@ class analysis(processor.ProcessorABC):\n         self.make_classifier_input
      = make_classifier_input\n         self.top_reconstruction_override = top_reconstruction_override\n         self.subtract_ttbar_with_weights
      = subtract_ttbar_with_weights\n-        self.isSyntheticData = isSyntheticData\n         self.friend_trigWeight
      = friend_trigWeight\n \n         if self.friend_trigWeight:\n@@ -134,6 +132,11
      @@ class analysis(processor.ProcessorABC):\n         self.isMixedData    = not
      (self.dataset.find("mix_v") == -1)\n         if self.isMixedData:\n             self.isMC
      = False\n+\n+        self.isSyntheticData  = not (self.dataset.find("syn_v")
      == -1)\n+        if self.isSyntheticData:\n+            self.isMC = False\n+\n         self.isDataForMixed
      = not (self.dataset.find("data_3b_for_mixed") == -1)\n         self.isTTForMixed   =
      not (self.dataset.find("TTTo") == -1) and not ( self.dataset.find("_for_mixed")
      == -1 )\n \n@@ -189,8 +192,8 @@ class analysis(processor.ProcessorABC):\n             self.do_lepton_jet_cleaning  =
      False\n \n \n-        logging.debug(f\''{self.chunk} isData={False}, isMC={self.isMC},
      isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed}, isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData},
      isPSData={self.isPSData} for file {fname}\\n\'')\n-        logging.debug(f\''{self.chunk}
      isMC {self.isMC}, isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n+        logging.info(f\''{self.chunk}
      isData={False}, isMC={self.isMC}, isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed},
      isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData}, isPSData={self.isPSData}
      for file {fname}\\n\'')\n+        logging.info(f\''{self.chunk} isMC {self.isMC},
      isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n
      \n \n \ndiff --git a/python/metadata/datasets_HH4b.yml b/python/metadata/datasets_HH4b.yml\nindex
      bda9189..4707db1 100644\n--- a/python/metadata/datasets_HH4b.yml\n+++ b/python/metadata/datasets_HH4b.yml\n@@
      -720,3 +720,48 @@ datasets:\n         files_template:\n         - root://cmseos.fnal.gov//store/user/jda102/condor/ZH4b/ULTrig/mixed2018_3bDvTMix4bDvT_vXXX/picoAOD_3bDvTMix4bDvT_4b_wJCM_vXXX_newSBDef.root\n     nSamples:
      15\n+\n+\n+\n+  synthetic_data:\n+    nSamples: 1\n+    UL16_postVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPF/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_postVFP/picoAOD_PSData.root      \n+          -
      /srv/python/skimmer/test/data_UL16_postVFPG/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPH/picoAOD_seedXXX.root\n+    UL16_preVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPB/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPC/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPD/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPE/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_preVFP/picoAOD_PSData.root      \n+    UL17:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL17C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17D/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL17E/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17F/picoAOD_seedXXX.root      \n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL17/picoAOD_PSData.root      \n+    UL18:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL18A/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18B/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL18C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18D/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL18/picoAOD_PSData.root      \n+\ndiff
      --git a/python/runner.py b/python/runner.py\nindex f6a92fa..a4dc28c 100644\n---
      a/python/runner.py\n+++ b/python/runner.py\n@@ -163,6 +163,7 @@ if __name__
      == \''__main__\'':\n \n     if \''all\'' in args.datasets:\n         metadata[\''datasets\''].pop("mixeddata")   #
      AGE: this is temporary\n+        metadata[\''datasets\''].pop("synthetic_data")   #
      AGE: this is temporary\n         metadata[\''datasets\''].pop("data_3b_for_mixed")   #
      AGE: this is temporary\n         args.datasets = metadata[\''datasets\''].keys()\n
      \n@@ -181,7 +182,7 @@ if __name__ == \''__main__\'':\n                     f"{year}
      name not in metadatafile for {dataset}")\n                 continue\n \n-            if
      dataset in [\''data\'', \''mixeddata\'', \''data_3b_for_mixed\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n+            if dataset in [\''data\'',
      \''mixeddata\'', \''data_3b_for_mixed\'', \''synthetic_data\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n                 xsec = 1.\n             elif
      isinstance(metadata[\''datasets\''][dataset][\''xs\''], float):\n                 xsec
      = metadata[\''datasets\''][dataset][\''xs\'']\n@@ -203,10 +204,11 @@ if __name__
      == \''__main__\'':\n                                          }\n             isData
      = (dataset == \''data\'')\n             isMixedData = (dataset == \''mixeddata\'')\n+            isSyntheticData
      = (dataset == \''synthetic_data\'')\n             isDataForMix = (dataset ==
      \''data_3b_for_mixed\'')\n             isTTForMixed = (dataset in [\''TTToHadronic_for_mixed\'',
      \''TTToSemiLeptonic_for_mixed\'', \''TTTo2L2Nu_for_mixed\''])\n \n-            if
      not ( isData or isMixedData or isDataForMix or isTTForMixed):\n+            if
      not ( isData or isSyntheticData or isMixedData or isDataForMix or isTTForMixed):\n                 logging.info("\\nConfig
      MC")\n                 if config_runner[\''data_tier\''].startswith(\''pico\''):\n                     if
      \''data\'' not in dataset:\n@@ -249,6 +251,31 @@ if __name__ == \''__main__\'':\n                     logging.info(\n                         f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n \n+            elif
      isSyntheticData:\n+                logging.info("\\nConfig Synthetic Data ")\n+\n+                nSyntheticSamples
      = metadata[\''datasets\''][dataset]["nSamples"]\n+                synthetic_config
      = metadata[\''datasets\''][dataset][year][config_runner[\''data_tier\'']]\n+                logging.info(f"\\nNumber
      of synthetic samples is {nSyntheticSamples}")\n+                for v in range(nSyntheticSamples):\n+\n+                    synthetic_name
      = f"syn_v{v}"\n+                    idataset = f\''{synthetic_name}_{year}\''\n+\n+                    metadata_dataset[idataset]
      = copy(metadata_dataset[dataset])\n+                    metadata_dataset[idataset][\''processName\'']
      = synthetic_name\n+                    # metadata_dataset[idataset][\''FvT_name\'']
      = synthetic_config[\''FvT_name_template\''].replace("XXX",str(v))\n+                    #
      metadata_dataset[idataset][\''FvT_file\''] = synthetic_config[\''FvT_file_template\''].replace("XXX",str(v))\n+                    synthetic_files
      = [f.replace("XXX",str(v)) for f in synthetic_config[\''files_template\'']]\n+                    fileset[idataset]
      = {\''files\'': list_of_files(synthetic_files,\n+                                                                test=args.test,
      test_files=config_runner[\''test_files\''],\n+                                                                allowlist_sites=config_runner[\''allowlist_sites\'']),\n+                                         \''metadata\'':
      metadata_dataset[idataset]}\n+\n+                    logging.info(\n+                        f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n+\n+\n             elif
      isDataForMix:\n                 logging.info("\\nConfig Data for Mixed ")\n
      \n'''
    hash: be7beff9ac9b123dfb8bdeb2581a74ef06734cdb
  saved_events: 20379
  source:
    root://cmseos.fnal.gov//store/user/algomez/XX4b/20231115/data2016G/picoAOD.root:
    - !!python/tuple
      - 0
      - 97545
    - !!python/tuple
      - 195090
      - 292635
    - !!python/tuple
      - 97545
      - 195090
    - !!python/tuple
      - 487725
      - 585270
    - !!python/tuple
      - 390180
      - 487725
    - !!python/tuple
      - 585270
      - 682815
    - !!python/tuple
      - 292635
      - 390180
    - !!python/tuple
      - 682815
      - 780360
    - !!python/tuple
      - 780360
      - 877903
  total_events: 877903
  total_jet: 114771
  xs:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
data_UL16_postVFPH:
  count: 903644.0
  cutFlowFourTag:
    all: 903644.0
    passFourTag: 22796.0
    passFourTag_btagSF: 0
    passHLT: 857335.0
    passJetMult: 832204.0
    passNoiseFilter: 903116.0
    pass_ttbar_filter: 21684.0
  cutFlowFourTagUnitWeight:
    all: 903644
    passFourTag: 22796
    passFourTag_btagSF: 0
    passHLT: 857335
    passJetMult: 832204
    passNoiseFilter: 903116
    pass_ttbar_filter: 21684
  cutFlowThreeTag:
    all: 903644.0
    passFourTag: 22796.0
    passFourTag_btagSF: 0
    passHLT: 857335.0
    passJetMult: 832204.0
    passNoiseFilter: 903116.0
    pass_ttbar_filter: 21684.0
  cutFlowThreeTagUnitWeight:
    all: 903644
    passFourTag: 22796
    passFourTag_btagSF: 0
    passHLT: 857335
    passJetMult: 832204
    passNoiseFilter: 903116
    pass_ttbar_filter: 21684
  files:
  - root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/data_UL16_postVFPH/picoAOD_seed0.root
  kFactor:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  lumi:
  - 16500.0
  - 16500.0
  - 16500.0
  - 16500.0
  - 16500.0
  - 16500.0
  - 16500.0
  - 16500.0
  - 16500.0
  missing: {}
  reproducible:
    args: Namespace(test=False, output_file='picoaod_datasets_declustered_data_Run2_seed0.yml',
      processor='skimmer/processor/make_declustered_data_4b.py', configs='skimmer/metadata/declustering_seed_0.yml',
      metadata='metadata/datasets_HH4b.yml', output_path='skimmer/metadata/', years=['UL17',
      'UL18', 'UL16_preVFP', 'UL16_postVFP'], datasets=['data'], era=['A', 'B', 'C',
      'D', 'E', 'F', 'G', 'H'], systematics=False, skimming=True, run_dask=False,
      condor=False, debug=False, githash='', gitdiff='')
    date: '2024-09-19 11:11:52'
    diff: 'b''diff --git a/.ci-workflows/synthetic-dataset-analyze-all.sh b/.ci-workflows/synthetic-dataset-analyze-all.sh\nindex
      40fa0ce..39596eb 100644\n--- a/.ci-workflows/synthetic-dataset-analyze-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-analyze-all.sh\n@@ -14,7 +14,9 @@ cd python/\n
      # fi\n # echo "############### Modifying dataset file with skimmer ci output"\n
      # cat metadata/datasets_ci.yml\n-python metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml
      -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml -o metadata/datasets_synthetic_seed0.yml\n+#python
      metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml
      -o metadata/datasets_synthetic_seed0.yml\n+\n+#python metadata/make_synthetic_yaml_datasets.py
      -m metadata/datasets_HH4b.yml -d skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed5.yml
      -o metadata/datasets_synthetic_seed0.yml\n \n # echo "############### Changing
      metadata"\n # sed -e "s/apply_FvT.*/apply_FvT: false/" -e "s/apply_trig.*/apply_trigWeight:
      false/" -e "s/run_SvB.*/run_SvB: false/"  analysis/metadata/HH4b.yml > analysis/metadata/tmp.yml\ndiff
      --git a/.ci-workflows/synthetic-dataset-make-dataset-all.sh b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\nindex
      37e4cd5..8b8f317 100644\n--- a/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n@@ -5,8 +5,13 @@ voms-proxy-info\n
      echo "############### Moving to python folder"\n cd python/\n echo "###############
      Running test processor"\n-time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering.yml -y UL17 UL18 UL16_preVFP UL16_postVFP -d
      data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed0.yml
      -m metadata/datasets_HH4b.yml   # --dask\n+\n+new_seed=0\n+\n+sed -e "s/declustering_rand_seed:
      [0-9]/declustering_rand_seed: $new_seed/" skimmer/metadata/declustering.yml
      > skimmer/metadata/declustering_seed_${new_seed}.yml\n+cat skimmer/metadata/declustering_seed_${new_seed}.yml\n+time
      python runner.py -s -p skimmer/processor/make_declustered_data_4b.py -c skimmer/metadata/declustering_seed_${new_seed}.yml
      -y UL17 UL18 UL16_preVFP UL16_postVFP -d data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed${new_seed}.yml
      -m metadata/datasets_HH4b.yml   # --dask\n # time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering_signal.yml -y UL17 UL18 UL16_preVFP UL16_postVFP
      -d GluGluToHHTo4B_cHHH1 -op skimmer/metadata/ -o picoaod_datasets_declustered_GluGluToHHTo4B_cHHH1_Run2_seed17.yml
      -m metadata/datasets_HH4b.yml\n \n-ls -R skimmer/\n+#ls -R skimmer/\n cd ../\ndiff
      --git a/python/analysis/metadata/HH4b_rerun_SvB.yml b/python/analysis/metadata/HH4b_rerun_SvB.yml\nindex
      7ea596b..8fbde86 100644\n--- a/python/analysis/metadata/HH4b_rerun_SvB.yml\n+++
      b/python/analysis/metadata/HH4b_rerun_SvB.yml\n@@ -6,7 +6,6 @@ config:\n   JCM:
      \''analysis/weights/JCM/2023/dataRunII/jetCombinatoricModel_SB_00-00-02.yml\''\n   blind:
      false\n   apply_FvT: false\n-  \n   apply_trigWeight: true\n   apply_btagSF:
      true\n   apply_boosted_veto: false\ndiff --git a/python/analysis/metadata/HH4b_synthetic_data.yml
      b/python/analysis/metadata/HH4b_synthetic_data.yml\nindex 0a930d7..8fbde86 100644\n---
      a/python/analysis/metadata/HH4b_synthetic_data.yml\n+++ b/python/analysis/metadata/HH4b_synthetic_data.yml\n@@
      -13,6 +13,6 @@ config:\n   run_systematics: false\n   SvB   : \''analysis/weights/pytorch_models/2024_HHUL/SvB_HCR_8_np753_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n   SvB_MA:
      \''analysis/weights/pytorch_models/2024_HHUL/SvB_MA_HCR+attention_8_np1061_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n-  top_reconstruction_override:
      "fast"\n-  isSyntheticData : True\n+  top_reconstruction_override: fast\n+\n   \ndiff
      --git a/python/analysis/processors/processor_HH4b.py b/python/analysis/processors/processor_HH4b.py\nindex
      a95e196..6201a25 100644\n--- a/python/analysis/processors/processor_HH4b.py\n+++
      b/python/analysis/processors/processor_HH4b.py\n@@ -60,7 +60,6 @@ class analysis(processor.ProcessorABC):\n         top_reconstruction_override:
      bool = False,\n         run_systematics: list = [],\n         make_classifier_input:
      str = None,\n-        isSyntheticData: bool = False,\n         subtract_ttbar_with_weights:
      bool = False,\n         friend_trigWeight: str = None,\n     ):\n@@ -84,7 +83,6
      @@ class analysis(processor.ProcessorABC):\n         self.make_classifier_input
      = make_classifier_input\n         self.top_reconstruction_override = top_reconstruction_override\n         self.subtract_ttbar_with_weights
      = subtract_ttbar_with_weights\n-        self.isSyntheticData = isSyntheticData\n         self.friend_trigWeight
      = friend_trigWeight\n \n         if self.friend_trigWeight:\n@@ -134,6 +132,11
      @@ class analysis(processor.ProcessorABC):\n         self.isMixedData    = not
      (self.dataset.find("mix_v") == -1)\n         if self.isMixedData:\n             self.isMC
      = False\n+\n+        self.isSyntheticData  = not (self.dataset.find("syn_v")
      == -1)\n+        if self.isSyntheticData:\n+            self.isMC = False\n+\n         self.isDataForMixed
      = not (self.dataset.find("data_3b_for_mixed") == -1)\n         self.isTTForMixed   =
      not (self.dataset.find("TTTo") == -1) and not ( self.dataset.find("_for_mixed")
      == -1 )\n \n@@ -189,8 +192,8 @@ class analysis(processor.ProcessorABC):\n             self.do_lepton_jet_cleaning  =
      False\n \n \n-        logging.debug(f\''{self.chunk} isData={False}, isMC={self.isMC},
      isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed}, isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData},
      isPSData={self.isPSData} for file {fname}\\n\'')\n-        logging.debug(f\''{self.chunk}
      isMC {self.isMC}, isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n+        logging.info(f\''{self.chunk}
      isData={False}, isMC={self.isMC}, isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed},
      isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData}, isPSData={self.isPSData}
      for file {fname}\\n\'')\n+        logging.info(f\''{self.chunk} isMC {self.isMC},
      isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n
      \n \n \ndiff --git a/python/metadata/datasets_HH4b.yml b/python/metadata/datasets_HH4b.yml\nindex
      bda9189..4707db1 100644\n--- a/python/metadata/datasets_HH4b.yml\n+++ b/python/metadata/datasets_HH4b.yml\n@@
      -720,3 +720,48 @@ datasets:\n         files_template:\n         - root://cmseos.fnal.gov//store/user/jda102/condor/ZH4b/ULTrig/mixed2018_3bDvTMix4bDvT_vXXX/picoAOD_3bDvTMix4bDvT_4b_wJCM_vXXX_newSBDef.root\n     nSamples:
      15\n+\n+\n+\n+  synthetic_data:\n+    nSamples: 1\n+    UL16_postVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPF/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_postVFP/picoAOD_PSData.root      \n+          -
      /srv/python/skimmer/test/data_UL16_postVFPG/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPH/picoAOD_seedXXX.root\n+    UL16_preVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPB/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPC/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPD/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPE/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_preVFP/picoAOD_PSData.root      \n+    UL17:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL17C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17D/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL17E/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17F/picoAOD_seedXXX.root      \n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL17/picoAOD_PSData.root      \n+    UL18:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL18A/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18B/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL18C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18D/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL18/picoAOD_PSData.root      \n+\ndiff
      --git a/python/runner.py b/python/runner.py\nindex f6a92fa..a4dc28c 100644\n---
      a/python/runner.py\n+++ b/python/runner.py\n@@ -163,6 +163,7 @@ if __name__
      == \''__main__\'':\n \n     if \''all\'' in args.datasets:\n         metadata[\''datasets\''].pop("mixeddata")   #
      AGE: this is temporary\n+        metadata[\''datasets\''].pop("synthetic_data")   #
      AGE: this is temporary\n         metadata[\''datasets\''].pop("data_3b_for_mixed")   #
      AGE: this is temporary\n         args.datasets = metadata[\''datasets\''].keys()\n
      \n@@ -181,7 +182,7 @@ if __name__ == \''__main__\'':\n                     f"{year}
      name not in metadatafile for {dataset}")\n                 continue\n \n-            if
      dataset in [\''data\'', \''mixeddata\'', \''data_3b_for_mixed\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n+            if dataset in [\''data\'',
      \''mixeddata\'', \''data_3b_for_mixed\'', \''synthetic_data\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n                 xsec = 1.\n             elif
      isinstance(metadata[\''datasets\''][dataset][\''xs\''], float):\n                 xsec
      = metadata[\''datasets\''][dataset][\''xs\'']\n@@ -203,10 +204,11 @@ if __name__
      == \''__main__\'':\n                                          }\n             isData
      = (dataset == \''data\'')\n             isMixedData = (dataset == \''mixeddata\'')\n+            isSyntheticData
      = (dataset == \''synthetic_data\'')\n             isDataForMix = (dataset ==
      \''data_3b_for_mixed\'')\n             isTTForMixed = (dataset in [\''TTToHadronic_for_mixed\'',
      \''TTToSemiLeptonic_for_mixed\'', \''TTTo2L2Nu_for_mixed\''])\n \n-            if
      not ( isData or isMixedData or isDataForMix or isTTForMixed):\n+            if
      not ( isData or isSyntheticData or isMixedData or isDataForMix or isTTForMixed):\n                 logging.info("\\nConfig
      MC")\n                 if config_runner[\''data_tier\''].startswith(\''pico\''):\n                     if
      \''data\'' not in dataset:\n@@ -249,6 +251,31 @@ if __name__ == \''__main__\'':\n                     logging.info(\n                         f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n \n+            elif
      isSyntheticData:\n+                logging.info("\\nConfig Synthetic Data ")\n+\n+                nSyntheticSamples
      = metadata[\''datasets\''][dataset]["nSamples"]\n+                synthetic_config
      = metadata[\''datasets\''][dataset][year][config_runner[\''data_tier\'']]\n+                logging.info(f"\\nNumber
      of synthetic samples is {nSyntheticSamples}")\n+                for v in range(nSyntheticSamples):\n+\n+                    synthetic_name
      = f"syn_v{v}"\n+                    idataset = f\''{synthetic_name}_{year}\''\n+\n+                    metadata_dataset[idataset]
      = copy(metadata_dataset[dataset])\n+                    metadata_dataset[idataset][\''processName\'']
      = synthetic_name\n+                    # metadata_dataset[idataset][\''FvT_name\'']
      = synthetic_config[\''FvT_name_template\''].replace("XXX",str(v))\n+                    #
      metadata_dataset[idataset][\''FvT_file\''] = synthetic_config[\''FvT_file_template\''].replace("XXX",str(v))\n+                    synthetic_files
      = [f.replace("XXX",str(v)) for f in synthetic_config[\''files_template\'']]\n+                    fileset[idataset]
      = {\''files\'': list_of_files(synthetic_files,\n+                                                                test=args.test,
      test_files=config_runner[\''test_files\''],\n+                                                                allowlist_sites=config_runner[\''allowlist_sites\'']),\n+                                         \''metadata\'':
      metadata_dataset[idataset]}\n+\n+                    logging.info(\n+                        f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n+\n+\n             elif
      isDataForMix:\n                 logging.info("\\nConfig Data for Mixed ")\n
      \n'''
    hash: be7beff9ac9b123dfb8bdeb2581a74ef06734cdb
  saved_events: 21684
  total_events: 903644
  total_jet: 122135
  xs:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
data_UL16_preVFPB:
  count: 598690.0
  cutFlowFourTag:
    all: 598690.0
    passFourTag: 16868.0
    passFourTag_btagSF: 0
    passHLT: 562903.0
    passJetMult: 549716.0
    passNoiseFilter: 598320.0
    pass_ttbar_filter: 15904.0
  cutFlowFourTagUnitWeight:
    all: 598690
    passFourTag: 16868
    passFourTag_btagSF: 0
    passHLT: 562903
    passJetMult: 549716
    passNoiseFilter: 598320
    pass_ttbar_filter: 15904
  cutFlowThreeTag:
    all: 598690.0
    passFourTag: 16868.0
    passFourTag_btagSF: 0
    passHLT: 562903.0
    passJetMult: 549716.0
    passNoiseFilter: 598320.0
    pass_ttbar_filter: 15904.0
  cutFlowThreeTagUnitWeight:
    all: 598690
    passFourTag: 16868
    passFourTag_btagSF: 0
    passHLT: 562903
    passJetMult: 549716
    passNoiseFilter: 598320
    pass_ttbar_filter: 15904
  files:
  - root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/data_UL16_preVFPB/picoAOD_seed0.root
  kFactor:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  lumi:
  - 19500.0
  - 19500.0
  - 19500.0
  - 19500.0
  - 19500.0
  - 19500.0
  reproducible:
    args: Namespace(test=False, output_file='picoaod_datasets_declustered_data_Run2_seed0.yml',
      processor='skimmer/processor/make_declustered_data_4b.py', configs='skimmer/metadata/declustering_seed_0.yml',
      metadata='metadata/datasets_HH4b.yml', output_path='skimmer/metadata/', years=['UL17',
      'UL18', 'UL16_preVFP', 'UL16_postVFP'], datasets=['data'], era=['A', 'B', 'C',
      'D', 'E', 'F', 'G', 'H'], systematics=False, skimming=True, run_dask=False,
      condor=False, debug=False, githash='', gitdiff='')
    date: '2024-09-19 11:11:51'
    diff: 'b''diff --git a/.ci-workflows/synthetic-dataset-analyze-all.sh b/.ci-workflows/synthetic-dataset-analyze-all.sh\nindex
      40fa0ce..39596eb 100644\n--- a/.ci-workflows/synthetic-dataset-analyze-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-analyze-all.sh\n@@ -14,7 +14,9 @@ cd python/\n
      # fi\n # echo "############### Modifying dataset file with skimmer ci output"\n
      # cat metadata/datasets_ci.yml\n-python metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml
      -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml -o metadata/datasets_synthetic_seed0.yml\n+#python
      metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml
      -o metadata/datasets_synthetic_seed0.yml\n+\n+#python metadata/make_synthetic_yaml_datasets.py
      -m metadata/datasets_HH4b.yml -d skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed5.yml
      -o metadata/datasets_synthetic_seed0.yml\n \n # echo "############### Changing
      metadata"\n # sed -e "s/apply_FvT.*/apply_FvT: false/" -e "s/apply_trig.*/apply_trigWeight:
      false/" -e "s/run_SvB.*/run_SvB: false/"  analysis/metadata/HH4b.yml > analysis/metadata/tmp.yml\ndiff
      --git a/.ci-workflows/synthetic-dataset-make-dataset-all.sh b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\nindex
      37e4cd5..8b8f317 100644\n--- a/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n@@ -5,8 +5,13 @@ voms-proxy-info\n
      echo "############### Moving to python folder"\n cd python/\n echo "###############
      Running test processor"\n-time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering.yml -y UL17 UL18 UL16_preVFP UL16_postVFP -d
      data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed0.yml
      -m metadata/datasets_HH4b.yml   # --dask\n+\n+new_seed=0\n+\n+sed -e "s/declustering_rand_seed:
      [0-9]/declustering_rand_seed: $new_seed/" skimmer/metadata/declustering.yml
      > skimmer/metadata/declustering_seed_${new_seed}.yml\n+cat skimmer/metadata/declustering_seed_${new_seed}.yml\n+time
      python runner.py -s -p skimmer/processor/make_declustered_data_4b.py -c skimmer/metadata/declustering_seed_${new_seed}.yml
      -y UL17 UL18 UL16_preVFP UL16_postVFP -d data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed${new_seed}.yml
      -m metadata/datasets_HH4b.yml   # --dask\n # time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering_signal.yml -y UL17 UL18 UL16_preVFP UL16_postVFP
      -d GluGluToHHTo4B_cHHH1 -op skimmer/metadata/ -o picoaod_datasets_declustered_GluGluToHHTo4B_cHHH1_Run2_seed17.yml
      -m metadata/datasets_HH4b.yml\n \n-ls -R skimmer/\n+#ls -R skimmer/\n cd ../\ndiff
      --git a/python/analysis/metadata/HH4b_rerun_SvB.yml b/python/analysis/metadata/HH4b_rerun_SvB.yml\nindex
      7ea596b..8fbde86 100644\n--- a/python/analysis/metadata/HH4b_rerun_SvB.yml\n+++
      b/python/analysis/metadata/HH4b_rerun_SvB.yml\n@@ -6,7 +6,6 @@ config:\n   JCM:
      \''analysis/weights/JCM/2023/dataRunII/jetCombinatoricModel_SB_00-00-02.yml\''\n   blind:
      false\n   apply_FvT: false\n-  \n   apply_trigWeight: true\n   apply_btagSF:
      true\n   apply_boosted_veto: false\ndiff --git a/python/analysis/metadata/HH4b_synthetic_data.yml
      b/python/analysis/metadata/HH4b_synthetic_data.yml\nindex 0a930d7..8fbde86 100644\n---
      a/python/analysis/metadata/HH4b_synthetic_data.yml\n+++ b/python/analysis/metadata/HH4b_synthetic_data.yml\n@@
      -13,6 +13,6 @@ config:\n   run_systematics: false\n   SvB   : \''analysis/weights/pytorch_models/2024_HHUL/SvB_HCR_8_np753_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n   SvB_MA:
      \''analysis/weights/pytorch_models/2024_HHUL/SvB_MA_HCR+attention_8_np1061_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n-  top_reconstruction_override:
      "fast"\n-  isSyntheticData : True\n+  top_reconstruction_override: fast\n+\n   \ndiff
      --git a/python/analysis/processors/processor_HH4b.py b/python/analysis/processors/processor_HH4b.py\nindex
      a95e196..6201a25 100644\n--- a/python/analysis/processors/processor_HH4b.py\n+++
      b/python/analysis/processors/processor_HH4b.py\n@@ -60,7 +60,6 @@ class analysis(processor.ProcessorABC):\n         top_reconstruction_override:
      bool = False,\n         run_systematics: list = [],\n         make_classifier_input:
      str = None,\n-        isSyntheticData: bool = False,\n         subtract_ttbar_with_weights:
      bool = False,\n         friend_trigWeight: str = None,\n     ):\n@@ -84,7 +83,6
      @@ class analysis(processor.ProcessorABC):\n         self.make_classifier_input
      = make_classifier_input\n         self.top_reconstruction_override = top_reconstruction_override\n         self.subtract_ttbar_with_weights
      = subtract_ttbar_with_weights\n-        self.isSyntheticData = isSyntheticData\n         self.friend_trigWeight
      = friend_trigWeight\n \n         if self.friend_trigWeight:\n@@ -134,6 +132,11
      @@ class analysis(processor.ProcessorABC):\n         self.isMixedData    = not
      (self.dataset.find("mix_v") == -1)\n         if self.isMixedData:\n             self.isMC
      = False\n+\n+        self.isSyntheticData  = not (self.dataset.find("syn_v")
      == -1)\n+        if self.isSyntheticData:\n+            self.isMC = False\n+\n         self.isDataForMixed
      = not (self.dataset.find("data_3b_for_mixed") == -1)\n         self.isTTForMixed   =
      not (self.dataset.find("TTTo") == -1) and not ( self.dataset.find("_for_mixed")
      == -1 )\n \n@@ -189,8 +192,8 @@ class analysis(processor.ProcessorABC):\n             self.do_lepton_jet_cleaning  =
      False\n \n \n-        logging.debug(f\''{self.chunk} isData={False}, isMC={self.isMC},
      isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed}, isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData},
      isPSData={self.isPSData} for file {fname}\\n\'')\n-        logging.debug(f\''{self.chunk}
      isMC {self.isMC}, isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n+        logging.info(f\''{self.chunk}
      isData={False}, isMC={self.isMC}, isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed},
      isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData}, isPSData={self.isPSData}
      for file {fname}\\n\'')\n+        logging.info(f\''{self.chunk} isMC {self.isMC},
      isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n
      \n \n \ndiff --git a/python/metadata/datasets_HH4b.yml b/python/metadata/datasets_HH4b.yml\nindex
      bda9189..4707db1 100644\n--- a/python/metadata/datasets_HH4b.yml\n+++ b/python/metadata/datasets_HH4b.yml\n@@
      -720,3 +720,48 @@ datasets:\n         files_template:\n         - root://cmseos.fnal.gov//store/user/jda102/condor/ZH4b/ULTrig/mixed2018_3bDvTMix4bDvT_vXXX/picoAOD_3bDvTMix4bDvT_4b_wJCM_vXXX_newSBDef.root\n     nSamples:
      15\n+\n+\n+\n+  synthetic_data:\n+    nSamples: 1\n+    UL16_postVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPF/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_postVFP/picoAOD_PSData.root      \n+          -
      /srv/python/skimmer/test/data_UL16_postVFPG/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPH/picoAOD_seedXXX.root\n+    UL16_preVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPB/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPC/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPD/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPE/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_preVFP/picoAOD_PSData.root      \n+    UL17:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL17C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17D/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL17E/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17F/picoAOD_seedXXX.root      \n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL17/picoAOD_PSData.root      \n+    UL18:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL18A/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18B/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL18C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18D/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL18/picoAOD_PSData.root      \n+\ndiff
      --git a/python/runner.py b/python/runner.py\nindex f6a92fa..a4dc28c 100644\n---
      a/python/runner.py\n+++ b/python/runner.py\n@@ -163,6 +163,7 @@ if __name__
      == \''__main__\'':\n \n     if \''all\'' in args.datasets:\n         metadata[\''datasets\''].pop("mixeddata")   #
      AGE: this is temporary\n+        metadata[\''datasets\''].pop("synthetic_data")   #
      AGE: this is temporary\n         metadata[\''datasets\''].pop("data_3b_for_mixed")   #
      AGE: this is temporary\n         args.datasets = metadata[\''datasets\''].keys()\n
      \n@@ -181,7 +182,7 @@ if __name__ == \''__main__\'':\n                     f"{year}
      name not in metadatafile for {dataset}")\n                 continue\n \n-            if
      dataset in [\''data\'', \''mixeddata\'', \''data_3b_for_mixed\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n+            if dataset in [\''data\'',
      \''mixeddata\'', \''data_3b_for_mixed\'', \''synthetic_data\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n                 xsec = 1.\n             elif
      isinstance(metadata[\''datasets\''][dataset][\''xs\''], float):\n                 xsec
      = metadata[\''datasets\''][dataset][\''xs\'']\n@@ -203,10 +204,11 @@ if __name__
      == \''__main__\'':\n                                          }\n             isData
      = (dataset == \''data\'')\n             isMixedData = (dataset == \''mixeddata\'')\n+            isSyntheticData
      = (dataset == \''synthetic_data\'')\n             isDataForMix = (dataset ==
      \''data_3b_for_mixed\'')\n             isTTForMixed = (dataset in [\''TTToHadronic_for_mixed\'',
      \''TTToSemiLeptonic_for_mixed\'', \''TTTo2L2Nu_for_mixed\''])\n \n-            if
      not ( isData or isMixedData or isDataForMix or isTTForMixed):\n+            if
      not ( isData or isSyntheticData or isMixedData or isDataForMix or isTTForMixed):\n                 logging.info("\\nConfig
      MC")\n                 if config_runner[\''data_tier\''].startswith(\''pico\''):\n                     if
      \''data\'' not in dataset:\n@@ -249,6 +251,31 @@ if __name__ == \''__main__\'':\n                     logging.info(\n                         f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n \n+            elif
      isSyntheticData:\n+                logging.info("\\nConfig Synthetic Data ")\n+\n+                nSyntheticSamples
      = metadata[\''datasets\''][dataset]["nSamples"]\n+                synthetic_config
      = metadata[\''datasets\''][dataset][year][config_runner[\''data_tier\'']]\n+                logging.info(f"\\nNumber
      of synthetic samples is {nSyntheticSamples}")\n+                for v in range(nSyntheticSamples):\n+\n+                    synthetic_name
      = f"syn_v{v}"\n+                    idataset = f\''{synthetic_name}_{year}\''\n+\n+                    metadata_dataset[idataset]
      = copy(metadata_dataset[dataset])\n+                    metadata_dataset[idataset][\''processName\'']
      = synthetic_name\n+                    # metadata_dataset[idataset][\''FvT_name\'']
      = synthetic_config[\''FvT_name_template\''].replace("XXX",str(v))\n+                    #
      metadata_dataset[idataset][\''FvT_file\''] = synthetic_config[\''FvT_file_template\''].replace("XXX",str(v))\n+                    synthetic_files
      = [f.replace("XXX",str(v)) for f in synthetic_config[\''files_template\'']]\n+                    fileset[idataset]
      = {\''files\'': list_of_files(synthetic_files,\n+                                                                test=args.test,
      test_files=config_runner[\''test_files\''],\n+                                                                allowlist_sites=config_runner[\''allowlist_sites\'']),\n+                                         \''metadata\'':
      metadata_dataset[idataset]}\n+\n+                    logging.info(\n+                        f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n+\n+\n             elif
      isDataForMix:\n                 logging.info("\\nConfig Data for Mixed ")\n
      \n'''
    hash: be7beff9ac9b123dfb8bdeb2581a74ef06734cdb
  saved_events: 15904
  source:
    root://cmseos.fnal.gov//store/user/algomez/XX4b/20231115/data2016B/picoAOD.root:
    - !!python/tuple
      - 199564
      - 299346
    - !!python/tuple
      - 99782
      - 199564
    - !!python/tuple
      - 299346
      - 399128
    - !!python/tuple
      - 0
      - 99782
    - !!python/tuple
      - 399128
      - 498910
    - !!python/tuple
      - 498910
      - 598690
  total_events: 598690
  total_jet: 90820
  xs:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
data_UL16_preVFPC:
  count: 256268.0
  cutFlowFourTag:
    all: 256268.0
    passFourTag: 6779.0
    passFourTag_btagSF: 0
    passHLT: 241024.0
    passJetMult: 234570.0
    passNoiseFilter: 256107.0
    pass_ttbar_filter: 6425.0
  cutFlowFourTagUnitWeight:
    all: 256268
    passFourTag: 6779
    passFourTag_btagSF: 0
    passHLT: 241024
    passJetMult: 234570
    passNoiseFilter: 256107
    pass_ttbar_filter: 6425
  cutFlowThreeTag:
    all: 256268.0
    passFourTag: 6779.0
    passFourTag_btagSF: 0
    passHLT: 241024.0
    passJetMult: 234570.0
    passNoiseFilter: 256107.0
    pass_ttbar_filter: 6425.0
  cutFlowThreeTagUnitWeight:
    all: 256268
    passFourTag: 6779
    passFourTag_btagSF: 0
    passHLT: 241024
    passJetMult: 234570
    passNoiseFilter: 256107
    pass_ttbar_filter: 6425
  files:
  - root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/data_UL16_preVFPC/picoAOD_seed0.root
  kFactor:
  - 1.0
  - 1.0
  - 1.0
  lumi:
  - 19500.0
  - 19500.0
  - 19500.0
  reproducible:
    args: Namespace(test=False, output_file='picoaod_datasets_declustered_data_Run2_seed0.yml',
      processor='skimmer/processor/make_declustered_data_4b.py', configs='skimmer/metadata/declustering_seed_0.yml',
      metadata='metadata/datasets_HH4b.yml', output_path='skimmer/metadata/', years=['UL17',
      'UL18', 'UL16_preVFP', 'UL16_postVFP'], datasets=['data'], era=['A', 'B', 'C',
      'D', 'E', 'F', 'G', 'H'], systematics=False, skimming=True, run_dask=False,
      condor=False, debug=False, githash='', gitdiff='')
    date: '2024-09-19 11:11:51'
    diff: 'b''diff --git a/.ci-workflows/synthetic-dataset-analyze-all.sh b/.ci-workflows/synthetic-dataset-analyze-all.sh\nindex
      40fa0ce..39596eb 100644\n--- a/.ci-workflows/synthetic-dataset-analyze-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-analyze-all.sh\n@@ -14,7 +14,9 @@ cd python/\n
      # fi\n # echo "############### Modifying dataset file with skimmer ci output"\n
      # cat metadata/datasets_ci.yml\n-python metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml
      -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml -o metadata/datasets_synthetic_seed0.yml\n+#python
      metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml
      -o metadata/datasets_synthetic_seed0.yml\n+\n+#python metadata/make_synthetic_yaml_datasets.py
      -m metadata/datasets_HH4b.yml -d skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed5.yml
      -o metadata/datasets_synthetic_seed0.yml\n \n # echo "############### Changing
      metadata"\n # sed -e "s/apply_FvT.*/apply_FvT: false/" -e "s/apply_trig.*/apply_trigWeight:
      false/" -e "s/run_SvB.*/run_SvB: false/"  analysis/metadata/HH4b.yml > analysis/metadata/tmp.yml\ndiff
      --git a/.ci-workflows/synthetic-dataset-make-dataset-all.sh b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\nindex
      37e4cd5..8b8f317 100644\n--- a/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n@@ -5,8 +5,13 @@ voms-proxy-info\n
      echo "############### Moving to python folder"\n cd python/\n echo "###############
      Running test processor"\n-time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering.yml -y UL17 UL18 UL16_preVFP UL16_postVFP -d
      data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed0.yml
      -m metadata/datasets_HH4b.yml   # --dask\n+\n+new_seed=0\n+\n+sed -e "s/declustering_rand_seed:
      [0-9]/declustering_rand_seed: $new_seed/" skimmer/metadata/declustering.yml
      > skimmer/metadata/declustering_seed_${new_seed}.yml\n+cat skimmer/metadata/declustering_seed_${new_seed}.yml\n+time
      python runner.py -s -p skimmer/processor/make_declustered_data_4b.py -c skimmer/metadata/declustering_seed_${new_seed}.yml
      -y UL17 UL18 UL16_preVFP UL16_postVFP -d data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed${new_seed}.yml
      -m metadata/datasets_HH4b.yml   # --dask\n # time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering_signal.yml -y UL17 UL18 UL16_preVFP UL16_postVFP
      -d GluGluToHHTo4B_cHHH1 -op skimmer/metadata/ -o picoaod_datasets_declustered_GluGluToHHTo4B_cHHH1_Run2_seed17.yml
      -m metadata/datasets_HH4b.yml\n \n-ls -R skimmer/\n+#ls -R skimmer/\n cd ../\ndiff
      --git a/python/analysis/metadata/HH4b_rerun_SvB.yml b/python/analysis/metadata/HH4b_rerun_SvB.yml\nindex
      7ea596b..8fbde86 100644\n--- a/python/analysis/metadata/HH4b_rerun_SvB.yml\n+++
      b/python/analysis/metadata/HH4b_rerun_SvB.yml\n@@ -6,7 +6,6 @@ config:\n   JCM:
      \''analysis/weights/JCM/2023/dataRunII/jetCombinatoricModel_SB_00-00-02.yml\''\n   blind:
      false\n   apply_FvT: false\n-  \n   apply_trigWeight: true\n   apply_btagSF:
      true\n   apply_boosted_veto: false\ndiff --git a/python/analysis/metadata/HH4b_synthetic_data.yml
      b/python/analysis/metadata/HH4b_synthetic_data.yml\nindex 0a930d7..8fbde86 100644\n---
      a/python/analysis/metadata/HH4b_synthetic_data.yml\n+++ b/python/analysis/metadata/HH4b_synthetic_data.yml\n@@
      -13,6 +13,6 @@ config:\n   run_systematics: false\n   SvB   : \''analysis/weights/pytorch_models/2024_HHUL/SvB_HCR_8_np753_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n   SvB_MA:
      \''analysis/weights/pytorch_models/2024_HHUL/SvB_MA_HCR+attention_8_np1061_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n-  top_reconstruction_override:
      "fast"\n-  isSyntheticData : True\n+  top_reconstruction_override: fast\n+\n   \ndiff
      --git a/python/analysis/processors/processor_HH4b.py b/python/analysis/processors/processor_HH4b.py\nindex
      a95e196..6201a25 100644\n--- a/python/analysis/processors/processor_HH4b.py\n+++
      b/python/analysis/processors/processor_HH4b.py\n@@ -60,7 +60,6 @@ class analysis(processor.ProcessorABC):\n         top_reconstruction_override:
      bool = False,\n         run_systematics: list = [],\n         make_classifier_input:
      str = None,\n-        isSyntheticData: bool = False,\n         subtract_ttbar_with_weights:
      bool = False,\n         friend_trigWeight: str = None,\n     ):\n@@ -84,7 +83,6
      @@ class analysis(processor.ProcessorABC):\n         self.make_classifier_input
      = make_classifier_input\n         self.top_reconstruction_override = top_reconstruction_override\n         self.subtract_ttbar_with_weights
      = subtract_ttbar_with_weights\n-        self.isSyntheticData = isSyntheticData\n         self.friend_trigWeight
      = friend_trigWeight\n \n         if self.friend_trigWeight:\n@@ -134,6 +132,11
      @@ class analysis(processor.ProcessorABC):\n         self.isMixedData    = not
      (self.dataset.find("mix_v") == -1)\n         if self.isMixedData:\n             self.isMC
      = False\n+\n+        self.isSyntheticData  = not (self.dataset.find("syn_v")
      == -1)\n+        if self.isSyntheticData:\n+            self.isMC = False\n+\n         self.isDataForMixed
      = not (self.dataset.find("data_3b_for_mixed") == -1)\n         self.isTTForMixed   =
      not (self.dataset.find("TTTo") == -1) and not ( self.dataset.find("_for_mixed")
      == -1 )\n \n@@ -189,8 +192,8 @@ class analysis(processor.ProcessorABC):\n             self.do_lepton_jet_cleaning  =
      False\n \n \n-        logging.debug(f\''{self.chunk} isData={False}, isMC={self.isMC},
      isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed}, isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData},
      isPSData={self.isPSData} for file {fname}\\n\'')\n-        logging.debug(f\''{self.chunk}
      isMC {self.isMC}, isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n+        logging.info(f\''{self.chunk}
      isData={False}, isMC={self.isMC}, isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed},
      isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData}, isPSData={self.isPSData}
      for file {fname}\\n\'')\n+        logging.info(f\''{self.chunk} isMC {self.isMC},
      isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n
      \n \n \ndiff --git a/python/metadata/datasets_HH4b.yml b/python/metadata/datasets_HH4b.yml\nindex
      bda9189..4707db1 100644\n--- a/python/metadata/datasets_HH4b.yml\n+++ b/python/metadata/datasets_HH4b.yml\n@@
      -720,3 +720,48 @@ datasets:\n         files_template:\n         - root://cmseos.fnal.gov//store/user/jda102/condor/ZH4b/ULTrig/mixed2018_3bDvTMix4bDvT_vXXX/picoAOD_3bDvTMix4bDvT_4b_wJCM_vXXX_newSBDef.root\n     nSamples:
      15\n+\n+\n+\n+  synthetic_data:\n+    nSamples: 1\n+    UL16_postVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPF/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_postVFP/picoAOD_PSData.root      \n+          -
      /srv/python/skimmer/test/data_UL16_postVFPG/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPH/picoAOD_seedXXX.root\n+    UL16_preVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPB/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPC/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPD/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPE/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_preVFP/picoAOD_PSData.root      \n+    UL17:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL17C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17D/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL17E/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17F/picoAOD_seedXXX.root      \n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL17/picoAOD_PSData.root      \n+    UL18:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL18A/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18B/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL18C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18D/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL18/picoAOD_PSData.root      \n+\ndiff
      --git a/python/runner.py b/python/runner.py\nindex f6a92fa..a4dc28c 100644\n---
      a/python/runner.py\n+++ b/python/runner.py\n@@ -163,6 +163,7 @@ if __name__
      == \''__main__\'':\n \n     if \''all\'' in args.datasets:\n         metadata[\''datasets\''].pop("mixeddata")   #
      AGE: this is temporary\n+        metadata[\''datasets\''].pop("synthetic_data")   #
      AGE: this is temporary\n         metadata[\''datasets\''].pop("data_3b_for_mixed")   #
      AGE: this is temporary\n         args.datasets = metadata[\''datasets\''].keys()\n
      \n@@ -181,7 +182,7 @@ if __name__ == \''__main__\'':\n                     f"{year}
      name not in metadatafile for {dataset}")\n                 continue\n \n-            if
      dataset in [\''data\'', \''mixeddata\'', \''data_3b_for_mixed\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n+            if dataset in [\''data\'',
      \''mixeddata\'', \''data_3b_for_mixed\'', \''synthetic_data\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n                 xsec = 1.\n             elif
      isinstance(metadata[\''datasets\''][dataset][\''xs\''], float):\n                 xsec
      = metadata[\''datasets\''][dataset][\''xs\'']\n@@ -203,10 +204,11 @@ if __name__
      == \''__main__\'':\n                                          }\n             isData
      = (dataset == \''data\'')\n             isMixedData = (dataset == \''mixeddata\'')\n+            isSyntheticData
      = (dataset == \''synthetic_data\'')\n             isDataForMix = (dataset ==
      \''data_3b_for_mixed\'')\n             isTTForMixed = (dataset in [\''TTToHadronic_for_mixed\'',
      \''TTToSemiLeptonic_for_mixed\'', \''TTTo2L2Nu_for_mixed\''])\n \n-            if
      not ( isData or isMixedData or isDataForMix or isTTForMixed):\n+            if
      not ( isData or isSyntheticData or isMixedData or isDataForMix or isTTForMixed):\n                 logging.info("\\nConfig
      MC")\n                 if config_runner[\''data_tier\''].startswith(\''pico\''):\n                     if
      \''data\'' not in dataset:\n@@ -249,6 +251,31 @@ if __name__ == \''__main__\'':\n                     logging.info(\n                         f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n \n+            elif
      isSyntheticData:\n+                logging.info("\\nConfig Synthetic Data ")\n+\n+                nSyntheticSamples
      = metadata[\''datasets\''][dataset]["nSamples"]\n+                synthetic_config
      = metadata[\''datasets\''][dataset][year][config_runner[\''data_tier\'']]\n+                logging.info(f"\\nNumber
      of synthetic samples is {nSyntheticSamples}")\n+                for v in range(nSyntheticSamples):\n+\n+                    synthetic_name
      = f"syn_v{v}"\n+                    idataset = f\''{synthetic_name}_{year}\''\n+\n+                    metadata_dataset[idataset]
      = copy(metadata_dataset[dataset])\n+                    metadata_dataset[idataset][\''processName\'']
      = synthetic_name\n+                    # metadata_dataset[idataset][\''FvT_name\'']
      = synthetic_config[\''FvT_name_template\''].replace("XXX",str(v))\n+                    #
      metadata_dataset[idataset][\''FvT_file\''] = synthetic_config[\''FvT_file_template\''].replace("XXX",str(v))\n+                    synthetic_files
      = [f.replace("XXX",str(v)) for f in synthetic_config[\''files_template\'']]\n+                    fileset[idataset]
      = {\''files\'': list_of_files(synthetic_files,\n+                                                                test=args.test,
      test_files=config_runner[\''test_files\''],\n+                                                                allowlist_sites=config_runner[\''allowlist_sites\'']),\n+                                         \''metadata\'':
      metadata_dataset[idataset]}\n+\n+                    logging.info(\n+                        f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n+\n+\n             elif
      isDataForMix:\n                 logging.info("\\nConfig Data for Mixed ")\n
      \n'''
    hash: be7beff9ac9b123dfb8bdeb2581a74ef06734cdb
  saved_events: 6425
  source:
    root://cmseos.fnal.gov//store/user/algomez/XX4b/20231115/data2016C/picoAOD.root:
    - !!python/tuple
      - 85423
      - 170846
    - !!python/tuple
      - 0
      - 85423
    - !!python/tuple
      - 170846
      - 256268
  total_events: 256268
  total_jet: 36532
  xs:
  - 1.0
  - 1.0
  - 1.0
data_UL16_preVFPD:
  count: 421098.0
  cutFlowFourTag:
    all: 421098.0
    passFourTag: 10594.0
    passFourTag_btagSF: 0
    passHLT: 398485.0
    passJetMult: 388248.0
    passNoiseFilter: 420861.0
    pass_ttbar_filter: 9985.0
  cutFlowFourTagUnitWeight:
    all: 421098
    passFourTag: 10594
    passFourTag_btagSF: 0
    passHLT: 398485
    passJetMult: 388248
    passNoiseFilter: 420861
    pass_ttbar_filter: 9985
  cutFlowThreeTag:
    all: 421098.0
    passFourTag: 10594.0
    passFourTag_btagSF: 0
    passHLT: 398485.0
    passJetMult: 388248.0
    passNoiseFilter: 420861.0
    pass_ttbar_filter: 9985.0
  cutFlowThreeTagUnitWeight:
    all: 421098
    passFourTag: 10594
    passFourTag_btagSF: 0
    passHLT: 398485
    passJetMult: 388248
    passNoiseFilter: 420861
    pass_ttbar_filter: 9985
  files:
  - root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/data_UL16_preVFPD/picoAOD_seed0.root
  kFactor:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  lumi:
  - 19500.0
  - 19500.0
  - 19500.0
  - 19500.0
  reproducible:
    args: Namespace(test=False, output_file='picoaod_datasets_declustered_data_Run2_seed0.yml',
      processor='skimmer/processor/make_declustered_data_4b.py', configs='skimmer/metadata/declustering_seed_0.yml',
      metadata='metadata/datasets_HH4b.yml', output_path='skimmer/metadata/', years=['UL17',
      'UL18', 'UL16_preVFP', 'UL16_postVFP'], datasets=['data'], era=['A', 'B', 'C',
      'D', 'E', 'F', 'G', 'H'], systematics=False, skimming=True, run_dask=False,
      condor=False, debug=False, githash='', gitdiff='')
    date: '2024-09-19 11:11:51'
    diff: 'b''diff --git a/.ci-workflows/synthetic-dataset-analyze-all.sh b/.ci-workflows/synthetic-dataset-analyze-all.sh\nindex
      40fa0ce..39596eb 100644\n--- a/.ci-workflows/synthetic-dataset-analyze-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-analyze-all.sh\n@@ -14,7 +14,9 @@ cd python/\n
      # fi\n # echo "############### Modifying dataset file with skimmer ci output"\n
      # cat metadata/datasets_ci.yml\n-python metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml
      -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml -o metadata/datasets_synthetic_seed0.yml\n+#python
      metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml
      -o metadata/datasets_synthetic_seed0.yml\n+\n+#python metadata/make_synthetic_yaml_datasets.py
      -m metadata/datasets_HH4b.yml -d skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed5.yml
      -o metadata/datasets_synthetic_seed0.yml\n \n # echo "############### Changing
      metadata"\n # sed -e "s/apply_FvT.*/apply_FvT: false/" -e "s/apply_trig.*/apply_trigWeight:
      false/" -e "s/run_SvB.*/run_SvB: false/"  analysis/metadata/HH4b.yml > analysis/metadata/tmp.yml\ndiff
      --git a/.ci-workflows/synthetic-dataset-make-dataset-all.sh b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\nindex
      37e4cd5..8b8f317 100644\n--- a/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n@@ -5,8 +5,13 @@ voms-proxy-info\n
      echo "############### Moving to python folder"\n cd python/\n echo "###############
      Running test processor"\n-time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering.yml -y UL17 UL18 UL16_preVFP UL16_postVFP -d
      data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed0.yml
      -m metadata/datasets_HH4b.yml   # --dask\n+\n+new_seed=0\n+\n+sed -e "s/declustering_rand_seed:
      [0-9]/declustering_rand_seed: $new_seed/" skimmer/metadata/declustering.yml
      > skimmer/metadata/declustering_seed_${new_seed}.yml\n+cat skimmer/metadata/declustering_seed_${new_seed}.yml\n+time
      python runner.py -s -p skimmer/processor/make_declustered_data_4b.py -c skimmer/metadata/declustering_seed_${new_seed}.yml
      -y UL17 UL18 UL16_preVFP UL16_postVFP -d data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed${new_seed}.yml
      -m metadata/datasets_HH4b.yml   # --dask\n # time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering_signal.yml -y UL17 UL18 UL16_preVFP UL16_postVFP
      -d GluGluToHHTo4B_cHHH1 -op skimmer/metadata/ -o picoaod_datasets_declustered_GluGluToHHTo4B_cHHH1_Run2_seed17.yml
      -m metadata/datasets_HH4b.yml\n \n-ls -R skimmer/\n+#ls -R skimmer/\n cd ../\ndiff
      --git a/python/analysis/metadata/HH4b_rerun_SvB.yml b/python/analysis/metadata/HH4b_rerun_SvB.yml\nindex
      7ea596b..8fbde86 100644\n--- a/python/analysis/metadata/HH4b_rerun_SvB.yml\n+++
      b/python/analysis/metadata/HH4b_rerun_SvB.yml\n@@ -6,7 +6,6 @@ config:\n   JCM:
      \''analysis/weights/JCM/2023/dataRunII/jetCombinatoricModel_SB_00-00-02.yml\''\n   blind:
      false\n   apply_FvT: false\n-  \n   apply_trigWeight: true\n   apply_btagSF:
      true\n   apply_boosted_veto: false\ndiff --git a/python/analysis/metadata/HH4b_synthetic_data.yml
      b/python/analysis/metadata/HH4b_synthetic_data.yml\nindex 0a930d7..8fbde86 100644\n---
      a/python/analysis/metadata/HH4b_synthetic_data.yml\n+++ b/python/analysis/metadata/HH4b_synthetic_data.yml\n@@
      -13,6 +13,6 @@ config:\n   run_systematics: false\n   SvB   : \''analysis/weights/pytorch_models/2024_HHUL/SvB_HCR_8_np753_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n   SvB_MA:
      \''analysis/weights/pytorch_models/2024_HHUL/SvB_MA_HCR+attention_8_np1061_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n-  top_reconstruction_override:
      "fast"\n-  isSyntheticData : True\n+  top_reconstruction_override: fast\n+\n   \ndiff
      --git a/python/analysis/processors/processor_HH4b.py b/python/analysis/processors/processor_HH4b.py\nindex
      a95e196..6201a25 100644\n--- a/python/analysis/processors/processor_HH4b.py\n+++
      b/python/analysis/processors/processor_HH4b.py\n@@ -60,7 +60,6 @@ class analysis(processor.ProcessorABC):\n         top_reconstruction_override:
      bool = False,\n         run_systematics: list = [],\n         make_classifier_input:
      str = None,\n-        isSyntheticData: bool = False,\n         subtract_ttbar_with_weights:
      bool = False,\n         friend_trigWeight: str = None,\n     ):\n@@ -84,7 +83,6
      @@ class analysis(processor.ProcessorABC):\n         self.make_classifier_input
      = make_classifier_input\n         self.top_reconstruction_override = top_reconstruction_override\n         self.subtract_ttbar_with_weights
      = subtract_ttbar_with_weights\n-        self.isSyntheticData = isSyntheticData\n         self.friend_trigWeight
      = friend_trigWeight\n \n         if self.friend_trigWeight:\n@@ -134,6 +132,11
      @@ class analysis(processor.ProcessorABC):\n         self.isMixedData    = not
      (self.dataset.find("mix_v") == -1)\n         if self.isMixedData:\n             self.isMC
      = False\n+\n+        self.isSyntheticData  = not (self.dataset.find("syn_v")
      == -1)\n+        if self.isSyntheticData:\n+            self.isMC = False\n+\n         self.isDataForMixed
      = not (self.dataset.find("data_3b_for_mixed") == -1)\n         self.isTTForMixed   =
      not (self.dataset.find("TTTo") == -1) and not ( self.dataset.find("_for_mixed")
      == -1 )\n \n@@ -189,8 +192,8 @@ class analysis(processor.ProcessorABC):\n             self.do_lepton_jet_cleaning  =
      False\n \n \n-        logging.debug(f\''{self.chunk} isData={False}, isMC={self.isMC},
      isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed}, isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData},
      isPSData={self.isPSData} for file {fname}\\n\'')\n-        logging.debug(f\''{self.chunk}
      isMC {self.isMC}, isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n+        logging.info(f\''{self.chunk}
      isData={False}, isMC={self.isMC}, isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed},
      isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData}, isPSData={self.isPSData}
      for file {fname}\\n\'')\n+        logging.info(f\''{self.chunk} isMC {self.isMC},
      isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n
      \n \n \ndiff --git a/python/metadata/datasets_HH4b.yml b/python/metadata/datasets_HH4b.yml\nindex
      bda9189..4707db1 100644\n--- a/python/metadata/datasets_HH4b.yml\n+++ b/python/metadata/datasets_HH4b.yml\n@@
      -720,3 +720,48 @@ datasets:\n         files_template:\n         - root://cmseos.fnal.gov//store/user/jda102/condor/ZH4b/ULTrig/mixed2018_3bDvTMix4bDvT_vXXX/picoAOD_3bDvTMix4bDvT_4b_wJCM_vXXX_newSBDef.root\n     nSamples:
      15\n+\n+\n+\n+  synthetic_data:\n+    nSamples: 1\n+    UL16_postVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPF/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_postVFP/picoAOD_PSData.root      \n+          -
      /srv/python/skimmer/test/data_UL16_postVFPG/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPH/picoAOD_seedXXX.root\n+    UL16_preVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPB/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPC/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPD/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPE/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_preVFP/picoAOD_PSData.root      \n+    UL17:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL17C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17D/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL17E/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17F/picoAOD_seedXXX.root      \n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL17/picoAOD_PSData.root      \n+    UL18:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL18A/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18B/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL18C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18D/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL18/picoAOD_PSData.root      \n+\ndiff
      --git a/python/runner.py b/python/runner.py\nindex f6a92fa..a4dc28c 100644\n---
      a/python/runner.py\n+++ b/python/runner.py\n@@ -163,6 +163,7 @@ if __name__
      == \''__main__\'':\n \n     if \''all\'' in args.datasets:\n         metadata[\''datasets\''].pop("mixeddata")   #
      AGE: this is temporary\n+        metadata[\''datasets\''].pop("synthetic_data")   #
      AGE: this is temporary\n         metadata[\''datasets\''].pop("data_3b_for_mixed")   #
      AGE: this is temporary\n         args.datasets = metadata[\''datasets\''].keys()\n
      \n@@ -181,7 +182,7 @@ if __name__ == \''__main__\'':\n                     f"{year}
      name not in metadatafile for {dataset}")\n                 continue\n \n-            if
      dataset in [\''data\'', \''mixeddata\'', \''data_3b_for_mixed\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n+            if dataset in [\''data\'',
      \''mixeddata\'', \''data_3b_for_mixed\'', \''synthetic_data\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n                 xsec = 1.\n             elif
      isinstance(metadata[\''datasets\''][dataset][\''xs\''], float):\n                 xsec
      = metadata[\''datasets\''][dataset][\''xs\'']\n@@ -203,10 +204,11 @@ if __name__
      == \''__main__\'':\n                                          }\n             isData
      = (dataset == \''data\'')\n             isMixedData = (dataset == \''mixeddata\'')\n+            isSyntheticData
      = (dataset == \''synthetic_data\'')\n             isDataForMix = (dataset ==
      \''data_3b_for_mixed\'')\n             isTTForMixed = (dataset in [\''TTToHadronic_for_mixed\'',
      \''TTToSemiLeptonic_for_mixed\'', \''TTTo2L2Nu_for_mixed\''])\n \n-            if
      not ( isData or isMixedData or isDataForMix or isTTForMixed):\n+            if
      not ( isData or isSyntheticData or isMixedData or isDataForMix or isTTForMixed):\n                 logging.info("\\nConfig
      MC")\n                 if config_runner[\''data_tier\''].startswith(\''pico\''):\n                     if
      \''data\'' not in dataset:\n@@ -249,6 +251,31 @@ if __name__ == \''__main__\'':\n                     logging.info(\n                         f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n \n+            elif
      isSyntheticData:\n+                logging.info("\\nConfig Synthetic Data ")\n+\n+                nSyntheticSamples
      = metadata[\''datasets\''][dataset]["nSamples"]\n+                synthetic_config
      = metadata[\''datasets\''][dataset][year][config_runner[\''data_tier\'']]\n+                logging.info(f"\\nNumber
      of synthetic samples is {nSyntheticSamples}")\n+                for v in range(nSyntheticSamples):\n+\n+                    synthetic_name
      = f"syn_v{v}"\n+                    idataset = f\''{synthetic_name}_{year}\''\n+\n+                    metadata_dataset[idataset]
      = copy(metadata_dataset[dataset])\n+                    metadata_dataset[idataset][\''processName\'']
      = synthetic_name\n+                    # metadata_dataset[idataset][\''FvT_name\'']
      = synthetic_config[\''FvT_name_template\''].replace("XXX",str(v))\n+                    #
      metadata_dataset[idataset][\''FvT_file\''] = synthetic_config[\''FvT_file_template\''].replace("XXX",str(v))\n+                    synthetic_files
      = [f.replace("XXX",str(v)) for f in synthetic_config[\''files_template\'']]\n+                    fileset[idataset]
      = {\''files\'': list_of_files(synthetic_files,\n+                                                                test=args.test,
      test_files=config_runner[\''test_files\''],\n+                                                                allowlist_sites=config_runner[\''allowlist_sites\'']),\n+                                         \''metadata\'':
      metadata_dataset[idataset]}\n+\n+                    logging.info(\n+                        f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n+\n+\n             elif
      isDataForMix:\n                 logging.info("\\nConfig Data for Mixed ")\n
      \n'''
    hash: be7beff9ac9b123dfb8bdeb2581a74ef06734cdb
  saved_events: 9985
  source:
    root://cmseos.fnal.gov//store/user/algomez/XX4b/20231115/data2016D/picoAOD.root:
    - !!python/tuple
      - 210550
      - 315825
    - !!python/tuple
      - 105275
      - 210550
    - !!python/tuple
      - 0
      - 105275
    - !!python/tuple
      - 315825
      - 421098
  total_events: 421098
  total_jet: 56676
  xs:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
data_UL16_preVFPE:
  count: 395976.0
  cutFlowFourTag:
    all: 395976.0
    passFourTag: 9166.0
    passFourTag_btagSF: 0
    passHLT: 375338.0
    passJetMult: 364677.0
    passNoiseFilter: 395717.0
    pass_ttbar_filter: 8667.0
  cutFlowFourTagUnitWeight:
    all: 395976
    passFourTag: 9166
    passFourTag_btagSF: 0
    passHLT: 375338
    passJetMult: 364677
    passNoiseFilter: 395717
    pass_ttbar_filter: 8667
  cutFlowThreeTag:
    all: 395976.0
    passFourTag: 9166.0
    passFourTag_btagSF: 0
    passHLT: 375338.0
    passJetMult: 364677.0
    passNoiseFilter: 395717.0
    pass_ttbar_filter: 8667.0
  cutFlowThreeTagUnitWeight:
    all: 395976
    passFourTag: 9166
    passFourTag_btagSF: 0
    passHLT: 375338
    passJetMult: 364677
    passNoiseFilter: 395717
    pass_ttbar_filter: 8667
  files:
  - root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/data_UL16_preVFPE/picoAOD_seed0.root
  kFactor:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  lumi:
  - 19500.0
  - 19500.0
  - 19500.0
  - 19500.0
  reproducible:
    args: Namespace(test=False, output_file='picoaod_datasets_declustered_data_Run2_seed0.yml',
      processor='skimmer/processor/make_declustered_data_4b.py', configs='skimmer/metadata/declustering_seed_0.yml',
      metadata='metadata/datasets_HH4b.yml', output_path='skimmer/metadata/', years=['UL17',
      'UL18', 'UL16_preVFP', 'UL16_postVFP'], datasets=['data'], era=['A', 'B', 'C',
      'D', 'E', 'F', 'G', 'H'], systematics=False, skimming=True, run_dask=False,
      condor=False, debug=False, githash='', gitdiff='')
    date: '2024-09-19 11:11:51'
    diff: 'b''diff --git a/.ci-workflows/synthetic-dataset-analyze-all.sh b/.ci-workflows/synthetic-dataset-analyze-all.sh\nindex
      40fa0ce..39596eb 100644\n--- a/.ci-workflows/synthetic-dataset-analyze-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-analyze-all.sh\n@@ -14,7 +14,9 @@ cd python/\n
      # fi\n # echo "############### Modifying dataset file with skimmer ci output"\n
      # cat metadata/datasets_ci.yml\n-python metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml
      -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml -o metadata/datasets_synthetic_seed0.yml\n+#python
      metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml
      -o metadata/datasets_synthetic_seed0.yml\n+\n+#python metadata/make_synthetic_yaml_datasets.py
      -m metadata/datasets_HH4b.yml -d skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed5.yml
      -o metadata/datasets_synthetic_seed0.yml\n \n # echo "############### Changing
      metadata"\n # sed -e "s/apply_FvT.*/apply_FvT: false/" -e "s/apply_trig.*/apply_trigWeight:
      false/" -e "s/run_SvB.*/run_SvB: false/"  analysis/metadata/HH4b.yml > analysis/metadata/tmp.yml\ndiff
      --git a/.ci-workflows/synthetic-dataset-make-dataset-all.sh b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\nindex
      37e4cd5..8b8f317 100644\n--- a/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n@@ -5,8 +5,13 @@ voms-proxy-info\n
      echo "############### Moving to python folder"\n cd python/\n echo "###############
      Running test processor"\n-time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering.yml -y UL17 UL18 UL16_preVFP UL16_postVFP -d
      data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed0.yml
      -m metadata/datasets_HH4b.yml   # --dask\n+\n+new_seed=0\n+\n+sed -e "s/declustering_rand_seed:
      [0-9]/declustering_rand_seed: $new_seed/" skimmer/metadata/declustering.yml
      > skimmer/metadata/declustering_seed_${new_seed}.yml\n+cat skimmer/metadata/declustering_seed_${new_seed}.yml\n+time
      python runner.py -s -p skimmer/processor/make_declustered_data_4b.py -c skimmer/metadata/declustering_seed_${new_seed}.yml
      -y UL17 UL18 UL16_preVFP UL16_postVFP -d data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed${new_seed}.yml
      -m metadata/datasets_HH4b.yml   # --dask\n # time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering_signal.yml -y UL17 UL18 UL16_preVFP UL16_postVFP
      -d GluGluToHHTo4B_cHHH1 -op skimmer/metadata/ -o picoaod_datasets_declustered_GluGluToHHTo4B_cHHH1_Run2_seed17.yml
      -m metadata/datasets_HH4b.yml\n \n-ls -R skimmer/\n+#ls -R skimmer/\n cd ../\ndiff
      --git a/python/analysis/metadata/HH4b_rerun_SvB.yml b/python/analysis/metadata/HH4b_rerun_SvB.yml\nindex
      7ea596b..8fbde86 100644\n--- a/python/analysis/metadata/HH4b_rerun_SvB.yml\n+++
      b/python/analysis/metadata/HH4b_rerun_SvB.yml\n@@ -6,7 +6,6 @@ config:\n   JCM:
      \''analysis/weights/JCM/2023/dataRunII/jetCombinatoricModel_SB_00-00-02.yml\''\n   blind:
      false\n   apply_FvT: false\n-  \n   apply_trigWeight: true\n   apply_btagSF:
      true\n   apply_boosted_veto: false\ndiff --git a/python/analysis/metadata/HH4b_synthetic_data.yml
      b/python/analysis/metadata/HH4b_synthetic_data.yml\nindex 0a930d7..8fbde86 100644\n---
      a/python/analysis/metadata/HH4b_synthetic_data.yml\n+++ b/python/analysis/metadata/HH4b_synthetic_data.yml\n@@
      -13,6 +13,6 @@ config:\n   run_systematics: false\n   SvB   : \''analysis/weights/pytorch_models/2024_HHUL/SvB_HCR_8_np753_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n   SvB_MA:
      \''analysis/weights/pytorch_models/2024_HHUL/SvB_MA_HCR+attention_8_np1061_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n-  top_reconstruction_override:
      "fast"\n-  isSyntheticData : True\n+  top_reconstruction_override: fast\n+\n   \ndiff
      --git a/python/analysis/processors/processor_HH4b.py b/python/analysis/processors/processor_HH4b.py\nindex
      a95e196..6201a25 100644\n--- a/python/analysis/processors/processor_HH4b.py\n+++
      b/python/analysis/processors/processor_HH4b.py\n@@ -60,7 +60,6 @@ class analysis(processor.ProcessorABC):\n         top_reconstruction_override:
      bool = False,\n         run_systematics: list = [],\n         make_classifier_input:
      str = None,\n-        isSyntheticData: bool = False,\n         subtract_ttbar_with_weights:
      bool = False,\n         friend_trigWeight: str = None,\n     ):\n@@ -84,7 +83,6
      @@ class analysis(processor.ProcessorABC):\n         self.make_classifier_input
      = make_classifier_input\n         self.top_reconstruction_override = top_reconstruction_override\n         self.subtract_ttbar_with_weights
      = subtract_ttbar_with_weights\n-        self.isSyntheticData = isSyntheticData\n         self.friend_trigWeight
      = friend_trigWeight\n \n         if self.friend_trigWeight:\n@@ -134,6 +132,11
      @@ class analysis(processor.ProcessorABC):\n         self.isMixedData    = not
      (self.dataset.find("mix_v") == -1)\n         if self.isMixedData:\n             self.isMC
      = False\n+\n+        self.isSyntheticData  = not (self.dataset.find("syn_v")
      == -1)\n+        if self.isSyntheticData:\n+            self.isMC = False\n+\n         self.isDataForMixed
      = not (self.dataset.find("data_3b_for_mixed") == -1)\n         self.isTTForMixed   =
      not (self.dataset.find("TTTo") == -1) and not ( self.dataset.find("_for_mixed")
      == -1 )\n \n@@ -189,8 +192,8 @@ class analysis(processor.ProcessorABC):\n             self.do_lepton_jet_cleaning  =
      False\n \n \n-        logging.debug(f\''{self.chunk} isData={False}, isMC={self.isMC},
      isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed}, isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData},
      isPSData={self.isPSData} for file {fname}\\n\'')\n-        logging.debug(f\''{self.chunk}
      isMC {self.isMC}, isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n+        logging.info(f\''{self.chunk}
      isData={False}, isMC={self.isMC}, isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed},
      isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData}, isPSData={self.isPSData}
      for file {fname}\\n\'')\n+        logging.info(f\''{self.chunk} isMC {self.isMC},
      isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n
      \n \n \ndiff --git a/python/metadata/datasets_HH4b.yml b/python/metadata/datasets_HH4b.yml\nindex
      bda9189..4707db1 100644\n--- a/python/metadata/datasets_HH4b.yml\n+++ b/python/metadata/datasets_HH4b.yml\n@@
      -720,3 +720,48 @@ datasets:\n         files_template:\n         - root://cmseos.fnal.gov//store/user/jda102/condor/ZH4b/ULTrig/mixed2018_3bDvTMix4bDvT_vXXX/picoAOD_3bDvTMix4bDvT_4b_wJCM_vXXX_newSBDef.root\n     nSamples:
      15\n+\n+\n+\n+  synthetic_data:\n+    nSamples: 1\n+    UL16_postVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPF/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_postVFP/picoAOD_PSData.root      \n+          -
      /srv/python/skimmer/test/data_UL16_postVFPG/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPH/picoAOD_seedXXX.root\n+    UL16_preVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPB/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPC/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPD/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPE/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_preVFP/picoAOD_PSData.root      \n+    UL17:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL17C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17D/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL17E/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17F/picoAOD_seedXXX.root      \n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL17/picoAOD_PSData.root      \n+    UL18:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL18A/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18B/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL18C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18D/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL18/picoAOD_PSData.root      \n+\ndiff
      --git a/python/runner.py b/python/runner.py\nindex f6a92fa..a4dc28c 100644\n---
      a/python/runner.py\n+++ b/python/runner.py\n@@ -163,6 +163,7 @@ if __name__
      == \''__main__\'':\n \n     if \''all\'' in args.datasets:\n         metadata[\''datasets\''].pop("mixeddata")   #
      AGE: this is temporary\n+        metadata[\''datasets\''].pop("synthetic_data")   #
      AGE: this is temporary\n         metadata[\''datasets\''].pop("data_3b_for_mixed")   #
      AGE: this is temporary\n         args.datasets = metadata[\''datasets\''].keys()\n
      \n@@ -181,7 +182,7 @@ if __name__ == \''__main__\'':\n                     f"{year}
      name not in metadatafile for {dataset}")\n                 continue\n \n-            if
      dataset in [\''data\'', \''mixeddata\'', \''data_3b_for_mixed\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n+            if dataset in [\''data\'',
      \''mixeddata\'', \''data_3b_for_mixed\'', \''synthetic_data\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n                 xsec = 1.\n             elif
      isinstance(metadata[\''datasets\''][dataset][\''xs\''], float):\n                 xsec
      = metadata[\''datasets\''][dataset][\''xs\'']\n@@ -203,10 +204,11 @@ if __name__
      == \''__main__\'':\n                                          }\n             isData
      = (dataset == \''data\'')\n             isMixedData = (dataset == \''mixeddata\'')\n+            isSyntheticData
      = (dataset == \''synthetic_data\'')\n             isDataForMix = (dataset ==
      \''data_3b_for_mixed\'')\n             isTTForMixed = (dataset in [\''TTToHadronic_for_mixed\'',
      \''TTToSemiLeptonic_for_mixed\'', \''TTTo2L2Nu_for_mixed\''])\n \n-            if
      not ( isData or isMixedData or isDataForMix or isTTForMixed):\n+            if
      not ( isData or isSyntheticData or isMixedData or isDataForMix or isTTForMixed):\n                 logging.info("\\nConfig
      MC")\n                 if config_runner[\''data_tier\''].startswith(\''pico\''):\n                     if
      \''data\'' not in dataset:\n@@ -249,6 +251,31 @@ if __name__ == \''__main__\'':\n                     logging.info(\n                         f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n \n+            elif
      isSyntheticData:\n+                logging.info("\\nConfig Synthetic Data ")\n+\n+                nSyntheticSamples
      = metadata[\''datasets\''][dataset]["nSamples"]\n+                synthetic_config
      = metadata[\''datasets\''][dataset][year][config_runner[\''data_tier\'']]\n+                logging.info(f"\\nNumber
      of synthetic samples is {nSyntheticSamples}")\n+                for v in range(nSyntheticSamples):\n+\n+                    synthetic_name
      = f"syn_v{v}"\n+                    idataset = f\''{synthetic_name}_{year}\''\n+\n+                    metadata_dataset[idataset]
      = copy(metadata_dataset[dataset])\n+                    metadata_dataset[idataset][\''processName\'']
      = synthetic_name\n+                    # metadata_dataset[idataset][\''FvT_name\'']
      = synthetic_config[\''FvT_name_template\''].replace("XXX",str(v))\n+                    #
      metadata_dataset[idataset][\''FvT_file\''] = synthetic_config[\''FvT_file_template\''].replace("XXX",str(v))\n+                    synthetic_files
      = [f.replace("XXX",str(v)) for f in synthetic_config[\''files_template\'']]\n+                    fileset[idataset]
      = {\''files\'': list_of_files(synthetic_files,\n+                                                                test=args.test,
      test_files=config_runner[\''test_files\''],\n+                                                                allowlist_sites=config_runner[\''allowlist_sites\'']),\n+                                         \''metadata\'':
      metadata_dataset[idataset]}\n+\n+                    logging.info(\n+                        f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n+\n+\n             elif
      isDataForMix:\n                 logging.info("\\nConfig Data for Mixed ")\n
      \n'''
    hash: be7beff9ac9b123dfb8bdeb2581a74ef06734cdb
  saved_events: 8667
  source:
    root://cmseos.fnal.gov//store/user/algomez/XX4b/20231115/data2016E/picoAOD.root:
    - !!python/tuple
      - 0
      - 98994
    - !!python/tuple
      - 98994
      - 197988
    - !!python/tuple
      - 197988
      - 296982
    - !!python/tuple
      - 296982
      - 395976
  total_events: 395976
  total_jet: 49283
  xs:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
data_UL17C:
  count: 498557.0
  cutFlowFourTag:
    all: 498557.0
    passFourTag: 24603.0
    passFourTag_btagSF: 0
    passHLT: 453114.0
    passJetMult: 446477.0
    passNoiseFilter: 498247.0
    pass_ttbar_filter: 23176.0
  cutFlowFourTagUnitWeight:
    all: 498557
    passFourTag: 24603
    passFourTag_btagSF: 0
    passHLT: 453114
    passJetMult: 446477
    passNoiseFilter: 498247
    pass_ttbar_filter: 23176
  cutFlowThreeTag:
    all: 498557.0
    passFourTag: 24603.0
    passFourTag_btagSF: 0
    passHLT: 453114.0
    passJetMult: 446477.0
    passNoiseFilter: 498247.0
    pass_ttbar_filter: 23176.0
  cutFlowThreeTagUnitWeight:
    all: 498557
    passFourTag: 24603
    passFourTag_btagSF: 0
    passHLT: 453114
    passJetMult: 446477
    passNoiseFilter: 498247
    pass_ttbar_filter: 23176
  files:
  - root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/data_UL17C/picoAOD_seed0.root
  kFactor:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  lumi:
  - 41500.0
  - 41500.0
  - 41500.0
  - 41500.0
  - 41500.0
  reproducible:
    args: Namespace(test=False, output_file='picoaod_datasets_declustered_data_Run2_seed0.yml',
      processor='skimmer/processor/make_declustered_data_4b.py', configs='skimmer/metadata/declustering_seed_0.yml',
      metadata='metadata/datasets_HH4b.yml', output_path='skimmer/metadata/', years=['UL17',
      'UL18', 'UL16_preVFP', 'UL16_postVFP'], datasets=['data'], era=['A', 'B', 'C',
      'D', 'E', 'F', 'G', 'H'], systematics=False, skimming=True, run_dask=False,
      condor=False, debug=False, githash='', gitdiff='')
    date: '2024-09-19 11:11:46'
    diff: 'b''diff --git a/.ci-workflows/synthetic-dataset-analyze-all.sh b/.ci-workflows/synthetic-dataset-analyze-all.sh\nindex
      40fa0ce..39596eb 100644\n--- a/.ci-workflows/synthetic-dataset-analyze-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-analyze-all.sh\n@@ -14,7 +14,9 @@ cd python/\n
      # fi\n # echo "############### Modifying dataset file with skimmer ci output"\n
      # cat metadata/datasets_ci.yml\n-python metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml
      -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml -o metadata/datasets_synthetic_seed0.yml\n+#python
      metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml
      -o metadata/datasets_synthetic_seed0.yml\n+\n+#python metadata/make_synthetic_yaml_datasets.py
      -m metadata/datasets_HH4b.yml -d skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed5.yml
      -o metadata/datasets_synthetic_seed0.yml\n \n # echo "############### Changing
      metadata"\n # sed -e "s/apply_FvT.*/apply_FvT: false/" -e "s/apply_trig.*/apply_trigWeight:
      false/" -e "s/run_SvB.*/run_SvB: false/"  analysis/metadata/HH4b.yml > analysis/metadata/tmp.yml\ndiff
      --git a/.ci-workflows/synthetic-dataset-make-dataset-all.sh b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\nindex
      37e4cd5..8b8f317 100644\n--- a/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n@@ -5,8 +5,13 @@ voms-proxy-info\n
      echo "############### Moving to python folder"\n cd python/\n echo "###############
      Running test processor"\n-time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering.yml -y UL17 UL18 UL16_preVFP UL16_postVFP -d
      data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed0.yml
      -m metadata/datasets_HH4b.yml   # --dask\n+\n+new_seed=0\n+\n+sed -e "s/declustering_rand_seed:
      [0-9]/declustering_rand_seed: $new_seed/" skimmer/metadata/declustering.yml
      > skimmer/metadata/declustering_seed_${new_seed}.yml\n+cat skimmer/metadata/declustering_seed_${new_seed}.yml\n+time
      python runner.py -s -p skimmer/processor/make_declustered_data_4b.py -c skimmer/metadata/declustering_seed_${new_seed}.yml
      -y UL17 UL18 UL16_preVFP UL16_postVFP -d data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed${new_seed}.yml
      -m metadata/datasets_HH4b.yml   # --dask\n # time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering_signal.yml -y UL17 UL18 UL16_preVFP UL16_postVFP
      -d GluGluToHHTo4B_cHHH1 -op skimmer/metadata/ -o picoaod_datasets_declustered_GluGluToHHTo4B_cHHH1_Run2_seed17.yml
      -m metadata/datasets_HH4b.yml\n \n-ls -R skimmer/\n+#ls -R skimmer/\n cd ../\ndiff
      --git a/python/analysis/metadata/HH4b_rerun_SvB.yml b/python/analysis/metadata/HH4b_rerun_SvB.yml\nindex
      7ea596b..8fbde86 100644\n--- a/python/analysis/metadata/HH4b_rerun_SvB.yml\n+++
      b/python/analysis/metadata/HH4b_rerun_SvB.yml\n@@ -6,7 +6,6 @@ config:\n   JCM:
      \''analysis/weights/JCM/2023/dataRunII/jetCombinatoricModel_SB_00-00-02.yml\''\n   blind:
      false\n   apply_FvT: false\n-  \n   apply_trigWeight: true\n   apply_btagSF:
      true\n   apply_boosted_veto: false\ndiff --git a/python/analysis/metadata/HH4b_synthetic_data.yml
      b/python/analysis/metadata/HH4b_synthetic_data.yml\nindex 0a930d7..8fbde86 100644\n---
      a/python/analysis/metadata/HH4b_synthetic_data.yml\n+++ b/python/analysis/metadata/HH4b_synthetic_data.yml\n@@
      -13,6 +13,6 @@ config:\n   run_systematics: false\n   SvB   : \''analysis/weights/pytorch_models/2024_HHUL/SvB_HCR_8_np753_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n   SvB_MA:
      \''analysis/weights/pytorch_models/2024_HHUL/SvB_MA_HCR+attention_8_np1061_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n-  top_reconstruction_override:
      "fast"\n-  isSyntheticData : True\n+  top_reconstruction_override: fast\n+\n   \ndiff
      --git a/python/analysis/processors/processor_HH4b.py b/python/analysis/processors/processor_HH4b.py\nindex
      a95e196..6201a25 100644\n--- a/python/analysis/processors/processor_HH4b.py\n+++
      b/python/analysis/processors/processor_HH4b.py\n@@ -60,7 +60,6 @@ class analysis(processor.ProcessorABC):\n         top_reconstruction_override:
      bool = False,\n         run_systematics: list = [],\n         make_classifier_input:
      str = None,\n-        isSyntheticData: bool = False,\n         subtract_ttbar_with_weights:
      bool = False,\n         friend_trigWeight: str = None,\n     ):\n@@ -84,7 +83,6
      @@ class analysis(processor.ProcessorABC):\n         self.make_classifier_input
      = make_classifier_input\n         self.top_reconstruction_override = top_reconstruction_override\n         self.subtract_ttbar_with_weights
      = subtract_ttbar_with_weights\n-        self.isSyntheticData = isSyntheticData\n         self.friend_trigWeight
      = friend_trigWeight\n \n         if self.friend_trigWeight:\n@@ -134,6 +132,11
      @@ class analysis(processor.ProcessorABC):\n         self.isMixedData    = not
      (self.dataset.find("mix_v") == -1)\n         if self.isMixedData:\n             self.isMC
      = False\n+\n+        self.isSyntheticData  = not (self.dataset.find("syn_v")
      == -1)\n+        if self.isSyntheticData:\n+            self.isMC = False\n+\n         self.isDataForMixed
      = not (self.dataset.find("data_3b_for_mixed") == -1)\n         self.isTTForMixed   =
      not (self.dataset.find("TTTo") == -1) and not ( self.dataset.find("_for_mixed")
      == -1 )\n \n@@ -189,8 +192,8 @@ class analysis(processor.ProcessorABC):\n             self.do_lepton_jet_cleaning  =
      False\n \n \n-        logging.debug(f\''{self.chunk} isData={False}, isMC={self.isMC},
      isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed}, isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData},
      isPSData={self.isPSData} for file {fname}\\n\'')\n-        logging.debug(f\''{self.chunk}
      isMC {self.isMC}, isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n+        logging.info(f\''{self.chunk}
      isData={False}, isMC={self.isMC}, isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed},
      isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData}, isPSData={self.isPSData}
      for file {fname}\\n\'')\n+        logging.info(f\''{self.chunk} isMC {self.isMC},
      isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n
      \n \n \ndiff --git a/python/metadata/datasets_HH4b.yml b/python/metadata/datasets_HH4b.yml\nindex
      bda9189..4707db1 100644\n--- a/python/metadata/datasets_HH4b.yml\n+++ b/python/metadata/datasets_HH4b.yml\n@@
      -720,3 +720,48 @@ datasets:\n         files_template:\n         - root://cmseos.fnal.gov//store/user/jda102/condor/ZH4b/ULTrig/mixed2018_3bDvTMix4bDvT_vXXX/picoAOD_3bDvTMix4bDvT_4b_wJCM_vXXX_newSBDef.root\n     nSamples:
      15\n+\n+\n+\n+  synthetic_data:\n+    nSamples: 1\n+    UL16_postVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPF/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_postVFP/picoAOD_PSData.root      \n+          -
      /srv/python/skimmer/test/data_UL16_postVFPG/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPH/picoAOD_seedXXX.root\n+    UL16_preVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPB/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPC/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPD/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPE/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_preVFP/picoAOD_PSData.root      \n+    UL17:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL17C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17D/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL17E/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17F/picoAOD_seedXXX.root      \n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL17/picoAOD_PSData.root      \n+    UL18:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL18A/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18B/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL18C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18D/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL18/picoAOD_PSData.root      \n+\ndiff
      --git a/python/runner.py b/python/runner.py\nindex f6a92fa..a4dc28c 100644\n---
      a/python/runner.py\n+++ b/python/runner.py\n@@ -163,6 +163,7 @@ if __name__
      == \''__main__\'':\n \n     if \''all\'' in args.datasets:\n         metadata[\''datasets\''].pop("mixeddata")   #
      AGE: this is temporary\n+        metadata[\''datasets\''].pop("synthetic_data")   #
      AGE: this is temporary\n         metadata[\''datasets\''].pop("data_3b_for_mixed")   #
      AGE: this is temporary\n         args.datasets = metadata[\''datasets\''].keys()\n
      \n@@ -181,7 +182,7 @@ if __name__ == \''__main__\'':\n                     f"{year}
      name not in metadatafile for {dataset}")\n                 continue\n \n-            if
      dataset in [\''data\'', \''mixeddata\'', \''data_3b_for_mixed\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n+            if dataset in [\''data\'',
      \''mixeddata\'', \''data_3b_for_mixed\'', \''synthetic_data\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n                 xsec = 1.\n             elif
      isinstance(metadata[\''datasets\''][dataset][\''xs\''], float):\n                 xsec
      = metadata[\''datasets\''][dataset][\''xs\'']\n@@ -203,10 +204,11 @@ if __name__
      == \''__main__\'':\n                                          }\n             isData
      = (dataset == \''data\'')\n             isMixedData = (dataset == \''mixeddata\'')\n+            isSyntheticData
      = (dataset == \''synthetic_data\'')\n             isDataForMix = (dataset ==
      \''data_3b_for_mixed\'')\n             isTTForMixed = (dataset in [\''TTToHadronic_for_mixed\'',
      \''TTToSemiLeptonic_for_mixed\'', \''TTTo2L2Nu_for_mixed\''])\n \n-            if
      not ( isData or isMixedData or isDataForMix or isTTForMixed):\n+            if
      not ( isData or isSyntheticData or isMixedData or isDataForMix or isTTForMixed):\n                 logging.info("\\nConfig
      MC")\n                 if config_runner[\''data_tier\''].startswith(\''pico\''):\n                     if
      \''data\'' not in dataset:\n@@ -249,6 +251,31 @@ if __name__ == \''__main__\'':\n                     logging.info(\n                         f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n \n+            elif
      isSyntheticData:\n+                logging.info("\\nConfig Synthetic Data ")\n+\n+                nSyntheticSamples
      = metadata[\''datasets\''][dataset]["nSamples"]\n+                synthetic_config
      = metadata[\''datasets\''][dataset][year][config_runner[\''data_tier\'']]\n+                logging.info(f"\\nNumber
      of synthetic samples is {nSyntheticSamples}")\n+                for v in range(nSyntheticSamples):\n+\n+                    synthetic_name
      = f"syn_v{v}"\n+                    idataset = f\''{synthetic_name}_{year}\''\n+\n+                    metadata_dataset[idataset]
      = copy(metadata_dataset[dataset])\n+                    metadata_dataset[idataset][\''processName\'']
      = synthetic_name\n+                    # metadata_dataset[idataset][\''FvT_name\'']
      = synthetic_config[\''FvT_name_template\''].replace("XXX",str(v))\n+                    #
      metadata_dataset[idataset][\''FvT_file\''] = synthetic_config[\''FvT_file_template\''].replace("XXX",str(v))\n+                    synthetic_files
      = [f.replace("XXX",str(v)) for f in synthetic_config[\''files_template\'']]\n+                    fileset[idataset]
      = {\''files\'': list_of_files(synthetic_files,\n+                                                                test=args.test,
      test_files=config_runner[\''test_files\''],\n+                                                                allowlist_sites=config_runner[\''allowlist_sites\'']),\n+                                         \''metadata\'':
      metadata_dataset[idataset]}\n+\n+                    logging.info(\n+                        f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n+\n+\n             elif
      isDataForMix:\n                 logging.info("\\nConfig Data for Mixed ")\n
      \n'''
    hash: be7beff9ac9b123dfb8bdeb2581a74ef06734cdb
  saved_events: 23176
  source:
    root://cmseos.fnal.gov//store/user/algomez/XX4b/20231115/data2017C/picoAOD.root:
    - !!python/tuple
      - 0
      - 99712
    - !!python/tuple
      - 99712
      - 199424
    - !!python/tuple
      - 199424
      - 299136
    - !!python/tuple
      - 299136
      - 398848
    - !!python/tuple
      - 398848
      - 498557
  total_events: 498557
  total_jet: 138991
  xs:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
data_UL17D:
  count: 234161.0
  cutFlowFourTag:
    all: 234161.0
    passFourTag: 11863.0
    passFourTag_btagSF: 0
    passHLT: 213954.0
    passJetMult: 210700.0
    passNoiseFilter: 234041.0
    pass_ttbar_filter: 11155.0
  cutFlowFourTagUnitWeight:
    all: 234161
    passFourTag: 11863
    passFourTag_btagSF: 0
    passHLT: 213954
    passJetMult: 210700
    passNoiseFilter: 234041
    pass_ttbar_filter: 11155
  cutFlowThreeTag:
    all: 234161.0
    passFourTag: 11863.0
    passFourTag_btagSF: 0
    passHLT: 213954.0
    passJetMult: 210700.0
    passNoiseFilter: 234041.0
    pass_ttbar_filter: 11155.0
  cutFlowThreeTagUnitWeight:
    all: 234161
    passFourTag: 11863
    passFourTag_btagSF: 0
    passHLT: 213954
    passJetMult: 210700
    passNoiseFilter: 234041
    pass_ttbar_filter: 11155
  files:
  - root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/data_UL17D/picoAOD_seed0.root
  kFactor:
  - 1.0
  - 1.0
  lumi:
  - 41500.0
  - 41500.0
  reproducible:
    args: Namespace(test=False, output_file='picoaod_datasets_declustered_data_Run2_seed0.yml',
      processor='skimmer/processor/make_declustered_data_4b.py', configs='skimmer/metadata/declustering_seed_0.yml',
      metadata='metadata/datasets_HH4b.yml', output_path='skimmer/metadata/', years=['UL17',
      'UL18', 'UL16_preVFP', 'UL16_postVFP'], datasets=['data'], era=['A', 'B', 'C',
      'D', 'E', 'F', 'G', 'H'], systematics=False, skimming=True, run_dask=False,
      condor=False, debug=False, githash='', gitdiff='')
    date: '2024-09-19 11:11:50'
    diff: 'b''diff --git a/.ci-workflows/synthetic-dataset-analyze-all.sh b/.ci-workflows/synthetic-dataset-analyze-all.sh\nindex
      40fa0ce..39596eb 100644\n--- a/.ci-workflows/synthetic-dataset-analyze-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-analyze-all.sh\n@@ -14,7 +14,9 @@ cd python/\n
      # fi\n # echo "############### Modifying dataset file with skimmer ci output"\n
      # cat metadata/datasets_ci.yml\n-python metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml
      -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml -o metadata/datasets_synthetic_seed0.yml\n+#python
      metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml
      -o metadata/datasets_synthetic_seed0.yml\n+\n+#python metadata/make_synthetic_yaml_datasets.py
      -m metadata/datasets_HH4b.yml -d skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed5.yml
      -o metadata/datasets_synthetic_seed0.yml\n \n # echo "############### Changing
      metadata"\n # sed -e "s/apply_FvT.*/apply_FvT: false/" -e "s/apply_trig.*/apply_trigWeight:
      false/" -e "s/run_SvB.*/run_SvB: false/"  analysis/metadata/HH4b.yml > analysis/metadata/tmp.yml\ndiff
      --git a/.ci-workflows/synthetic-dataset-make-dataset-all.sh b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\nindex
      37e4cd5..8b8f317 100644\n--- a/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n@@ -5,8 +5,13 @@ voms-proxy-info\n
      echo "############### Moving to python folder"\n cd python/\n echo "###############
      Running test processor"\n-time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering.yml -y UL17 UL18 UL16_preVFP UL16_postVFP -d
      data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed0.yml
      -m metadata/datasets_HH4b.yml   # --dask\n+\n+new_seed=0\n+\n+sed -e "s/declustering_rand_seed:
      [0-9]/declustering_rand_seed: $new_seed/" skimmer/metadata/declustering.yml
      > skimmer/metadata/declustering_seed_${new_seed}.yml\n+cat skimmer/metadata/declustering_seed_${new_seed}.yml\n+time
      python runner.py -s -p skimmer/processor/make_declustered_data_4b.py -c skimmer/metadata/declustering_seed_${new_seed}.yml
      -y UL17 UL18 UL16_preVFP UL16_postVFP -d data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed${new_seed}.yml
      -m metadata/datasets_HH4b.yml   # --dask\n # time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering_signal.yml -y UL17 UL18 UL16_preVFP UL16_postVFP
      -d GluGluToHHTo4B_cHHH1 -op skimmer/metadata/ -o picoaod_datasets_declustered_GluGluToHHTo4B_cHHH1_Run2_seed17.yml
      -m metadata/datasets_HH4b.yml\n \n-ls -R skimmer/\n+#ls -R skimmer/\n cd ../\ndiff
      --git a/python/analysis/metadata/HH4b_rerun_SvB.yml b/python/analysis/metadata/HH4b_rerun_SvB.yml\nindex
      7ea596b..8fbde86 100644\n--- a/python/analysis/metadata/HH4b_rerun_SvB.yml\n+++
      b/python/analysis/metadata/HH4b_rerun_SvB.yml\n@@ -6,7 +6,6 @@ config:\n   JCM:
      \''analysis/weights/JCM/2023/dataRunII/jetCombinatoricModel_SB_00-00-02.yml\''\n   blind:
      false\n   apply_FvT: false\n-  \n   apply_trigWeight: true\n   apply_btagSF:
      true\n   apply_boosted_veto: false\ndiff --git a/python/analysis/metadata/HH4b_synthetic_data.yml
      b/python/analysis/metadata/HH4b_synthetic_data.yml\nindex 0a930d7..8fbde86 100644\n---
      a/python/analysis/metadata/HH4b_synthetic_data.yml\n+++ b/python/analysis/metadata/HH4b_synthetic_data.yml\n@@
      -13,6 +13,6 @@ config:\n   run_systematics: false\n   SvB   : \''analysis/weights/pytorch_models/2024_HHUL/SvB_HCR_8_np753_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n   SvB_MA:
      \''analysis/weights/pytorch_models/2024_HHUL/SvB_MA_HCR+attention_8_np1061_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n-  top_reconstruction_override:
      "fast"\n-  isSyntheticData : True\n+  top_reconstruction_override: fast\n+\n   \ndiff
      --git a/python/analysis/processors/processor_HH4b.py b/python/analysis/processors/processor_HH4b.py\nindex
      a95e196..6201a25 100644\n--- a/python/analysis/processors/processor_HH4b.py\n+++
      b/python/analysis/processors/processor_HH4b.py\n@@ -60,7 +60,6 @@ class analysis(processor.ProcessorABC):\n         top_reconstruction_override:
      bool = False,\n         run_systematics: list = [],\n         make_classifier_input:
      str = None,\n-        isSyntheticData: bool = False,\n         subtract_ttbar_with_weights:
      bool = False,\n         friend_trigWeight: str = None,\n     ):\n@@ -84,7 +83,6
      @@ class analysis(processor.ProcessorABC):\n         self.make_classifier_input
      = make_classifier_input\n         self.top_reconstruction_override = top_reconstruction_override\n         self.subtract_ttbar_with_weights
      = subtract_ttbar_with_weights\n-        self.isSyntheticData = isSyntheticData\n         self.friend_trigWeight
      = friend_trigWeight\n \n         if self.friend_trigWeight:\n@@ -134,6 +132,11
      @@ class analysis(processor.ProcessorABC):\n         self.isMixedData    = not
      (self.dataset.find("mix_v") == -1)\n         if self.isMixedData:\n             self.isMC
      = False\n+\n+        self.isSyntheticData  = not (self.dataset.find("syn_v")
      == -1)\n+        if self.isSyntheticData:\n+            self.isMC = False\n+\n         self.isDataForMixed
      = not (self.dataset.find("data_3b_for_mixed") == -1)\n         self.isTTForMixed   =
      not (self.dataset.find("TTTo") == -1) and not ( self.dataset.find("_for_mixed")
      == -1 )\n \n@@ -189,8 +192,8 @@ class analysis(processor.ProcessorABC):\n             self.do_lepton_jet_cleaning  =
      False\n \n \n-        logging.debug(f\''{self.chunk} isData={False}, isMC={self.isMC},
      isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed}, isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData},
      isPSData={self.isPSData} for file {fname}\\n\'')\n-        logging.debug(f\''{self.chunk}
      isMC {self.isMC}, isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n+        logging.info(f\''{self.chunk}
      isData={False}, isMC={self.isMC}, isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed},
      isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData}, isPSData={self.isPSData}
      for file {fname}\\n\'')\n+        logging.info(f\''{self.chunk} isMC {self.isMC},
      isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n
      \n \n \ndiff --git a/python/metadata/datasets_HH4b.yml b/python/metadata/datasets_HH4b.yml\nindex
      bda9189..4707db1 100644\n--- a/python/metadata/datasets_HH4b.yml\n+++ b/python/metadata/datasets_HH4b.yml\n@@
      -720,3 +720,48 @@ datasets:\n         files_template:\n         - root://cmseos.fnal.gov//store/user/jda102/condor/ZH4b/ULTrig/mixed2018_3bDvTMix4bDvT_vXXX/picoAOD_3bDvTMix4bDvT_4b_wJCM_vXXX_newSBDef.root\n     nSamples:
      15\n+\n+\n+\n+  synthetic_data:\n+    nSamples: 1\n+    UL16_postVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPF/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_postVFP/picoAOD_PSData.root      \n+          -
      /srv/python/skimmer/test/data_UL16_postVFPG/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPH/picoAOD_seedXXX.root\n+    UL16_preVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPB/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPC/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPD/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPE/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_preVFP/picoAOD_PSData.root      \n+    UL17:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL17C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17D/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL17E/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17F/picoAOD_seedXXX.root      \n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL17/picoAOD_PSData.root      \n+    UL18:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL18A/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18B/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL18C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18D/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL18/picoAOD_PSData.root      \n+\ndiff
      --git a/python/runner.py b/python/runner.py\nindex f6a92fa..a4dc28c 100644\n---
      a/python/runner.py\n+++ b/python/runner.py\n@@ -163,6 +163,7 @@ if __name__
      == \''__main__\'':\n \n     if \''all\'' in args.datasets:\n         metadata[\''datasets\''].pop("mixeddata")   #
      AGE: this is temporary\n+        metadata[\''datasets\''].pop("synthetic_data")   #
      AGE: this is temporary\n         metadata[\''datasets\''].pop("data_3b_for_mixed")   #
      AGE: this is temporary\n         args.datasets = metadata[\''datasets\''].keys()\n
      \n@@ -181,7 +182,7 @@ if __name__ == \''__main__\'':\n                     f"{year}
      name not in metadatafile for {dataset}")\n                 continue\n \n-            if
      dataset in [\''data\'', \''mixeddata\'', \''data_3b_for_mixed\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n+            if dataset in [\''data\'',
      \''mixeddata\'', \''data_3b_for_mixed\'', \''synthetic_data\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n                 xsec = 1.\n             elif
      isinstance(metadata[\''datasets\''][dataset][\''xs\''], float):\n                 xsec
      = metadata[\''datasets\''][dataset][\''xs\'']\n@@ -203,10 +204,11 @@ if __name__
      == \''__main__\'':\n                                          }\n             isData
      = (dataset == \''data\'')\n             isMixedData = (dataset == \''mixeddata\'')\n+            isSyntheticData
      = (dataset == \''synthetic_data\'')\n             isDataForMix = (dataset ==
      \''data_3b_for_mixed\'')\n             isTTForMixed = (dataset in [\''TTToHadronic_for_mixed\'',
      \''TTToSemiLeptonic_for_mixed\'', \''TTTo2L2Nu_for_mixed\''])\n \n-            if
      not ( isData or isMixedData or isDataForMix or isTTForMixed):\n+            if
      not ( isData or isSyntheticData or isMixedData or isDataForMix or isTTForMixed):\n                 logging.info("\\nConfig
      MC")\n                 if config_runner[\''data_tier\''].startswith(\''pico\''):\n                     if
      \''data\'' not in dataset:\n@@ -249,6 +251,31 @@ if __name__ == \''__main__\'':\n                     logging.info(\n                         f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n \n+            elif
      isSyntheticData:\n+                logging.info("\\nConfig Synthetic Data ")\n+\n+                nSyntheticSamples
      = metadata[\''datasets\''][dataset]["nSamples"]\n+                synthetic_config
      = metadata[\''datasets\''][dataset][year][config_runner[\''data_tier\'']]\n+                logging.info(f"\\nNumber
      of synthetic samples is {nSyntheticSamples}")\n+                for v in range(nSyntheticSamples):\n+\n+                    synthetic_name
      = f"syn_v{v}"\n+                    idataset = f\''{synthetic_name}_{year}\''\n+\n+                    metadata_dataset[idataset]
      = copy(metadata_dataset[dataset])\n+                    metadata_dataset[idataset][\''processName\'']
      = synthetic_name\n+                    # metadata_dataset[idataset][\''FvT_name\'']
      = synthetic_config[\''FvT_name_template\''].replace("XXX",str(v))\n+                    #
      metadata_dataset[idataset][\''FvT_file\''] = synthetic_config[\''FvT_file_template\''].replace("XXX",str(v))\n+                    synthetic_files
      = [f.replace("XXX",str(v)) for f in synthetic_config[\''files_template\'']]\n+                    fileset[idataset]
      = {\''files\'': list_of_files(synthetic_files,\n+                                                                test=args.test,
      test_files=config_runner[\''test_files\''],\n+                                                                allowlist_sites=config_runner[\''allowlist_sites\'']),\n+                                         \''metadata\'':
      metadata_dataset[idataset]}\n+\n+                    logging.info(\n+                        f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n+\n+\n             elif
      isDataForMix:\n                 logging.info("\\nConfig Data for Mixed ")\n
      \n'''
    hash: be7beff9ac9b123dfb8bdeb2581a74ef06734cdb
  saved_events: 11155
  source:
    root://cmseos.fnal.gov//store/user/algomez/XX4b/20231115/data2017D/picoAOD.root:
    - !!python/tuple
      - 0
      - 117081
    - !!python/tuple
      - 117081
      - 234161
  total_events: 234161
  total_jet: 66922
  xs:
  - 1.0
  - 1.0
data_UL17E:
  count: 549026.0
  cutFlowFourTag:
    all: 549026.0
    passFourTag: 24170.0
    passFourTag_btagSF: 0
    passHLT: 503815.0
    passJetMult: 493312.0
    passNoiseFilter: 548670.0
    pass_ttbar_filter: 22856.0
  cutFlowFourTagUnitWeight:
    all: 549026
    passFourTag: 24170
    passFourTag_btagSF: 0
    passHLT: 503815
    passJetMult: 493312
    passNoiseFilter: 548670
    pass_ttbar_filter: 22856
  cutFlowThreeTag:
    all: 549026.0
    passFourTag: 24170.0
    passFourTag_btagSF: 0
    passHLT: 503815.0
    passJetMult: 493312.0
    passNoiseFilter: 548670.0
    pass_ttbar_filter: 22856.0
  cutFlowThreeTagUnitWeight:
    all: 549026
    passFourTag: 24170
    passFourTag_btagSF: 0
    passHLT: 503815
    passJetMult: 493312
    passNoiseFilter: 548670
    pass_ttbar_filter: 22856
  files:
  - root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/data_UL17E/picoAOD_seed0.root
  kFactor:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  lumi:
  - 41500.0
  - 41500.0
  - 41500.0
  - 41500.0
  - 41500.0
  reproducible:
    args: Namespace(test=False, output_file='picoaod_datasets_declustered_data_Run2_seed0.yml',
      processor='skimmer/processor/make_declustered_data_4b.py', configs='skimmer/metadata/declustering_seed_0.yml',
      metadata='metadata/datasets_HH4b.yml', output_path='skimmer/metadata/', years=['UL17',
      'UL18', 'UL16_preVFP', 'UL16_postVFP'], datasets=['data'], era=['A', 'B', 'C',
      'D', 'E', 'F', 'G', 'H'], systematics=False, skimming=True, run_dask=False,
      condor=False, debug=False, githash='', gitdiff='')
    date: '2024-09-19 11:11:50'
    diff: 'b''diff --git a/.ci-workflows/synthetic-dataset-analyze-all.sh b/.ci-workflows/synthetic-dataset-analyze-all.sh\nindex
      40fa0ce..39596eb 100644\n--- a/.ci-workflows/synthetic-dataset-analyze-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-analyze-all.sh\n@@ -14,7 +14,9 @@ cd python/\n
      # fi\n # echo "############### Modifying dataset file with skimmer ci output"\n
      # cat metadata/datasets_ci.yml\n-python metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml
      -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml -o metadata/datasets_synthetic_seed0.yml\n+#python
      metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml
      -o metadata/datasets_synthetic_seed0.yml\n+\n+#python metadata/make_synthetic_yaml_datasets.py
      -m metadata/datasets_HH4b.yml -d skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed5.yml
      -o metadata/datasets_synthetic_seed0.yml\n \n # echo "############### Changing
      metadata"\n # sed -e "s/apply_FvT.*/apply_FvT: false/" -e "s/apply_trig.*/apply_trigWeight:
      false/" -e "s/run_SvB.*/run_SvB: false/"  analysis/metadata/HH4b.yml > analysis/metadata/tmp.yml\ndiff
      --git a/.ci-workflows/synthetic-dataset-make-dataset-all.sh b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\nindex
      37e4cd5..8b8f317 100644\n--- a/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n@@ -5,8 +5,13 @@ voms-proxy-info\n
      echo "############### Moving to python folder"\n cd python/\n echo "###############
      Running test processor"\n-time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering.yml -y UL17 UL18 UL16_preVFP UL16_postVFP -d
      data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed0.yml
      -m metadata/datasets_HH4b.yml   # --dask\n+\n+new_seed=0\n+\n+sed -e "s/declustering_rand_seed:
      [0-9]/declustering_rand_seed: $new_seed/" skimmer/metadata/declustering.yml
      > skimmer/metadata/declustering_seed_${new_seed}.yml\n+cat skimmer/metadata/declustering_seed_${new_seed}.yml\n+time
      python runner.py -s -p skimmer/processor/make_declustered_data_4b.py -c skimmer/metadata/declustering_seed_${new_seed}.yml
      -y UL17 UL18 UL16_preVFP UL16_postVFP -d data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed${new_seed}.yml
      -m metadata/datasets_HH4b.yml   # --dask\n # time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering_signal.yml -y UL17 UL18 UL16_preVFP UL16_postVFP
      -d GluGluToHHTo4B_cHHH1 -op skimmer/metadata/ -o picoaod_datasets_declustered_GluGluToHHTo4B_cHHH1_Run2_seed17.yml
      -m metadata/datasets_HH4b.yml\n \n-ls -R skimmer/\n+#ls -R skimmer/\n cd ../\ndiff
      --git a/python/analysis/metadata/HH4b_rerun_SvB.yml b/python/analysis/metadata/HH4b_rerun_SvB.yml\nindex
      7ea596b..8fbde86 100644\n--- a/python/analysis/metadata/HH4b_rerun_SvB.yml\n+++
      b/python/analysis/metadata/HH4b_rerun_SvB.yml\n@@ -6,7 +6,6 @@ config:\n   JCM:
      \''analysis/weights/JCM/2023/dataRunII/jetCombinatoricModel_SB_00-00-02.yml\''\n   blind:
      false\n   apply_FvT: false\n-  \n   apply_trigWeight: true\n   apply_btagSF:
      true\n   apply_boosted_veto: false\ndiff --git a/python/analysis/metadata/HH4b_synthetic_data.yml
      b/python/analysis/metadata/HH4b_synthetic_data.yml\nindex 0a930d7..8fbde86 100644\n---
      a/python/analysis/metadata/HH4b_synthetic_data.yml\n+++ b/python/analysis/metadata/HH4b_synthetic_data.yml\n@@
      -13,6 +13,6 @@ config:\n   run_systematics: false\n   SvB   : \''analysis/weights/pytorch_models/2024_HHUL/SvB_HCR_8_np753_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n   SvB_MA:
      \''analysis/weights/pytorch_models/2024_HHUL/SvB_MA_HCR+attention_8_np1061_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n-  top_reconstruction_override:
      "fast"\n-  isSyntheticData : True\n+  top_reconstruction_override: fast\n+\n   \ndiff
      --git a/python/analysis/processors/processor_HH4b.py b/python/analysis/processors/processor_HH4b.py\nindex
      a95e196..6201a25 100644\n--- a/python/analysis/processors/processor_HH4b.py\n+++
      b/python/analysis/processors/processor_HH4b.py\n@@ -60,7 +60,6 @@ class analysis(processor.ProcessorABC):\n         top_reconstruction_override:
      bool = False,\n         run_systematics: list = [],\n         make_classifier_input:
      str = None,\n-        isSyntheticData: bool = False,\n         subtract_ttbar_with_weights:
      bool = False,\n         friend_trigWeight: str = None,\n     ):\n@@ -84,7 +83,6
      @@ class analysis(processor.ProcessorABC):\n         self.make_classifier_input
      = make_classifier_input\n         self.top_reconstruction_override = top_reconstruction_override\n         self.subtract_ttbar_with_weights
      = subtract_ttbar_with_weights\n-        self.isSyntheticData = isSyntheticData\n         self.friend_trigWeight
      = friend_trigWeight\n \n         if self.friend_trigWeight:\n@@ -134,6 +132,11
      @@ class analysis(processor.ProcessorABC):\n         self.isMixedData    = not
      (self.dataset.find("mix_v") == -1)\n         if self.isMixedData:\n             self.isMC
      = False\n+\n+        self.isSyntheticData  = not (self.dataset.find("syn_v")
      == -1)\n+        if self.isSyntheticData:\n+            self.isMC = False\n+\n         self.isDataForMixed
      = not (self.dataset.find("data_3b_for_mixed") == -1)\n         self.isTTForMixed   =
      not (self.dataset.find("TTTo") == -1) and not ( self.dataset.find("_for_mixed")
      == -1 )\n \n@@ -189,8 +192,8 @@ class analysis(processor.ProcessorABC):\n             self.do_lepton_jet_cleaning  =
      False\n \n \n-        logging.debug(f\''{self.chunk} isData={False}, isMC={self.isMC},
      isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed}, isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData},
      isPSData={self.isPSData} for file {fname}\\n\'')\n-        logging.debug(f\''{self.chunk}
      isMC {self.isMC}, isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n+        logging.info(f\''{self.chunk}
      isData={False}, isMC={self.isMC}, isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed},
      isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData}, isPSData={self.isPSData}
      for file {fname}\\n\'')\n+        logging.info(f\''{self.chunk} isMC {self.isMC},
      isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n
      \n \n \ndiff --git a/python/metadata/datasets_HH4b.yml b/python/metadata/datasets_HH4b.yml\nindex
      bda9189..4707db1 100644\n--- a/python/metadata/datasets_HH4b.yml\n+++ b/python/metadata/datasets_HH4b.yml\n@@
      -720,3 +720,48 @@ datasets:\n         files_template:\n         - root://cmseos.fnal.gov//store/user/jda102/condor/ZH4b/ULTrig/mixed2018_3bDvTMix4bDvT_vXXX/picoAOD_3bDvTMix4bDvT_4b_wJCM_vXXX_newSBDef.root\n     nSamples:
      15\n+\n+\n+\n+  synthetic_data:\n+    nSamples: 1\n+    UL16_postVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPF/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_postVFP/picoAOD_PSData.root      \n+          -
      /srv/python/skimmer/test/data_UL16_postVFPG/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPH/picoAOD_seedXXX.root\n+    UL16_preVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPB/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPC/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPD/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPE/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_preVFP/picoAOD_PSData.root      \n+    UL17:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL17C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17D/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL17E/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17F/picoAOD_seedXXX.root      \n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL17/picoAOD_PSData.root      \n+    UL18:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL18A/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18B/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL18C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18D/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL18/picoAOD_PSData.root      \n+\ndiff
      --git a/python/runner.py b/python/runner.py\nindex f6a92fa..a4dc28c 100644\n---
      a/python/runner.py\n+++ b/python/runner.py\n@@ -163,6 +163,7 @@ if __name__
      == \''__main__\'':\n \n     if \''all\'' in args.datasets:\n         metadata[\''datasets\''].pop("mixeddata")   #
      AGE: this is temporary\n+        metadata[\''datasets\''].pop("synthetic_data")   #
      AGE: this is temporary\n         metadata[\''datasets\''].pop("data_3b_for_mixed")   #
      AGE: this is temporary\n         args.datasets = metadata[\''datasets\''].keys()\n
      \n@@ -181,7 +182,7 @@ if __name__ == \''__main__\'':\n                     f"{year}
      name not in metadatafile for {dataset}")\n                 continue\n \n-            if
      dataset in [\''data\'', \''mixeddata\'', \''data_3b_for_mixed\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n+            if dataset in [\''data\'',
      \''mixeddata\'', \''data_3b_for_mixed\'', \''synthetic_data\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n                 xsec = 1.\n             elif
      isinstance(metadata[\''datasets\''][dataset][\''xs\''], float):\n                 xsec
      = metadata[\''datasets\''][dataset][\''xs\'']\n@@ -203,10 +204,11 @@ if __name__
      == \''__main__\'':\n                                          }\n             isData
      = (dataset == \''data\'')\n             isMixedData = (dataset == \''mixeddata\'')\n+            isSyntheticData
      = (dataset == \''synthetic_data\'')\n             isDataForMix = (dataset ==
      \''data_3b_for_mixed\'')\n             isTTForMixed = (dataset in [\''TTToHadronic_for_mixed\'',
      \''TTToSemiLeptonic_for_mixed\'', \''TTTo2L2Nu_for_mixed\''])\n \n-            if
      not ( isData or isMixedData or isDataForMix or isTTForMixed):\n+            if
      not ( isData or isSyntheticData or isMixedData or isDataForMix or isTTForMixed):\n                 logging.info("\\nConfig
      MC")\n                 if config_runner[\''data_tier\''].startswith(\''pico\''):\n                     if
      \''data\'' not in dataset:\n@@ -249,6 +251,31 @@ if __name__ == \''__main__\'':\n                     logging.info(\n                         f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n \n+            elif
      isSyntheticData:\n+                logging.info("\\nConfig Synthetic Data ")\n+\n+                nSyntheticSamples
      = metadata[\''datasets\''][dataset]["nSamples"]\n+                synthetic_config
      = metadata[\''datasets\''][dataset][year][config_runner[\''data_tier\'']]\n+                logging.info(f"\\nNumber
      of synthetic samples is {nSyntheticSamples}")\n+                for v in range(nSyntheticSamples):\n+\n+                    synthetic_name
      = f"syn_v{v}"\n+                    idataset = f\''{synthetic_name}_{year}\''\n+\n+                    metadata_dataset[idataset]
      = copy(metadata_dataset[dataset])\n+                    metadata_dataset[idataset][\''processName\'']
      = synthetic_name\n+                    # metadata_dataset[idataset][\''FvT_name\'']
      = synthetic_config[\''FvT_name_template\''].replace("XXX",str(v))\n+                    #
      metadata_dataset[idataset][\''FvT_file\''] = synthetic_config[\''FvT_file_template\''].replace("XXX",str(v))\n+                    synthetic_files
      = [f.replace("XXX",str(v)) for f in synthetic_config[\''files_template\'']]\n+                    fileset[idataset]
      = {\''files\'': list_of_files(synthetic_files,\n+                                                                test=args.test,
      test_files=config_runner[\''test_files\''],\n+                                                                allowlist_sites=config_runner[\''allowlist_sites\'']),\n+                                         \''metadata\'':
      metadata_dataset[idataset]}\n+\n+                    logging.info(\n+                        f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n+\n+\n             elif
      isDataForMix:\n                 logging.info("\\nConfig Data for Mixed ")\n
      \n'''
    hash: be7beff9ac9b123dfb8bdeb2581a74ef06734cdb
  saved_events: 22856
  source:
    root://cmseos.fnal.gov//store/user/algomez/XX4b/20231115/data2017E/picoAOD.root:
    - !!python/tuple
      - 109806
      - 219612
    - !!python/tuple
      - 0
      - 109806
    - !!python/tuple
      - 219612
      - 329418
    - !!python/tuple
      - 329418
      - 439224
    - !!python/tuple
      - 439224
      - 549026
  total_events: 549026
  total_jet: 136315
  xs:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
data_UL17F:
  count: 710245.0
  cutFlowFourTag:
    all: 710245.0
    passFourTag: 24595.0
    passFourTag_btagSF: 0
    passHLT: 648552.0
    passJetMult: 636751.0
    passNoiseFilter: 709743.0
    pass_ttbar_filter: 23171.0
  cutFlowFourTagUnitWeight:
    all: 710245
    passFourTag: 24595
    passFourTag_btagSF: 0
    passHLT: 648552
    passJetMult: 636751
    passNoiseFilter: 709743
    pass_ttbar_filter: 23171
  cutFlowThreeTag:
    all: 710245.0
    passFourTag: 24595.0
    passFourTag_btagSF: 0
    passHLT: 648552.0
    passJetMult: 636751.0
    passNoiseFilter: 709743.0
    pass_ttbar_filter: 23171.0
  cutFlowThreeTagUnitWeight:
    all: 710245
    passFourTag: 24595
    passFourTag_btagSF: 0
    passHLT: 648552
    passJetMult: 636751
    passNoiseFilter: 709743
    pass_ttbar_filter: 23171
  files:
  - root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/data_UL17F/picoAOD_seed0.root
  kFactor:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  lumi:
  - 41500.0
  - 41500.0
  - 41500.0
  - 41500.0
  - 41500.0
  - 41500.0
  - 41500.0
  reproducible:
    args: Namespace(test=False, output_file='picoaod_datasets_declustered_data_Run2_seed0.yml',
      processor='skimmer/processor/make_declustered_data_4b.py', configs='skimmer/metadata/declustering_seed_0.yml',
      metadata='metadata/datasets_HH4b.yml', output_path='skimmer/metadata/', years=['UL17',
      'UL18', 'UL16_preVFP', 'UL16_postVFP'], datasets=['data'], era=['A', 'B', 'C',
      'D', 'E', 'F', 'G', 'H'], systematics=False, skimming=True, run_dask=False,
      condor=False, debug=False, githash='', gitdiff='')
    date: '2024-09-19 11:11:50'
    diff: 'b''diff --git a/.ci-workflows/synthetic-dataset-analyze-all.sh b/.ci-workflows/synthetic-dataset-analyze-all.sh\nindex
      40fa0ce..39596eb 100644\n--- a/.ci-workflows/synthetic-dataset-analyze-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-analyze-all.sh\n@@ -14,7 +14,9 @@ cd python/\n
      # fi\n # echo "############### Modifying dataset file with skimmer ci output"\n
      # cat metadata/datasets_ci.yml\n-python metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml
      -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml -o metadata/datasets_synthetic_seed0.yml\n+#python
      metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml
      -o metadata/datasets_synthetic_seed0.yml\n+\n+#python metadata/make_synthetic_yaml_datasets.py
      -m metadata/datasets_HH4b.yml -d skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed5.yml
      -o metadata/datasets_synthetic_seed0.yml\n \n # echo "############### Changing
      metadata"\n # sed -e "s/apply_FvT.*/apply_FvT: false/" -e "s/apply_trig.*/apply_trigWeight:
      false/" -e "s/run_SvB.*/run_SvB: false/"  analysis/metadata/HH4b.yml > analysis/metadata/tmp.yml\ndiff
      --git a/.ci-workflows/synthetic-dataset-make-dataset-all.sh b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\nindex
      37e4cd5..8b8f317 100644\n--- a/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n@@ -5,8 +5,13 @@ voms-proxy-info\n
      echo "############### Moving to python folder"\n cd python/\n echo "###############
      Running test processor"\n-time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering.yml -y UL17 UL18 UL16_preVFP UL16_postVFP -d
      data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed0.yml
      -m metadata/datasets_HH4b.yml   # --dask\n+\n+new_seed=0\n+\n+sed -e "s/declustering_rand_seed:
      [0-9]/declustering_rand_seed: $new_seed/" skimmer/metadata/declustering.yml
      > skimmer/metadata/declustering_seed_${new_seed}.yml\n+cat skimmer/metadata/declustering_seed_${new_seed}.yml\n+time
      python runner.py -s -p skimmer/processor/make_declustered_data_4b.py -c skimmer/metadata/declustering_seed_${new_seed}.yml
      -y UL17 UL18 UL16_preVFP UL16_postVFP -d data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed${new_seed}.yml
      -m metadata/datasets_HH4b.yml   # --dask\n # time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering_signal.yml -y UL17 UL18 UL16_preVFP UL16_postVFP
      -d GluGluToHHTo4B_cHHH1 -op skimmer/metadata/ -o picoaod_datasets_declustered_GluGluToHHTo4B_cHHH1_Run2_seed17.yml
      -m metadata/datasets_HH4b.yml\n \n-ls -R skimmer/\n+#ls -R skimmer/\n cd ../\ndiff
      --git a/python/analysis/metadata/HH4b_rerun_SvB.yml b/python/analysis/metadata/HH4b_rerun_SvB.yml\nindex
      7ea596b..8fbde86 100644\n--- a/python/analysis/metadata/HH4b_rerun_SvB.yml\n+++
      b/python/analysis/metadata/HH4b_rerun_SvB.yml\n@@ -6,7 +6,6 @@ config:\n   JCM:
      \''analysis/weights/JCM/2023/dataRunII/jetCombinatoricModel_SB_00-00-02.yml\''\n   blind:
      false\n   apply_FvT: false\n-  \n   apply_trigWeight: true\n   apply_btagSF:
      true\n   apply_boosted_veto: false\ndiff --git a/python/analysis/metadata/HH4b_synthetic_data.yml
      b/python/analysis/metadata/HH4b_synthetic_data.yml\nindex 0a930d7..8fbde86 100644\n---
      a/python/analysis/metadata/HH4b_synthetic_data.yml\n+++ b/python/analysis/metadata/HH4b_synthetic_data.yml\n@@
      -13,6 +13,6 @@ config:\n   run_systematics: false\n   SvB   : \''analysis/weights/pytorch_models/2024_HHUL/SvB_HCR_8_np753_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n   SvB_MA:
      \''analysis/weights/pytorch_models/2024_HHUL/SvB_MA_HCR+attention_8_np1061_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n-  top_reconstruction_override:
      "fast"\n-  isSyntheticData : True\n+  top_reconstruction_override: fast\n+\n   \ndiff
      --git a/python/analysis/processors/processor_HH4b.py b/python/analysis/processors/processor_HH4b.py\nindex
      a95e196..6201a25 100644\n--- a/python/analysis/processors/processor_HH4b.py\n+++
      b/python/analysis/processors/processor_HH4b.py\n@@ -60,7 +60,6 @@ class analysis(processor.ProcessorABC):\n         top_reconstruction_override:
      bool = False,\n         run_systematics: list = [],\n         make_classifier_input:
      str = None,\n-        isSyntheticData: bool = False,\n         subtract_ttbar_with_weights:
      bool = False,\n         friend_trigWeight: str = None,\n     ):\n@@ -84,7 +83,6
      @@ class analysis(processor.ProcessorABC):\n         self.make_classifier_input
      = make_classifier_input\n         self.top_reconstruction_override = top_reconstruction_override\n         self.subtract_ttbar_with_weights
      = subtract_ttbar_with_weights\n-        self.isSyntheticData = isSyntheticData\n         self.friend_trigWeight
      = friend_trigWeight\n \n         if self.friend_trigWeight:\n@@ -134,6 +132,11
      @@ class analysis(processor.ProcessorABC):\n         self.isMixedData    = not
      (self.dataset.find("mix_v") == -1)\n         if self.isMixedData:\n             self.isMC
      = False\n+\n+        self.isSyntheticData  = not (self.dataset.find("syn_v")
      == -1)\n+        if self.isSyntheticData:\n+            self.isMC = False\n+\n         self.isDataForMixed
      = not (self.dataset.find("data_3b_for_mixed") == -1)\n         self.isTTForMixed   =
      not (self.dataset.find("TTTo") == -1) and not ( self.dataset.find("_for_mixed")
      == -1 )\n \n@@ -189,8 +192,8 @@ class analysis(processor.ProcessorABC):\n             self.do_lepton_jet_cleaning  =
      False\n \n \n-        logging.debug(f\''{self.chunk} isData={False}, isMC={self.isMC},
      isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed}, isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData},
      isPSData={self.isPSData} for file {fname}\\n\'')\n-        logging.debug(f\''{self.chunk}
      isMC {self.isMC}, isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n+        logging.info(f\''{self.chunk}
      isData={False}, isMC={self.isMC}, isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed},
      isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData}, isPSData={self.isPSData}
      for file {fname}\\n\'')\n+        logging.info(f\''{self.chunk} isMC {self.isMC},
      isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n
      \n \n \ndiff --git a/python/metadata/datasets_HH4b.yml b/python/metadata/datasets_HH4b.yml\nindex
      bda9189..4707db1 100644\n--- a/python/metadata/datasets_HH4b.yml\n+++ b/python/metadata/datasets_HH4b.yml\n@@
      -720,3 +720,48 @@ datasets:\n         files_template:\n         - root://cmseos.fnal.gov//store/user/jda102/condor/ZH4b/ULTrig/mixed2018_3bDvTMix4bDvT_vXXX/picoAOD_3bDvTMix4bDvT_4b_wJCM_vXXX_newSBDef.root\n     nSamples:
      15\n+\n+\n+\n+  synthetic_data:\n+    nSamples: 1\n+    UL16_postVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPF/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_postVFP/picoAOD_PSData.root      \n+          -
      /srv/python/skimmer/test/data_UL16_postVFPG/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPH/picoAOD_seedXXX.root\n+    UL16_preVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPB/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPC/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPD/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPE/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_preVFP/picoAOD_PSData.root      \n+    UL17:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL17C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17D/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL17E/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17F/picoAOD_seedXXX.root      \n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL17/picoAOD_PSData.root      \n+    UL18:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL18A/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18B/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL18C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18D/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL18/picoAOD_PSData.root      \n+\ndiff
      --git a/python/runner.py b/python/runner.py\nindex f6a92fa..a4dc28c 100644\n---
      a/python/runner.py\n+++ b/python/runner.py\n@@ -163,6 +163,7 @@ if __name__
      == \''__main__\'':\n \n     if \''all\'' in args.datasets:\n         metadata[\''datasets\''].pop("mixeddata")   #
      AGE: this is temporary\n+        metadata[\''datasets\''].pop("synthetic_data")   #
      AGE: this is temporary\n         metadata[\''datasets\''].pop("data_3b_for_mixed")   #
      AGE: this is temporary\n         args.datasets = metadata[\''datasets\''].keys()\n
      \n@@ -181,7 +182,7 @@ if __name__ == \''__main__\'':\n                     f"{year}
      name not in metadatafile for {dataset}")\n                 continue\n \n-            if
      dataset in [\''data\'', \''mixeddata\'', \''data_3b_for_mixed\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n+            if dataset in [\''data\'',
      \''mixeddata\'', \''data_3b_for_mixed\'', \''synthetic_data\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n                 xsec = 1.\n             elif
      isinstance(metadata[\''datasets\''][dataset][\''xs\''], float):\n                 xsec
      = metadata[\''datasets\''][dataset][\''xs\'']\n@@ -203,10 +204,11 @@ if __name__
      == \''__main__\'':\n                                          }\n             isData
      = (dataset == \''data\'')\n             isMixedData = (dataset == \''mixeddata\'')\n+            isSyntheticData
      = (dataset == \''synthetic_data\'')\n             isDataForMix = (dataset ==
      \''data_3b_for_mixed\'')\n             isTTForMixed = (dataset in [\''TTToHadronic_for_mixed\'',
      \''TTToSemiLeptonic_for_mixed\'', \''TTTo2L2Nu_for_mixed\''])\n \n-            if
      not ( isData or isMixedData or isDataForMix or isTTForMixed):\n+            if
      not ( isData or isSyntheticData or isMixedData or isDataForMix or isTTForMixed):\n                 logging.info("\\nConfig
      MC")\n                 if config_runner[\''data_tier\''].startswith(\''pico\''):\n                     if
      \''data\'' not in dataset:\n@@ -249,6 +251,31 @@ if __name__ == \''__main__\'':\n                     logging.info(\n                         f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n \n+            elif
      isSyntheticData:\n+                logging.info("\\nConfig Synthetic Data ")\n+\n+                nSyntheticSamples
      = metadata[\''datasets\''][dataset]["nSamples"]\n+                synthetic_config
      = metadata[\''datasets\''][dataset][year][config_runner[\''data_tier\'']]\n+                logging.info(f"\\nNumber
      of synthetic samples is {nSyntheticSamples}")\n+                for v in range(nSyntheticSamples):\n+\n+                    synthetic_name
      = f"syn_v{v}"\n+                    idataset = f\''{synthetic_name}_{year}\''\n+\n+                    metadata_dataset[idataset]
      = copy(metadata_dataset[dataset])\n+                    metadata_dataset[idataset][\''processName\'']
      = synthetic_name\n+                    # metadata_dataset[idataset][\''FvT_name\'']
      = synthetic_config[\''FvT_name_template\''].replace("XXX",str(v))\n+                    #
      metadata_dataset[idataset][\''FvT_file\''] = synthetic_config[\''FvT_file_template\''].replace("XXX",str(v))\n+                    synthetic_files
      = [f.replace("XXX",str(v)) for f in synthetic_config[\''files_template\'']]\n+                    fileset[idataset]
      = {\''files\'': list_of_files(synthetic_files,\n+                                                                test=args.test,
      test_files=config_runner[\''test_files\''],\n+                                                                allowlist_sites=config_runner[\''allowlist_sites\'']),\n+                                         \''metadata\'':
      metadata_dataset[idataset]}\n+\n+                    logging.info(\n+                        f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n+\n+\n             elif
      isDataForMix:\n                 logging.info("\\nConfig Data for Mixed ")\n
      \n'''
    hash: be7beff9ac9b123dfb8bdeb2581a74ef06734cdb
  saved_events: 23171
  source:
    root://cmseos.fnal.gov//store/user/algomez/XX4b/20231115/data2017F/picoAOD.root:
    - !!python/tuple
      - 0
      - 101464
    - !!python/tuple
      - 101464
      - 202928
    - !!python/tuple
      - 202928
      - 304392
    - !!python/tuple
      - 405856
      - 507320
    - !!python/tuple
      - 304392
      - 405856
    - !!python/tuple
      - 507320
      - 608784
    - !!python/tuple
      - 608784
      - 710245
  total_events: 710245
  total_jet: 138187
  xs:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
data_UL18A:
  count: 902005.0
  cutFlowFourTag:
    all: 901984.0
    passFourTag: 31913.0
    passFourTag_btagSF: 0
    passHLT: 858709.0
    passJetMult: 848300.0
    passNoiseFilter: 901227.0
    pass_ttbar_filter: 30014.0
  cutFlowFourTagUnitWeight:
    all: 901984
    passFourTag: 31913
    passFourTag_btagSF: 0
    passHLT: 858709
    passJetMult: 848300
    passNoiseFilter: 901227
    pass_ttbar_filter: 30014
  cutFlowThreeTag:
    all: 901984.0
    passFourTag: 31913.0
    passFourTag_btagSF: 0
    passHLT: 858709.0
    passJetMult: 848300.0
    passNoiseFilter: 901227.0
    pass_ttbar_filter: 30014.0
  cutFlowThreeTagUnitWeight:
    all: 901984
    passFourTag: 31913
    passFourTag_btagSF: 0
    passHLT: 858709
    passJetMult: 848300
    passNoiseFilter: 901227
    pass_ttbar_filter: 30014
  files:
  - root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/data_UL18A/picoAOD_seed0.root
  kFactor:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  lumi:
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  reproducible:
    args: Namespace(test=False, output_file='picoaod_datasets_declustered_data_Run2_seed0.yml',
      processor='skimmer/processor/make_declustered_data_4b.py', configs='skimmer/metadata/declustering_seed_0.yml',
      metadata='metadata/datasets_HH4b.yml', output_path='skimmer/metadata/', years=['UL17',
      'UL18', 'UL16_preVFP', 'UL16_postVFP'], datasets=['data'], era=['A', 'B', 'C',
      'D', 'E', 'F', 'G', 'H'], systematics=False, skimming=True, run_dask=False,
      condor=False, debug=False, githash='', gitdiff='')
    date: '2024-09-19 11:11:50'
    diff: 'b''diff --git a/.ci-workflows/synthetic-dataset-analyze-all.sh b/.ci-workflows/synthetic-dataset-analyze-all.sh\nindex
      40fa0ce..39596eb 100644\n--- a/.ci-workflows/synthetic-dataset-analyze-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-analyze-all.sh\n@@ -14,7 +14,9 @@ cd python/\n
      # fi\n # echo "############### Modifying dataset file with skimmer ci output"\n
      # cat metadata/datasets_ci.yml\n-python metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml
      -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml -o metadata/datasets_synthetic_seed0.yml\n+#python
      metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml
      -o metadata/datasets_synthetic_seed0.yml\n+\n+#python metadata/make_synthetic_yaml_datasets.py
      -m metadata/datasets_HH4b.yml -d skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed5.yml
      -o metadata/datasets_synthetic_seed0.yml\n \n # echo "############### Changing
      metadata"\n # sed -e "s/apply_FvT.*/apply_FvT: false/" -e "s/apply_trig.*/apply_trigWeight:
      false/" -e "s/run_SvB.*/run_SvB: false/"  analysis/metadata/HH4b.yml > analysis/metadata/tmp.yml\ndiff
      --git a/.ci-workflows/synthetic-dataset-make-dataset-all.sh b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\nindex
      37e4cd5..8b8f317 100644\n--- a/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n@@ -5,8 +5,13 @@ voms-proxy-info\n
      echo "############### Moving to python folder"\n cd python/\n echo "###############
      Running test processor"\n-time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering.yml -y UL17 UL18 UL16_preVFP UL16_postVFP -d
      data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed0.yml
      -m metadata/datasets_HH4b.yml   # --dask\n+\n+new_seed=0\n+\n+sed -e "s/declustering_rand_seed:
      [0-9]/declustering_rand_seed: $new_seed/" skimmer/metadata/declustering.yml
      > skimmer/metadata/declustering_seed_${new_seed}.yml\n+cat skimmer/metadata/declustering_seed_${new_seed}.yml\n+time
      python runner.py -s -p skimmer/processor/make_declustered_data_4b.py -c skimmer/metadata/declustering_seed_${new_seed}.yml
      -y UL17 UL18 UL16_preVFP UL16_postVFP -d data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed${new_seed}.yml
      -m metadata/datasets_HH4b.yml   # --dask\n # time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering_signal.yml -y UL17 UL18 UL16_preVFP UL16_postVFP
      -d GluGluToHHTo4B_cHHH1 -op skimmer/metadata/ -o picoaod_datasets_declustered_GluGluToHHTo4B_cHHH1_Run2_seed17.yml
      -m metadata/datasets_HH4b.yml\n \n-ls -R skimmer/\n+#ls -R skimmer/\n cd ../\ndiff
      --git a/python/analysis/metadata/HH4b_rerun_SvB.yml b/python/analysis/metadata/HH4b_rerun_SvB.yml\nindex
      7ea596b..8fbde86 100644\n--- a/python/analysis/metadata/HH4b_rerun_SvB.yml\n+++
      b/python/analysis/metadata/HH4b_rerun_SvB.yml\n@@ -6,7 +6,6 @@ config:\n   JCM:
      \''analysis/weights/JCM/2023/dataRunII/jetCombinatoricModel_SB_00-00-02.yml\''\n   blind:
      false\n   apply_FvT: false\n-  \n   apply_trigWeight: true\n   apply_btagSF:
      true\n   apply_boosted_veto: false\ndiff --git a/python/analysis/metadata/HH4b_synthetic_data.yml
      b/python/analysis/metadata/HH4b_synthetic_data.yml\nindex 0a930d7..8fbde86 100644\n---
      a/python/analysis/metadata/HH4b_synthetic_data.yml\n+++ b/python/analysis/metadata/HH4b_synthetic_data.yml\n@@
      -13,6 +13,6 @@ config:\n   run_systematics: false\n   SvB   : \''analysis/weights/pytorch_models/2024_HHUL/SvB_HCR_8_np753_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n   SvB_MA:
      \''analysis/weights/pytorch_models/2024_HHUL/SvB_MA_HCR+attention_8_np1061_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n-  top_reconstruction_override:
      "fast"\n-  isSyntheticData : True\n+  top_reconstruction_override: fast\n+\n   \ndiff
      --git a/python/analysis/processors/processor_HH4b.py b/python/analysis/processors/processor_HH4b.py\nindex
      a95e196..6201a25 100644\n--- a/python/analysis/processors/processor_HH4b.py\n+++
      b/python/analysis/processors/processor_HH4b.py\n@@ -60,7 +60,6 @@ class analysis(processor.ProcessorABC):\n         top_reconstruction_override:
      bool = False,\n         run_systematics: list = [],\n         make_classifier_input:
      str = None,\n-        isSyntheticData: bool = False,\n         subtract_ttbar_with_weights:
      bool = False,\n         friend_trigWeight: str = None,\n     ):\n@@ -84,7 +83,6
      @@ class analysis(processor.ProcessorABC):\n         self.make_classifier_input
      = make_classifier_input\n         self.top_reconstruction_override = top_reconstruction_override\n         self.subtract_ttbar_with_weights
      = subtract_ttbar_with_weights\n-        self.isSyntheticData = isSyntheticData\n         self.friend_trigWeight
      = friend_trigWeight\n \n         if self.friend_trigWeight:\n@@ -134,6 +132,11
      @@ class analysis(processor.ProcessorABC):\n         self.isMixedData    = not
      (self.dataset.find("mix_v") == -1)\n         if self.isMixedData:\n             self.isMC
      = False\n+\n+        self.isSyntheticData  = not (self.dataset.find("syn_v")
      == -1)\n+        if self.isSyntheticData:\n+            self.isMC = False\n+\n         self.isDataForMixed
      = not (self.dataset.find("data_3b_for_mixed") == -1)\n         self.isTTForMixed   =
      not (self.dataset.find("TTTo") == -1) and not ( self.dataset.find("_for_mixed")
      == -1 )\n \n@@ -189,8 +192,8 @@ class analysis(processor.ProcessorABC):\n             self.do_lepton_jet_cleaning  =
      False\n \n \n-        logging.debug(f\''{self.chunk} isData={False}, isMC={self.isMC},
      isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed}, isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData},
      isPSData={self.isPSData} for file {fname}\\n\'')\n-        logging.debug(f\''{self.chunk}
      isMC {self.isMC}, isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n+        logging.info(f\''{self.chunk}
      isData={False}, isMC={self.isMC}, isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed},
      isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData}, isPSData={self.isPSData}
      for file {fname}\\n\'')\n+        logging.info(f\''{self.chunk} isMC {self.isMC},
      isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n
      \n \n \ndiff --git a/python/metadata/datasets_HH4b.yml b/python/metadata/datasets_HH4b.yml\nindex
      bda9189..4707db1 100644\n--- a/python/metadata/datasets_HH4b.yml\n+++ b/python/metadata/datasets_HH4b.yml\n@@
      -720,3 +720,48 @@ datasets:\n         files_template:\n         - root://cmseos.fnal.gov//store/user/jda102/condor/ZH4b/ULTrig/mixed2018_3bDvTMix4bDvT_vXXX/picoAOD_3bDvTMix4bDvT_4b_wJCM_vXXX_newSBDef.root\n     nSamples:
      15\n+\n+\n+\n+  synthetic_data:\n+    nSamples: 1\n+    UL16_postVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPF/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_postVFP/picoAOD_PSData.root      \n+          -
      /srv/python/skimmer/test/data_UL16_postVFPG/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPH/picoAOD_seedXXX.root\n+    UL16_preVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPB/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPC/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPD/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPE/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_preVFP/picoAOD_PSData.root      \n+    UL17:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL17C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17D/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL17E/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17F/picoAOD_seedXXX.root      \n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL17/picoAOD_PSData.root      \n+    UL18:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL18A/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18B/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL18C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18D/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL18/picoAOD_PSData.root      \n+\ndiff
      --git a/python/runner.py b/python/runner.py\nindex f6a92fa..a4dc28c 100644\n---
      a/python/runner.py\n+++ b/python/runner.py\n@@ -163,6 +163,7 @@ if __name__
      == \''__main__\'':\n \n     if \''all\'' in args.datasets:\n         metadata[\''datasets\''].pop("mixeddata")   #
      AGE: this is temporary\n+        metadata[\''datasets\''].pop("synthetic_data")   #
      AGE: this is temporary\n         metadata[\''datasets\''].pop("data_3b_for_mixed")   #
      AGE: this is temporary\n         args.datasets = metadata[\''datasets\''].keys()\n
      \n@@ -181,7 +182,7 @@ if __name__ == \''__main__\'':\n                     f"{year}
      name not in metadatafile for {dataset}")\n                 continue\n \n-            if
      dataset in [\''data\'', \''mixeddata\'', \''data_3b_for_mixed\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n+            if dataset in [\''data\'',
      \''mixeddata\'', \''data_3b_for_mixed\'', \''synthetic_data\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n                 xsec = 1.\n             elif
      isinstance(metadata[\''datasets\''][dataset][\''xs\''], float):\n                 xsec
      = metadata[\''datasets\''][dataset][\''xs\'']\n@@ -203,10 +204,11 @@ if __name__
      == \''__main__\'':\n                                          }\n             isData
      = (dataset == \''data\'')\n             isMixedData = (dataset == \''mixeddata\'')\n+            isSyntheticData
      = (dataset == \''synthetic_data\'')\n             isDataForMix = (dataset ==
      \''data_3b_for_mixed\'')\n             isTTForMixed = (dataset in [\''TTToHadronic_for_mixed\'',
      \''TTToSemiLeptonic_for_mixed\'', \''TTTo2L2Nu_for_mixed\''])\n \n-            if
      not ( isData or isMixedData or isDataForMix or isTTForMixed):\n+            if
      not ( isData or isSyntheticData or isMixedData or isDataForMix or isTTForMixed):\n                 logging.info("\\nConfig
      MC")\n                 if config_runner[\''data_tier\''].startswith(\''pico\''):\n                     if
      \''data\'' not in dataset:\n@@ -249,6 +251,31 @@ if __name__ == \''__main__\'':\n                     logging.info(\n                         f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n \n+            elif
      isSyntheticData:\n+                logging.info("\\nConfig Synthetic Data ")\n+\n+                nSyntheticSamples
      = metadata[\''datasets\''][dataset]["nSamples"]\n+                synthetic_config
      = metadata[\''datasets\''][dataset][year][config_runner[\''data_tier\'']]\n+                logging.info(f"\\nNumber
      of synthetic samples is {nSyntheticSamples}")\n+                for v in range(nSyntheticSamples):\n+\n+                    synthetic_name
      = f"syn_v{v}"\n+                    idataset = f\''{synthetic_name}_{year}\''\n+\n+                    metadata_dataset[idataset]
      = copy(metadata_dataset[dataset])\n+                    metadata_dataset[idataset][\''processName\'']
      = synthetic_name\n+                    # metadata_dataset[idataset][\''FvT_name\'']
      = synthetic_config[\''FvT_name_template\''].replace("XXX",str(v))\n+                    #
      metadata_dataset[idataset][\''FvT_file\''] = synthetic_config[\''FvT_file_template\''].replace("XXX",str(v))\n+                    synthetic_files
      = [f.replace("XXX",str(v)) for f in synthetic_config[\''files_template\'']]\n+                    fileset[idataset]
      = {\''files\'': list_of_files(synthetic_files,\n+                                                                test=args.test,
      test_files=config_runner[\''test_files\''],\n+                                                                allowlist_sites=config_runner[\''allowlist_sites\'']),\n+                                         \''metadata\'':
      metadata_dataset[idataset]}\n+\n+                    logging.info(\n+                        f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n+\n+\n             elif
      isDataForMix:\n                 logging.info("\\nConfig Data for Mixed ")\n
      \n'''
    hash: be7beff9ac9b123dfb8bdeb2581a74ef06734cdb
  saved_events: 30014
  source:
    root://cmseos.fnal.gov//store/user/algomez/XX4b/20231115/data2018A/picoAOD.root:
    - !!python/tuple
      - 0
      - 100223
    - !!python/tuple
      - 100223
      - 200446
    - !!python/tuple
      - 200446
      - 300669
    - !!python/tuple
      - 300669
      - 400892
    - !!python/tuple
      - 400892
      - 501115
    - !!python/tuple
      - 501115
      - 601338
    - !!python/tuple
      - 601338
      - 701561
    - !!python/tuple
      - 701561
      - 801784
    - !!python/tuple
      - 801784
      - 902005
  total_events: 902005
  total_jet: 182892
  xs:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
data_UL18B:
  count: 448667.0
  cutFlowFourTag:
    all: 448667.0
    passFourTag: 15420.0
    passFourTag_btagSF: 0
    passHLT: 412800.0
    passJetMult: 407860.0
    passNoiseFilter: 448317.0
    pass_ttbar_filter: 14420.0
  cutFlowFourTagUnitWeight:
    all: 448667
    passFourTag: 15420
    passFourTag_btagSF: 0
    passHLT: 412800
    passJetMult: 407860
    passNoiseFilter: 448317
    pass_ttbar_filter: 14420
  cutFlowThreeTag:
    all: 448667.0
    passFourTag: 15420.0
    passFourTag_btagSF: 0
    passHLT: 412800.0
    passJetMult: 407860.0
    passNoiseFilter: 448317.0
    pass_ttbar_filter: 14420.0
  cutFlowThreeTagUnitWeight:
    all: 448667
    passFourTag: 15420
    passFourTag_btagSF: 0
    passHLT: 412800
    passJetMult: 407860
    passNoiseFilter: 448317
    pass_ttbar_filter: 14420
  files:
  - root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/data_UL18B/picoAOD_seed0.root
  kFactor:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  lumi:
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  reproducible:
    args: Namespace(test=False, output_file='picoaod_datasets_declustered_data_Run2_seed0.yml',
      processor='skimmer/processor/make_declustered_data_4b.py', configs='skimmer/metadata/declustering_seed_0.yml',
      metadata='metadata/datasets_HH4b.yml', output_path='skimmer/metadata/', years=['UL17',
      'UL18', 'UL16_preVFP', 'UL16_postVFP'], datasets=['data'], era=['A', 'B', 'C',
      'D', 'E', 'F', 'G', 'H'], systematics=False, skimming=True, run_dask=False,
      condor=False, debug=False, githash='', gitdiff='')
    date: '2024-09-19 11:11:50'
    diff: 'b''diff --git a/.ci-workflows/synthetic-dataset-analyze-all.sh b/.ci-workflows/synthetic-dataset-analyze-all.sh\nindex
      40fa0ce..39596eb 100644\n--- a/.ci-workflows/synthetic-dataset-analyze-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-analyze-all.sh\n@@ -14,7 +14,9 @@ cd python/\n
      # fi\n # echo "############### Modifying dataset file with skimmer ci output"\n
      # cat metadata/datasets_ci.yml\n-python metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml
      -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml -o metadata/datasets_synthetic_seed0.yml\n+#python
      metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml
      -o metadata/datasets_synthetic_seed0.yml\n+\n+#python metadata/make_synthetic_yaml_datasets.py
      -m metadata/datasets_HH4b.yml -d skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed5.yml
      -o metadata/datasets_synthetic_seed0.yml\n \n # echo "############### Changing
      metadata"\n # sed -e "s/apply_FvT.*/apply_FvT: false/" -e "s/apply_trig.*/apply_trigWeight:
      false/" -e "s/run_SvB.*/run_SvB: false/"  analysis/metadata/HH4b.yml > analysis/metadata/tmp.yml\ndiff
      --git a/.ci-workflows/synthetic-dataset-make-dataset-all.sh b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\nindex
      37e4cd5..8b8f317 100644\n--- a/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n@@ -5,8 +5,13 @@ voms-proxy-info\n
      echo "############### Moving to python folder"\n cd python/\n echo "###############
      Running test processor"\n-time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering.yml -y UL17 UL18 UL16_preVFP UL16_postVFP -d
      data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed0.yml
      -m metadata/datasets_HH4b.yml   # --dask\n+\n+new_seed=0\n+\n+sed -e "s/declustering_rand_seed:
      [0-9]/declustering_rand_seed: $new_seed/" skimmer/metadata/declustering.yml
      > skimmer/metadata/declustering_seed_${new_seed}.yml\n+cat skimmer/metadata/declustering_seed_${new_seed}.yml\n+time
      python runner.py -s -p skimmer/processor/make_declustered_data_4b.py -c skimmer/metadata/declustering_seed_${new_seed}.yml
      -y UL17 UL18 UL16_preVFP UL16_postVFP -d data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed${new_seed}.yml
      -m metadata/datasets_HH4b.yml   # --dask\n # time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering_signal.yml -y UL17 UL18 UL16_preVFP UL16_postVFP
      -d GluGluToHHTo4B_cHHH1 -op skimmer/metadata/ -o picoaod_datasets_declustered_GluGluToHHTo4B_cHHH1_Run2_seed17.yml
      -m metadata/datasets_HH4b.yml\n \n-ls -R skimmer/\n+#ls -R skimmer/\n cd ../\ndiff
      --git a/python/analysis/metadata/HH4b_rerun_SvB.yml b/python/analysis/metadata/HH4b_rerun_SvB.yml\nindex
      7ea596b..8fbde86 100644\n--- a/python/analysis/metadata/HH4b_rerun_SvB.yml\n+++
      b/python/analysis/metadata/HH4b_rerun_SvB.yml\n@@ -6,7 +6,6 @@ config:\n   JCM:
      \''analysis/weights/JCM/2023/dataRunII/jetCombinatoricModel_SB_00-00-02.yml\''\n   blind:
      false\n   apply_FvT: false\n-  \n   apply_trigWeight: true\n   apply_btagSF:
      true\n   apply_boosted_veto: false\ndiff --git a/python/analysis/metadata/HH4b_synthetic_data.yml
      b/python/analysis/metadata/HH4b_synthetic_data.yml\nindex 0a930d7..8fbde86 100644\n---
      a/python/analysis/metadata/HH4b_synthetic_data.yml\n+++ b/python/analysis/metadata/HH4b_synthetic_data.yml\n@@
      -13,6 +13,6 @@ config:\n   run_systematics: false\n   SvB   : \''analysis/weights/pytorch_models/2024_HHUL/SvB_HCR_8_np753_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n   SvB_MA:
      \''analysis/weights/pytorch_models/2024_HHUL/SvB_MA_HCR+attention_8_np1061_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n-  top_reconstruction_override:
      "fast"\n-  isSyntheticData : True\n+  top_reconstruction_override: fast\n+\n   \ndiff
      --git a/python/analysis/processors/processor_HH4b.py b/python/analysis/processors/processor_HH4b.py\nindex
      a95e196..6201a25 100644\n--- a/python/analysis/processors/processor_HH4b.py\n+++
      b/python/analysis/processors/processor_HH4b.py\n@@ -60,7 +60,6 @@ class analysis(processor.ProcessorABC):\n         top_reconstruction_override:
      bool = False,\n         run_systematics: list = [],\n         make_classifier_input:
      str = None,\n-        isSyntheticData: bool = False,\n         subtract_ttbar_with_weights:
      bool = False,\n         friend_trigWeight: str = None,\n     ):\n@@ -84,7 +83,6
      @@ class analysis(processor.ProcessorABC):\n         self.make_classifier_input
      = make_classifier_input\n         self.top_reconstruction_override = top_reconstruction_override\n         self.subtract_ttbar_with_weights
      = subtract_ttbar_with_weights\n-        self.isSyntheticData = isSyntheticData\n         self.friend_trigWeight
      = friend_trigWeight\n \n         if self.friend_trigWeight:\n@@ -134,6 +132,11
      @@ class analysis(processor.ProcessorABC):\n         self.isMixedData    = not
      (self.dataset.find("mix_v") == -1)\n         if self.isMixedData:\n             self.isMC
      = False\n+\n+        self.isSyntheticData  = not (self.dataset.find("syn_v")
      == -1)\n+        if self.isSyntheticData:\n+            self.isMC = False\n+\n         self.isDataForMixed
      = not (self.dataset.find("data_3b_for_mixed") == -1)\n         self.isTTForMixed   =
      not (self.dataset.find("TTTo") == -1) and not ( self.dataset.find("_for_mixed")
      == -1 )\n \n@@ -189,8 +192,8 @@ class analysis(processor.ProcessorABC):\n             self.do_lepton_jet_cleaning  =
      False\n \n \n-        logging.debug(f\''{self.chunk} isData={False}, isMC={self.isMC},
      isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed}, isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData},
      isPSData={self.isPSData} for file {fname}\\n\'')\n-        logging.debug(f\''{self.chunk}
      isMC {self.isMC}, isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n+        logging.info(f\''{self.chunk}
      isData={False}, isMC={self.isMC}, isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed},
      isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData}, isPSData={self.isPSData}
      for file {fname}\\n\'')\n+        logging.info(f\''{self.chunk} isMC {self.isMC},
      isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n
      \n \n \ndiff --git a/python/metadata/datasets_HH4b.yml b/python/metadata/datasets_HH4b.yml\nindex
      bda9189..4707db1 100644\n--- a/python/metadata/datasets_HH4b.yml\n+++ b/python/metadata/datasets_HH4b.yml\n@@
      -720,3 +720,48 @@ datasets:\n         files_template:\n         - root://cmseos.fnal.gov//store/user/jda102/condor/ZH4b/ULTrig/mixed2018_3bDvTMix4bDvT_vXXX/picoAOD_3bDvTMix4bDvT_4b_wJCM_vXXX_newSBDef.root\n     nSamples:
      15\n+\n+\n+\n+  synthetic_data:\n+    nSamples: 1\n+    UL16_postVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPF/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_postVFP/picoAOD_PSData.root      \n+          -
      /srv/python/skimmer/test/data_UL16_postVFPG/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPH/picoAOD_seedXXX.root\n+    UL16_preVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPB/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPC/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPD/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPE/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_preVFP/picoAOD_PSData.root      \n+    UL17:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL17C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17D/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL17E/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17F/picoAOD_seedXXX.root      \n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL17/picoAOD_PSData.root      \n+    UL18:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL18A/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18B/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL18C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18D/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL18/picoAOD_PSData.root      \n+\ndiff
      --git a/python/runner.py b/python/runner.py\nindex f6a92fa..a4dc28c 100644\n---
      a/python/runner.py\n+++ b/python/runner.py\n@@ -163,6 +163,7 @@ if __name__
      == \''__main__\'':\n \n     if \''all\'' in args.datasets:\n         metadata[\''datasets\''].pop("mixeddata")   #
      AGE: this is temporary\n+        metadata[\''datasets\''].pop("synthetic_data")   #
      AGE: this is temporary\n         metadata[\''datasets\''].pop("data_3b_for_mixed")   #
      AGE: this is temporary\n         args.datasets = metadata[\''datasets\''].keys()\n
      \n@@ -181,7 +182,7 @@ if __name__ == \''__main__\'':\n                     f"{year}
      name not in metadatafile for {dataset}")\n                 continue\n \n-            if
      dataset in [\''data\'', \''mixeddata\'', \''data_3b_for_mixed\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n+            if dataset in [\''data\'',
      \''mixeddata\'', \''data_3b_for_mixed\'', \''synthetic_data\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n                 xsec = 1.\n             elif
      isinstance(metadata[\''datasets\''][dataset][\''xs\''], float):\n                 xsec
      = metadata[\''datasets\''][dataset][\''xs\'']\n@@ -203,10 +204,11 @@ if __name__
      == \''__main__\'':\n                                          }\n             isData
      = (dataset == \''data\'')\n             isMixedData = (dataset == \''mixeddata\'')\n+            isSyntheticData
      = (dataset == \''synthetic_data\'')\n             isDataForMix = (dataset ==
      \''data_3b_for_mixed\'')\n             isTTForMixed = (dataset in [\''TTToHadronic_for_mixed\'',
      \''TTToSemiLeptonic_for_mixed\'', \''TTTo2L2Nu_for_mixed\''])\n \n-            if
      not ( isData or isMixedData or isDataForMix or isTTForMixed):\n+            if
      not ( isData or isSyntheticData or isMixedData or isDataForMix or isTTForMixed):\n                 logging.info("\\nConfig
      MC")\n                 if config_runner[\''data_tier\''].startswith(\''pico\''):\n                     if
      \''data\'' not in dataset:\n@@ -249,6 +251,31 @@ if __name__ == \''__main__\'':\n                     logging.info(\n                         f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n \n+            elif
      isSyntheticData:\n+                logging.info("\\nConfig Synthetic Data ")\n+\n+                nSyntheticSamples
      = metadata[\''datasets\''][dataset]["nSamples"]\n+                synthetic_config
      = metadata[\''datasets\''][dataset][year][config_runner[\''data_tier\'']]\n+                logging.info(f"\\nNumber
      of synthetic samples is {nSyntheticSamples}")\n+                for v in range(nSyntheticSamples):\n+\n+                    synthetic_name
      = f"syn_v{v}"\n+                    idataset = f\''{synthetic_name}_{year}\''\n+\n+                    metadata_dataset[idataset]
      = copy(metadata_dataset[dataset])\n+                    metadata_dataset[idataset][\''processName\'']
      = synthetic_name\n+                    # metadata_dataset[idataset][\''FvT_name\'']
      = synthetic_config[\''FvT_name_template\''].replace("XXX",str(v))\n+                    #
      metadata_dataset[idataset][\''FvT_file\''] = synthetic_config[\''FvT_file_template\''].replace("XXX",str(v))\n+                    synthetic_files
      = [f.replace("XXX",str(v)) for f in synthetic_config[\''files_template\'']]\n+                    fileset[idataset]
      = {\''files\'': list_of_files(synthetic_files,\n+                                                                test=args.test,
      test_files=config_runner[\''test_files\''],\n+                                                                allowlist_sites=config_runner[\''allowlist_sites\'']),\n+                                         \''metadata\'':
      metadata_dataset[idataset]}\n+\n+                    logging.info(\n+                        f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n+\n+\n             elif
      isDataForMix:\n                 logging.info("\\nConfig Data for Mixed ")\n
      \n'''
    hash: be7beff9ac9b123dfb8bdeb2581a74ef06734cdb
  saved_events: 14420
  source:
    root://cmseos.fnal.gov//store/user/algomez/XX4b/20231115/data2018B/picoAOD.root:
    - !!python/tuple
      - 0
      - 112167
    - !!python/tuple
      - 112167
      - 224334
    - !!python/tuple
      - 224334
      - 336501
    - !!python/tuple
      - 336501
      - 448667
  total_events: 448667
  total_jet: 88068
  xs:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
data_UL18C:
  count: 418436.0
  cutFlowFourTag:
    all: 418436.0
    passFourTag: 14387.0
    passFourTag_btagSF: 0
    passHLT: 384550.0
    passJetMult: 379920.0
    passNoiseFilter: 418098.0
    pass_ttbar_filter: 13432.0
  cutFlowFourTagUnitWeight:
    all: 418436
    passFourTag: 14387
    passFourTag_btagSF: 0
    passHLT: 384550
    passJetMult: 379920
    passNoiseFilter: 418098
    pass_ttbar_filter: 13432
  cutFlowThreeTag:
    all: 418436.0
    passFourTag: 14387.0
    passFourTag_btagSF: 0
    passHLT: 384550.0
    passJetMult: 379920.0
    passNoiseFilter: 418098.0
    pass_ttbar_filter: 13432.0
  cutFlowThreeTagUnitWeight:
    all: 418436
    passFourTag: 14387
    passFourTag_btagSF: 0
    passHLT: 384550
    passJetMult: 379920
    passNoiseFilter: 418098
    pass_ttbar_filter: 13432
  files:
  - root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/data_UL18C/picoAOD_seed0.root
  kFactor:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  lumi:
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  reproducible:
    args: Namespace(test=False, output_file='picoaod_datasets_declustered_data_Run2_seed0.yml',
      processor='skimmer/processor/make_declustered_data_4b.py', configs='skimmer/metadata/declustering_seed_0.yml',
      metadata='metadata/datasets_HH4b.yml', output_path='skimmer/metadata/', years=['UL17',
      'UL18', 'UL16_preVFP', 'UL16_postVFP'], datasets=['data'], era=['A', 'B', 'C',
      'D', 'E', 'F', 'G', 'H'], systematics=False, skimming=True, run_dask=False,
      condor=False, debug=False, githash='', gitdiff='')
    date: '2024-09-19 11:11:50'
    diff: 'b''diff --git a/.ci-workflows/synthetic-dataset-analyze-all.sh b/.ci-workflows/synthetic-dataset-analyze-all.sh\nindex
      40fa0ce..39596eb 100644\n--- a/.ci-workflows/synthetic-dataset-analyze-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-analyze-all.sh\n@@ -14,7 +14,9 @@ cd python/\n
      # fi\n # echo "############### Modifying dataset file with skimmer ci output"\n
      # cat metadata/datasets_ci.yml\n-python metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml
      -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml -o metadata/datasets_synthetic_seed0.yml\n+#python
      metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml
      -o metadata/datasets_synthetic_seed0.yml\n+\n+#python metadata/make_synthetic_yaml_datasets.py
      -m metadata/datasets_HH4b.yml -d skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed5.yml
      -o metadata/datasets_synthetic_seed0.yml\n \n # echo "############### Changing
      metadata"\n # sed -e "s/apply_FvT.*/apply_FvT: false/" -e "s/apply_trig.*/apply_trigWeight:
      false/" -e "s/run_SvB.*/run_SvB: false/"  analysis/metadata/HH4b.yml > analysis/metadata/tmp.yml\ndiff
      --git a/.ci-workflows/synthetic-dataset-make-dataset-all.sh b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\nindex
      37e4cd5..8b8f317 100644\n--- a/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n@@ -5,8 +5,13 @@ voms-proxy-info\n
      echo "############### Moving to python folder"\n cd python/\n echo "###############
      Running test processor"\n-time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering.yml -y UL17 UL18 UL16_preVFP UL16_postVFP -d
      data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed0.yml
      -m metadata/datasets_HH4b.yml   # --dask\n+\n+new_seed=0\n+\n+sed -e "s/declustering_rand_seed:
      [0-9]/declustering_rand_seed: $new_seed/" skimmer/metadata/declustering.yml
      > skimmer/metadata/declustering_seed_${new_seed}.yml\n+cat skimmer/metadata/declustering_seed_${new_seed}.yml\n+time
      python runner.py -s -p skimmer/processor/make_declustered_data_4b.py -c skimmer/metadata/declustering_seed_${new_seed}.yml
      -y UL17 UL18 UL16_preVFP UL16_postVFP -d data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed${new_seed}.yml
      -m metadata/datasets_HH4b.yml   # --dask\n # time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering_signal.yml -y UL17 UL18 UL16_preVFP UL16_postVFP
      -d GluGluToHHTo4B_cHHH1 -op skimmer/metadata/ -o picoaod_datasets_declustered_GluGluToHHTo4B_cHHH1_Run2_seed17.yml
      -m metadata/datasets_HH4b.yml\n \n-ls -R skimmer/\n+#ls -R skimmer/\n cd ../\ndiff
      --git a/python/analysis/metadata/HH4b_rerun_SvB.yml b/python/analysis/metadata/HH4b_rerun_SvB.yml\nindex
      7ea596b..8fbde86 100644\n--- a/python/analysis/metadata/HH4b_rerun_SvB.yml\n+++
      b/python/analysis/metadata/HH4b_rerun_SvB.yml\n@@ -6,7 +6,6 @@ config:\n   JCM:
      \''analysis/weights/JCM/2023/dataRunII/jetCombinatoricModel_SB_00-00-02.yml\''\n   blind:
      false\n   apply_FvT: false\n-  \n   apply_trigWeight: true\n   apply_btagSF:
      true\n   apply_boosted_veto: false\ndiff --git a/python/analysis/metadata/HH4b_synthetic_data.yml
      b/python/analysis/metadata/HH4b_synthetic_data.yml\nindex 0a930d7..8fbde86 100644\n---
      a/python/analysis/metadata/HH4b_synthetic_data.yml\n+++ b/python/analysis/metadata/HH4b_synthetic_data.yml\n@@
      -13,6 +13,6 @@ config:\n   run_systematics: false\n   SvB   : \''analysis/weights/pytorch_models/2024_HHUL/SvB_HCR_8_np753_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n   SvB_MA:
      \''analysis/weights/pytorch_models/2024_HHUL/SvB_MA_HCR+attention_8_np1061_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n-  top_reconstruction_override:
      "fast"\n-  isSyntheticData : True\n+  top_reconstruction_override: fast\n+\n   \ndiff
      --git a/python/analysis/processors/processor_HH4b.py b/python/analysis/processors/processor_HH4b.py\nindex
      a95e196..6201a25 100644\n--- a/python/analysis/processors/processor_HH4b.py\n+++
      b/python/analysis/processors/processor_HH4b.py\n@@ -60,7 +60,6 @@ class analysis(processor.ProcessorABC):\n         top_reconstruction_override:
      bool = False,\n         run_systematics: list = [],\n         make_classifier_input:
      str = None,\n-        isSyntheticData: bool = False,\n         subtract_ttbar_with_weights:
      bool = False,\n         friend_trigWeight: str = None,\n     ):\n@@ -84,7 +83,6
      @@ class analysis(processor.ProcessorABC):\n         self.make_classifier_input
      = make_classifier_input\n         self.top_reconstruction_override = top_reconstruction_override\n         self.subtract_ttbar_with_weights
      = subtract_ttbar_with_weights\n-        self.isSyntheticData = isSyntheticData\n         self.friend_trigWeight
      = friend_trigWeight\n \n         if self.friend_trigWeight:\n@@ -134,6 +132,11
      @@ class analysis(processor.ProcessorABC):\n         self.isMixedData    = not
      (self.dataset.find("mix_v") == -1)\n         if self.isMixedData:\n             self.isMC
      = False\n+\n+        self.isSyntheticData  = not (self.dataset.find("syn_v")
      == -1)\n+        if self.isSyntheticData:\n+            self.isMC = False\n+\n         self.isDataForMixed
      = not (self.dataset.find("data_3b_for_mixed") == -1)\n         self.isTTForMixed   =
      not (self.dataset.find("TTTo") == -1) and not ( self.dataset.find("_for_mixed")
      == -1 )\n \n@@ -189,8 +192,8 @@ class analysis(processor.ProcessorABC):\n             self.do_lepton_jet_cleaning  =
      False\n \n \n-        logging.debug(f\''{self.chunk} isData={False}, isMC={self.isMC},
      isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed}, isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData},
      isPSData={self.isPSData} for file {fname}\\n\'')\n-        logging.debug(f\''{self.chunk}
      isMC {self.isMC}, isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n+        logging.info(f\''{self.chunk}
      isData={False}, isMC={self.isMC}, isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed},
      isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData}, isPSData={self.isPSData}
      for file {fname}\\n\'')\n+        logging.info(f\''{self.chunk} isMC {self.isMC},
      isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n
      \n \n \ndiff --git a/python/metadata/datasets_HH4b.yml b/python/metadata/datasets_HH4b.yml\nindex
      bda9189..4707db1 100644\n--- a/python/metadata/datasets_HH4b.yml\n+++ b/python/metadata/datasets_HH4b.yml\n@@
      -720,3 +720,48 @@ datasets:\n         files_template:\n         - root://cmseos.fnal.gov//store/user/jda102/condor/ZH4b/ULTrig/mixed2018_3bDvTMix4bDvT_vXXX/picoAOD_3bDvTMix4bDvT_4b_wJCM_vXXX_newSBDef.root\n     nSamples:
      15\n+\n+\n+\n+  synthetic_data:\n+    nSamples: 1\n+    UL16_postVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPF/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_postVFP/picoAOD_PSData.root      \n+          -
      /srv/python/skimmer/test/data_UL16_postVFPG/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPH/picoAOD_seedXXX.root\n+    UL16_preVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPB/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPC/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPD/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPE/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_preVFP/picoAOD_PSData.root      \n+    UL17:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL17C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17D/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL17E/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17F/picoAOD_seedXXX.root      \n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL17/picoAOD_PSData.root      \n+    UL18:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL18A/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18B/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL18C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18D/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL18/picoAOD_PSData.root      \n+\ndiff
      --git a/python/runner.py b/python/runner.py\nindex f6a92fa..a4dc28c 100644\n---
      a/python/runner.py\n+++ b/python/runner.py\n@@ -163,6 +163,7 @@ if __name__
      == \''__main__\'':\n \n     if \''all\'' in args.datasets:\n         metadata[\''datasets\''].pop("mixeddata")   #
      AGE: this is temporary\n+        metadata[\''datasets\''].pop("synthetic_data")   #
      AGE: this is temporary\n         metadata[\''datasets\''].pop("data_3b_for_mixed")   #
      AGE: this is temporary\n         args.datasets = metadata[\''datasets\''].keys()\n
      \n@@ -181,7 +182,7 @@ if __name__ == \''__main__\'':\n                     f"{year}
      name not in metadatafile for {dataset}")\n                 continue\n \n-            if
      dataset in [\''data\'', \''mixeddata\'', \''data_3b_for_mixed\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n+            if dataset in [\''data\'',
      \''mixeddata\'', \''data_3b_for_mixed\'', \''synthetic_data\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n                 xsec = 1.\n             elif
      isinstance(metadata[\''datasets\''][dataset][\''xs\''], float):\n                 xsec
      = metadata[\''datasets\''][dataset][\''xs\'']\n@@ -203,10 +204,11 @@ if __name__
      == \''__main__\'':\n                                          }\n             isData
      = (dataset == \''data\'')\n             isMixedData = (dataset == \''mixeddata\'')\n+            isSyntheticData
      = (dataset == \''synthetic_data\'')\n             isDataForMix = (dataset ==
      \''data_3b_for_mixed\'')\n             isTTForMixed = (dataset in [\''TTToHadronic_for_mixed\'',
      \''TTToSemiLeptonic_for_mixed\'', \''TTTo2L2Nu_for_mixed\''])\n \n-            if
      not ( isData or isMixedData or isDataForMix or isTTForMixed):\n+            if
      not ( isData or isSyntheticData or isMixedData or isDataForMix or isTTForMixed):\n                 logging.info("\\nConfig
      MC")\n                 if config_runner[\''data_tier\''].startswith(\''pico\''):\n                     if
      \''data\'' not in dataset:\n@@ -249,6 +251,31 @@ if __name__ == \''__main__\'':\n                     logging.info(\n                         f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n \n+            elif
      isSyntheticData:\n+                logging.info("\\nConfig Synthetic Data ")\n+\n+                nSyntheticSamples
      = metadata[\''datasets\''][dataset]["nSamples"]\n+                synthetic_config
      = metadata[\''datasets\''][dataset][year][config_runner[\''data_tier\'']]\n+                logging.info(f"\\nNumber
      of synthetic samples is {nSyntheticSamples}")\n+                for v in range(nSyntheticSamples):\n+\n+                    synthetic_name
      = f"syn_v{v}"\n+                    idataset = f\''{synthetic_name}_{year}\''\n+\n+                    metadata_dataset[idataset]
      = copy(metadata_dataset[dataset])\n+                    metadata_dataset[idataset][\''processName\'']
      = synthetic_name\n+                    # metadata_dataset[idataset][\''FvT_name\'']
      = synthetic_config[\''FvT_name_template\''].replace("XXX",str(v))\n+                    #
      metadata_dataset[idataset][\''FvT_file\''] = synthetic_config[\''FvT_file_template\''].replace("XXX",str(v))\n+                    synthetic_files
      = [f.replace("XXX",str(v)) for f in synthetic_config[\''files_template\'']]\n+                    fileset[idataset]
      = {\''files\'': list_of_files(synthetic_files,\n+                                                                test=args.test,
      test_files=config_runner[\''test_files\''],\n+                                                                allowlist_sites=config_runner[\''allowlist_sites\'']),\n+                                         \''metadata\'':
      metadata_dataset[idataset]}\n+\n+                    logging.info(\n+                        f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n+\n+\n             elif
      isDataForMix:\n                 logging.info("\\nConfig Data for Mixed ")\n
      \n'''
    hash: be7beff9ac9b123dfb8bdeb2581a74ef06734cdb
  saved_events: 13432
  source:
    root://cmseos.fnal.gov//store/user/algomez/XX4b/20231115/data2018C/picoAOD.root:
    - !!python/tuple
      - 0
      - 104609
    - !!python/tuple
      - 104609
      - 209218
    - !!python/tuple
      - 209218
      - 313827
    - !!python/tuple
      - 313827
      - 418436
  total_events: 418436
  total_jet: 82111
  xs:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
data_UL18D:
  count: 1874829.0
  cutFlowFourTag:
    all: 1874829.0
    passFourTag: 62950.0
    passFourTag_btagSF: 0
    passHLT: 1719804.0
    passJetMult: 1690251.0
    passNoiseFilter: 1871407.0
    pass_ttbar_filter: 58844.0
  cutFlowFourTagUnitWeight:
    all: 1874829
    passFourTag: 62950
    passFourTag_btagSF: 0
    passHLT: 1719804
    passJetMult: 1690251
    passNoiseFilter: 1871407
    pass_ttbar_filter: 58844
  cutFlowThreeTag:
    all: 1874829.0
    passFourTag: 62950.0
    passFourTag_btagSF: 0
    passHLT: 1719804.0
    passJetMult: 1690251.0
    passNoiseFilter: 1871407.0
    pass_ttbar_filter: 58844.0
  cutFlowThreeTagUnitWeight:
    all: 1874829
    passFourTag: 62950
    passFourTag_btagSF: 0
    passHLT: 1719804
    passJetMult: 1690251
    passNoiseFilter: 1871407
    pass_ttbar_filter: 58844
  files:
  - root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/data_UL18D/picoAOD_seed0.root
  kFactor:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  lumi:
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  - 59800.0
  reproducible:
    args: Namespace(test=False, output_file='picoaod_datasets_declustered_data_Run2_seed0.yml',
      processor='skimmer/processor/make_declustered_data_4b.py', configs='skimmer/metadata/declustering_seed_0.yml',
      metadata='metadata/datasets_HH4b.yml', output_path='skimmer/metadata/', years=['UL17',
      'UL18', 'UL16_preVFP', 'UL16_postVFP'], datasets=['data'], era=['A', 'B', 'C',
      'D', 'E', 'F', 'G', 'H'], systematics=False, skimming=True, run_dask=False,
      condor=False, debug=False, githash='', gitdiff='')
    date: '2024-09-19 11:11:51'
    diff: 'b''diff --git a/.ci-workflows/synthetic-dataset-analyze-all.sh b/.ci-workflows/synthetic-dataset-analyze-all.sh\nindex
      40fa0ce..39596eb 100644\n--- a/.ci-workflows/synthetic-dataset-analyze-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-analyze-all.sh\n@@ -14,7 +14,9 @@ cd python/\n
      # fi\n # echo "############### Modifying dataset file with skimmer ci output"\n
      # cat metadata/datasets_ci.yml\n-python metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml
      -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml -o metadata/datasets_synthetic_seed0.yml\n+#python
      metadata/merge_yaml_datasets.py -m metadata/datasets_HH4b.yml -f skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed0.yml
      -o metadata/datasets_synthetic_seed0.yml\n+\n+#python metadata/make_synthetic_yaml_datasets.py
      -m metadata/datasets_HH4b.yml -d skimmer/metadata/picoaod_datasets_declustered_data_Run2_seed5.yml
      -o metadata/datasets_synthetic_seed0.yml\n \n # echo "############### Changing
      metadata"\n # sed -e "s/apply_FvT.*/apply_FvT: false/" -e "s/apply_trig.*/apply_trigWeight:
      false/" -e "s/run_SvB.*/run_SvB: false/"  analysis/metadata/HH4b.yml > analysis/metadata/tmp.yml\ndiff
      --git a/.ci-workflows/synthetic-dataset-make-dataset-all.sh b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\nindex
      37e4cd5..8b8f317 100644\n--- a/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n+++
      b/.ci-workflows/synthetic-dataset-make-dataset-all.sh\n@@ -5,8 +5,13 @@ voms-proxy-info\n
      echo "############### Moving to python folder"\n cd python/\n echo "###############
      Running test processor"\n-time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering.yml -y UL17 UL18 UL16_preVFP UL16_postVFP -d
      data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed0.yml
      -m metadata/datasets_HH4b.yml   # --dask\n+\n+new_seed=0\n+\n+sed -e "s/declustering_rand_seed:
      [0-9]/declustering_rand_seed: $new_seed/" skimmer/metadata/declustering.yml
      > skimmer/metadata/declustering_seed_${new_seed}.yml\n+cat skimmer/metadata/declustering_seed_${new_seed}.yml\n+time
      python runner.py -s -p skimmer/processor/make_declustered_data_4b.py -c skimmer/metadata/declustering_seed_${new_seed}.yml
      -y UL17 UL18 UL16_preVFP UL16_postVFP -d data -op skimmer/metadata/ -o picoaod_datasets_declustered_data_Run2_seed${new_seed}.yml
      -m metadata/datasets_HH4b.yml   # --dask\n # time python runner.py -s -p skimmer/processor/make_declustered_data_4b.py
      -c skimmer/metadata/declustering_signal.yml -y UL17 UL18 UL16_preVFP UL16_postVFP
      -d GluGluToHHTo4B_cHHH1 -op skimmer/metadata/ -o picoaod_datasets_declustered_GluGluToHHTo4B_cHHH1_Run2_seed17.yml
      -m metadata/datasets_HH4b.yml\n \n-ls -R skimmer/\n+#ls -R skimmer/\n cd ../\ndiff
      --git a/python/analysis/metadata/HH4b_rerun_SvB.yml b/python/analysis/metadata/HH4b_rerun_SvB.yml\nindex
      7ea596b..8fbde86 100644\n--- a/python/analysis/metadata/HH4b_rerun_SvB.yml\n+++
      b/python/analysis/metadata/HH4b_rerun_SvB.yml\n@@ -6,7 +6,6 @@ config:\n   JCM:
      \''analysis/weights/JCM/2023/dataRunII/jetCombinatoricModel_SB_00-00-02.yml\''\n   blind:
      false\n   apply_FvT: false\n-  \n   apply_trigWeight: true\n   apply_btagSF:
      true\n   apply_boosted_veto: false\ndiff --git a/python/analysis/metadata/HH4b_synthetic_data.yml
      b/python/analysis/metadata/HH4b_synthetic_data.yml\nindex 0a930d7..8fbde86 100644\n---
      a/python/analysis/metadata/HH4b_synthetic_data.yml\n+++ b/python/analysis/metadata/HH4b_synthetic_data.yml\n@@
      -13,6 +13,6 @@ config:\n   run_systematics: false\n   SvB   : \''analysis/weights/pytorch_models/2024_HHUL/SvB_HCR_8_np753_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n   SvB_MA:
      \''analysis/weights/pytorch_models/2024_HHUL/SvB_MA_HCR+attention_8_np1061_seed13_lr0.01_epochs20_offset*_epoch20.pkl\''\n-  top_reconstruction_override:
      "fast"\n-  isSyntheticData : True\n+  top_reconstruction_override: fast\n+\n   \ndiff
      --git a/python/analysis/processors/processor_HH4b.py b/python/analysis/processors/processor_HH4b.py\nindex
      a95e196..6201a25 100644\n--- a/python/analysis/processors/processor_HH4b.py\n+++
      b/python/analysis/processors/processor_HH4b.py\n@@ -60,7 +60,6 @@ class analysis(processor.ProcessorABC):\n         top_reconstruction_override:
      bool = False,\n         run_systematics: list = [],\n         make_classifier_input:
      str = None,\n-        isSyntheticData: bool = False,\n         subtract_ttbar_with_weights:
      bool = False,\n         friend_trigWeight: str = None,\n     ):\n@@ -84,7 +83,6
      @@ class analysis(processor.ProcessorABC):\n         self.make_classifier_input
      = make_classifier_input\n         self.top_reconstruction_override = top_reconstruction_override\n         self.subtract_ttbar_with_weights
      = subtract_ttbar_with_weights\n-        self.isSyntheticData = isSyntheticData\n         self.friend_trigWeight
      = friend_trigWeight\n \n         if self.friend_trigWeight:\n@@ -134,6 +132,11
      @@ class analysis(processor.ProcessorABC):\n         self.isMixedData    = not
      (self.dataset.find("mix_v") == -1)\n         if self.isMixedData:\n             self.isMC
      = False\n+\n+        self.isSyntheticData  = not (self.dataset.find("syn_v")
      == -1)\n+        if self.isSyntheticData:\n+            self.isMC = False\n+\n         self.isDataForMixed
      = not (self.dataset.find("data_3b_for_mixed") == -1)\n         self.isTTForMixed   =
      not (self.dataset.find("TTTo") == -1) and not ( self.dataset.find("_for_mixed")
      == -1 )\n \n@@ -189,8 +192,8 @@ class analysis(processor.ProcessorABC):\n             self.do_lepton_jet_cleaning  =
      False\n \n \n-        logging.debug(f\''{self.chunk} isData={False}, isMC={self.isMC},
      isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed}, isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData},
      isPSData={self.isPSData} for file {fname}\\n\'')\n-        logging.debug(f\''{self.chunk}
      isMC {self.isMC}, isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n+        logging.info(f\''{self.chunk}
      isData={False}, isMC={self.isMC}, isMixedData={self.isMixedData}, isDataForMixed={self.isDataForMixed},
      isTTForMixed={self.isTTForMixed},  isSyntheticData={self.isSyntheticData}, isPSData={self.isPSData}
      for file {fname}\\n\'')\n+        logging.info(f\''{self.chunk} isMC {self.isMC},
      isSyntheticData {self.isSyntheticData}, isPSData={self.isPSData}\\n\\n\'')\n
      \n \n \ndiff --git a/python/metadata/datasets_HH4b.yml b/python/metadata/datasets_HH4b.yml\nindex
      bda9189..4707db1 100644\n--- a/python/metadata/datasets_HH4b.yml\n+++ b/python/metadata/datasets_HH4b.yml\n@@
      -720,3 +720,48 @@ datasets:\n         files_template:\n         - root://cmseos.fnal.gov//store/user/jda102/condor/ZH4b/ULTrig/mixed2018_3bDvTMix4bDvT_vXXX/picoAOD_3bDvTMix4bDvT_4b_wJCM_vXXX_newSBDef.root\n     nSamples:
      15\n+\n+\n+\n+  synthetic_data:\n+    nSamples: 1\n+    UL16_postVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPF/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_postVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_postVFP/picoAOD_PSData.root      \n+          -
      /srv/python/skimmer/test/data_UL16_postVFPG/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_postVFPH/picoAOD_seedXXX.root\n+    UL16_preVFP:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPB/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPC/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPD/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL16_preVFPE/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL16_preVFP/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL16_preVFP/picoAOD_PSData.root      \n+    UL17:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL17C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17D/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL17E/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL17F/picoAOD_seedXXX.root      \n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL17/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL17/picoAOD_PSData.root      \n+    UL18:\n+      picoAOD:\n+        files_template:\n+          -
      /srv/python/skimmer/test/data_UL18A/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18B/picoAOD_seedXXX.root\n+          -
      /srv/python/skimmer/test/data_UL18C/picoAOD_seedXXX.root\n+          - /srv/python/skimmer/test/data_UL18D/picoAOD_seedXXX.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTTo2L2Nu_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToHadronic_UL18/picoAOD_PSData.root\n+          -
      root://cmseos.fnal.gov//store/user/jda102/XX4b/2024_v1/TTToSemiLeptonic_UL18/picoAOD_PSData.root      \n+\ndiff
      --git a/python/runner.py b/python/runner.py\nindex f6a92fa..a4dc28c 100644\n---
      a/python/runner.py\n+++ b/python/runner.py\n@@ -163,6 +163,7 @@ if __name__
      == \''__main__\'':\n \n     if \''all\'' in args.datasets:\n         metadata[\''datasets\''].pop("mixeddata")   #
      AGE: this is temporary\n+        metadata[\''datasets\''].pop("synthetic_data")   #
      AGE: this is temporary\n         metadata[\''datasets\''].pop("data_3b_for_mixed")   #
      AGE: this is temporary\n         args.datasets = metadata[\''datasets\''].keys()\n
      \n@@ -181,7 +182,7 @@ if __name__ == \''__main__\'':\n                     f"{year}
      name not in metadatafile for {dataset}")\n                 continue\n \n-            if
      dataset in [\''data\'', \''mixeddata\'', \''data_3b_for_mixed\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n+            if dataset in [\''data\'',
      \''mixeddata\'', \''data_3b_for_mixed\'', \''synthetic_data\''] or not (\''xs\''
      in metadata[\''datasets\''][dataset].keys()):\n                 xsec = 1.\n             elif
      isinstance(metadata[\''datasets\''][dataset][\''xs\''], float):\n                 xsec
      = metadata[\''datasets\''][dataset][\''xs\'']\n@@ -203,10 +204,11 @@ if __name__
      == \''__main__\'':\n                                          }\n             isData
      = (dataset == \''data\'')\n             isMixedData = (dataset == \''mixeddata\'')\n+            isSyntheticData
      = (dataset == \''synthetic_data\'')\n             isDataForMix = (dataset ==
      \''data_3b_for_mixed\'')\n             isTTForMixed = (dataset in [\''TTToHadronic_for_mixed\'',
      \''TTToSemiLeptonic_for_mixed\'', \''TTTo2L2Nu_for_mixed\''])\n \n-            if
      not ( isData or isMixedData or isDataForMix or isTTForMixed):\n+            if
      not ( isData or isSyntheticData or isMixedData or isDataForMix or isTTForMixed):\n                 logging.info("\\nConfig
      MC")\n                 if config_runner[\''data_tier\''].startswith(\''pico\''):\n                     if
      \''data\'' not in dataset:\n@@ -249,6 +251,31 @@ if __name__ == \''__main__\'':\n                     logging.info(\n                         f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n \n+            elif
      isSyntheticData:\n+                logging.info("\\nConfig Synthetic Data ")\n+\n+                nSyntheticSamples
      = metadata[\''datasets\''][dataset]["nSamples"]\n+                synthetic_config
      = metadata[\''datasets\''][dataset][year][config_runner[\''data_tier\'']]\n+                logging.info(f"\\nNumber
      of synthetic samples is {nSyntheticSamples}")\n+                for v in range(nSyntheticSamples):\n+\n+                    synthetic_name
      = f"syn_v{v}"\n+                    idataset = f\''{synthetic_name}_{year}\''\n+\n+                    metadata_dataset[idataset]
      = copy(metadata_dataset[dataset])\n+                    metadata_dataset[idataset][\''processName\'']
      = synthetic_name\n+                    # metadata_dataset[idataset][\''FvT_name\'']
      = synthetic_config[\''FvT_name_template\''].replace("XXX",str(v))\n+                    #
      metadata_dataset[idataset][\''FvT_file\''] = synthetic_config[\''FvT_file_template\''].replace("XXX",str(v))\n+                    synthetic_files
      = [f.replace("XXX",str(v)) for f in synthetic_config[\''files_template\'']]\n+                    fileset[idataset]
      = {\''files\'': list_of_files(synthetic_files,\n+                                                                test=args.test,
      test_files=config_runner[\''test_files\''],\n+                                                                allowlist_sites=config_runner[\''allowlist_sites\'']),\n+                                         \''metadata\'':
      metadata_dataset[idataset]}\n+\n+                    logging.info(\n+                        f\''\\nDataset
      {idataset} with {len(fileset[idataset]["files"])} files\'')\n+\n+\n             elif
      isDataForMix:\n                 logging.info("\\nConfig Data for Mixed ")\n
      \n'''
    hash: be7beff9ac9b123dfb8bdeb2581a74ef06734cdb
  saved_events: 58844
  source:
    root://cmseos.fnal.gov//store/user/algomez/XX4b/20231115/data2018D/picoAOD.root:
    - !!python/tuple
      - 0
      - 98676
    - !!python/tuple
      - 98676
      - 197352
    - !!python/tuple
      - 197352
      - 296028
    - !!python/tuple
      - 296028
      - 394704
    - !!python/tuple
      - 394704
      - 493380
    - !!python/tuple
      - 493380
      - 592056
    - !!python/tuple
      - 592056
      - 690732
    - !!python/tuple
      - 690732
      - 789408
    - !!python/tuple
      - 789408
      - 888084
    - !!python/tuple
      - 888084
      - 986760
    - !!python/tuple
      - 986760
      - 1085436
    - !!python/tuple
      - 1085436
      - 1184112
    - !!python/tuple
      - 1184112
      - 1282788
    - !!python/tuple
      - 1282788
      - 1381464
    - !!python/tuple
      - 1381464
      - 1480140
    - !!python/tuple
      - 1480140
      - 1578816
    - !!python/tuple
      - 1578816
      - 1677492
    - !!python/tuple
      - 1677492
      - 1776168
    - !!python/tuple
      - 1776168
      - 1874829
  total_events: 1874829
  total_jet: 357174
  xs:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0

analysis_container = "/cvmfs/unpacked.cern.ch/gitlab-registry.cern.ch/cms-cmu/coffea4bees:latest"
combine_container = "/cvmfs/unpacked.cern.ch/gitlab-registry.cern.ch/cms-analysis/general/combine-container:CMSSW_11_3_4-combine_v9.1.0-harvester_v2.1.0"

output_dir = "python/output"
outputs = []

output_code = [ 
  f"{output_dir}/analysis_helpers_job.log",
  f"{output_dir}/kappa_framework.log",
  f"{output_dir}/jet_clustering.log",
  f"{output_dir}/trig_emulator.log"
]
# outputs.extend(output_code)

output_skimmer = [
  f"{output_dir}/skimmer_basic_test_job.log",
  f"{output_dir}/skimmer_test_job/picoaod_datasets_GluGluToHHTo4B_cHHH0_UL18.yml",
  f"{output_dir}/skimmer_analysis_test_job/test_skimmer.coffea",
  f"{output_dir}/skimmer_analysis_cutflow_job/test_dump_skimmer_cutflow.yml"
]
outputs.extend(output_skimmer)

# outputs.append()

output_synthetic_dataset_make = [
  f"{output_dir}/synthetic_dataset_make_dataset/picoaod_datasets_declustered_test_UL18.yml",
  f"{output_dir}/synthetic_dataset_analyze/test_synthetic_datasets.coffea",
  f"{output_dir}/synthetic_dataset_analyze_cutflow/test_dump_cutflow_synthetic_datasets.yml"
]
# outputs.extend(output_synthetic_dataset_make_dataset)

output_synthetic_dataset_analyze = [
  f"{output_dir}/synthetic_dataset_cluster/test_synthetic_datasets.coffea",
  f"{output_dir}/synthetic_dataset_plot_job/jet-splitting-PDFs-test/clustering_pdfs_vs_pT_RunII.yml"
]
# outputs.extend(output_synthetic_dataset_analyze)


output_weights_trigger = [
  f"{output_dir}/weights_trigger_friendtree_job/trigger_weights_friends.json",
  f"{output_dir}/weights_trigger_friendtree_job/GluGluToHHTo4B_cHHH1_UL18/trigWeight.chunk2.root",
  f"{output_dir}/weights_trigger_analysis_job/test_trigWeight.coffea",
  f"{output_dir}/weights_trigger_cutflow_job/test_dump_cutflow_trigWeight.yml"
]
# outputs.extend(output_weights_trigger)


output_analysis = [
  f"{output_dir}/analysis_test_job/test.coffea",
  f"{output_dir}/analysis_makeweights_job/testJCM_ROOT/jetCombinatoricModel_SB_.yml",
  f"{output_dir}/analysis_plot_job/RunII/passPreSel/fourTag/SR/SvB_MA_ps_zz.pdf",
  f"{output_dir}/analysis_iplot_job.log",
  f"{output_dir}/baseclass_test_job/test_dumpPlotCounts.yml",
  f"{output_dir}/analysis_cutflow_job/test_dump_cutflow.yml",
]
# outputs.extend(output_analysis)

output_classifier_friendtree = [
  f"{output_dir}/classifier_friendtree_job/classifier_friendtree.yml"
]
# outputs.extend(output_classifier_friendtree)

output_topreco_friendtree = [
  f"{output_dir}/topreco_friendtree_job/top_reconstruction_friendtree.json"
]
# outputs.extend(output_topreco_friendtree)

output_unsup = [
  f"{output_dir}/analysis_test_job_unsup/test_unsup.coffea",
  f"{output_dir}/analysis_plot_job_unsup/RunII/passPreSel/fourTag/SR/mix_v0/v4j_mass.pdf",
  f"{output_dir}/analysis_cutflow_job_unsup/test_dump_cutflow_unsup.yml"
]
# outputs.extend(output_unsup)

output_mixeddata = [
  f"{output_dir}/analysis_test_mixed_job/testMixedData.json",
  f"{output_dir}/analysis_test_mixed_job/testMixedData.coffea",
  f"{output_dir}/analysis_runTwoStageClosure_ROOT/test_dump_twoStageClosureInputsCounts.yml",
  f"{output_dir}/analysis_mixed_cutflow_job/test_dump_MixedData.yml"
]
# outputs.extend(output_mixeddata)

output_systematics = [
  f"{output_dir}/analysis_systematics_test_job/test_systematics.coffea",
  f"{output_dir}/analysis_systematics_cutflow_job/test_dump_systematics_cutflow.yml"
]
# outputs.extend(output_systematics)


rule all:
    input: outputs


###### THIS IS WHERE THE RULES START ######

rule analysis_helpers_job:
    container: analysis_container
    log: f"{output_dir}/analysis_helpers_job.log"
    shell: "source .ci-workflows/analysis-helpers-job.sh"

rule kappa_framework:
    container: analysis_container
    log: f"{output_dir}/kappa_framework.log"
    shell: "source .ci-workflows/baseclass-kappa-framework.sh"

rule jet_clustering:
    container: analysis_container
    log: f"{output_dir}/jet_clustering.log"
    shell: "source .ci-workflows/jet-clustering-tests.sh"

rule trig_emulator:
    container: analysis_container
    log: f"{output_dir}/trig_emulator.log"
    shell: "source .ci-workflows/trig-emulator-tests.sh"

rule skimmer_test_job:
    container: analysis_container
    output:
      f"{output_dir}/skimmer_test_job/picoaod_datasets_GluGluToHHTo4B_cHHH0_UL18.yml"
    shell: "source .ci-workflows/skimmer-test-job.sh"

rule skimmer_basic_test_job:
    container: analysis_container
    log: f"{output_dir}/skimmer_basic_test_job.log"
    shell: "source .ci-workflows/skimmer-basic-test-job.sh"  

rule synthetic_dataset_make_dataset:
    container: analysis_container
    output:
      f"{output_dir}/synthetic_dataset_make_dataset/picoaod_datasets_declustered_test_UL18.yml",
    shell: "source .ci-workflows/synthetic-dataset-make-dataset.sh"


rule weights_trigger_friendtree_job:
    container: analysis_container
    output: 
      f"{output_dir}/weights_trigger_friendtree_job/trigger_weights_friends.json",
      f"{output_dir}/weights_trigger_friendtree_job/GluGluToHHTo4B_cHHH1_UL18/trigWeight.chunk2.root"
    shell: "source .ci-workflows/weights-trigger-friendtree-job.sh"

rule classifier_friendtree_job:
    container: analysis_container
    output: 
      f"{output_dir}/classifier_friendtree_job/classifier_friendtree.yml"
    shell: "source .ci-workflows/classifier-friendtree-job.sh"

rule topreco_friendtree_job:
    container: analysis_container
    output: 
      f"{output_dir}/topreco_friendtree_job/top_reconstruction_friendtree.json"
    shell: "source .ci-workflows/topreco-friendtree-job.sh"


rule analysis_test_job:
    output: 
        f"{output_dir}/analysis_test_job/test.coffea" 
    container: analysis_container
    shell: "source .ci-workflows/analysis-test-job.sh"


rule analysis_test_job_truthStudy:
    output: 
        f"{output_dir}/analysis_test_job_truthStudy/test_truthStudy.coffea" 
    container: analysis_container
    shell: "source .ci-workflows/analysis-test-job-truthStudy.sh"

rule synthetic_dataset_cluster:
    output: 
        f"{output_dir}/synthetic_dataset_cluster/test_synthetic_datasets.coffea" 
    container: analysis_container
    shell: "source .ci-workflows/synthetic-dataset-cluster.sh"


rule analysis_test_job_unsup:
    output: 
        f"{output_dir}/analysis_test_job_unsup/test_unsup.coffea" 
    container: analysis_container
    shell: "source .ci-workflows/analysis-test-job-unsup.sh"

rule analysis_test_mixed_job:
    output: 
        f"{output_dir}/analysis_test_mixed_job/testMixedData.json",
        f"{output_dir}/analysis_test_mixed_job/testMixedData.coffea"
    container: analysis_container
    shell: "source .ci-workflows/analysis-test-mixed-job.sh"

rule analysis_systematics_test_job:
    output: 
        f"{output_dir}/analysis_systematics_test_job/test_systematics.coffea" 
    container: analysis_container
    shell: "source .ci-workflows/analysis-systematics-test-job.sh"

rule skimmer_analysis_test_job:
    input: f"{output_dir}/skimmer_test_job/picoaod_datasets_GluGluToHHTo4B_cHHH0_UL18.yml"
    output: 
        f"{output_dir}/skimmer_analysis_test_job/test_skimmer.coffea"
    container: analysis_container
    shell: "source .ci-workflows/skimmer-analysis-test-job.sh"

rule synthetic_dataset_analyze:
    input:
        f"{output_dir}/synthetic_dataset_make_dataset/picoaod_datasets_declustered_test_UL18.yml"
    output: 
        f"{output_dir}/synthetic_dataset_analyze/test_synthetic_datasets.coffea" 
    container: analysis_container
    shell: "source .ci-workflows/synthetic-dataset-analyze.sh"

rule weights_trigger_analysis_job:
    input: 
        f"{output_dir}/weights_trigger_friendtree_job/trigger_weights_friends.json"
    output: 
        f"{output_dir}/weights_trigger_analysis_job/test_trigWeight.coffea"
    container: analysis_container
    shell: "source .ci-workflows/weights-trigger-analysis-job.sh"

rule analysis_makeweights_job:
    input: 
        f"{output_dir}/analysis_test_job/test.coffea"
    output: 
        f"{output_dir}/analysis_makeweights_job/testJCM_ROOT/jetCombinatoricModel_SB_.yml"
    container: analysis_container
    shell: "source .ci-workflows/analysis-makeweights-job.sh"

rule analysis_runTwoStageClosure_ROOT:
    input: 
        f"{output_dir}/analysis_test_mixed_job/testMixedData.json"
    output: 
        f"{output_dir}/analysis_runTwoStageClosure_ROOT/test_dump_twoStageClosureInputsCounts.yml"
    shell:
      """
      export APPTAINER_BINDPATH=/uscmst1b_scratch,/cvmfs,/cvmfs/grid.cern.ch/etc/grid-security/vomses:/etc/vomses,/cvmfs/grid.cern.ch/etc/grid-security:/etc/grid-security,/tmp
      export APPTAINER_CACHEDIR="/tmp/$(whoami)/apptainer_cache"
      export APPTAINER_TMPDIR="/tmp/.apptainer/"

      APPTAINER_SHELL=$(which bash) apptainer exec -B .:/home/cmsusr/coffea4bees \
      --pwd /home/cmsusr/coffea4bees/  \
      {combine_container} \
      /bin/bash -c "export LANG=C && export LC_ALL=C && \
       source /cvmfs/cms.cern.ch/cmsset_default.sh && 
       cd /home/cmsusr/CMSSW_11_3_4/ && \
       cmsenv && \
       cd - && \
       source .ci-workflows/analysis-runTwoStageClosure-ROOT.sh"
      """

rule analysis_plot_job:
    input: 
        f"{output_dir}/analysis_test_job/test.coffea"
    output: 
        f"{output_dir}/analysis_plot_job/RunII/passPreSel/fourTag/SR/SvB_MA_ps_zz.pdf"
    container: analysis_container
    shell: "source .ci-workflows/analysis-plot-job.sh"

rule analysis_plot_job_unsup:
    input: 
        f"{output_dir}/analysis_test_job_unsup/test_unsup.coffea"
    output: 
        f"{output_dir}/analysis_plot_job_unsup/RunII/passPreSel/fourTag/SR/mix_v0/v4j_mass.pdf"
    container: analysis_container
    shell: "source .ci-workflows/analysis-plot-job-unsup.sh"

rule analysis_iplot_job:
    input: 
        f"{output_dir}/analysis_test_job/test.coffea"
    log: f"{output_dir}/analysis_iplot_job.log"
    container: analysis_container
    shell: "source .ci-workflows/analysis-iplot-job.sh"

rule baseclass_test_job:
    input: 
        f"{output_dir}/analysis_test_job/test.coffea"
    output: f"{output_dir}/baseclass_test_job/test_dumpPlotCounts.yml"
    container: analysis_container
    shell: "source .ci-workflows/baseclass-test-job.sh"

rule synthetic_dataset_plot_job:
    input: 
        f"{output_dir}/synthetic_dataset_cluster/test_synthetic_datasets.coffea"
    output: f"{output_dir}/synthetic_dataset_plot_job/jet-splitting-PDFs-test/clustering_pdfs_vs_pT_RunII.yml"
    container: analysis_container
    shell: "source .ci-workflows/synthetic-dataset-plot-job.sh"


rule analysis_cutflow_job:    
    input: f"{output_dir}/analysis_test_job/test.coffea"
    output: 
        f"{output_dir}/analysis_cutflow_job/test_dump_cutflow.yml"
    container: analysis_container
    shell: "source .ci-workflows/analysis-cutflow-job.sh"

rule analysis_mixed_cutflow_job:    
    input: f"{output_dir}/analysis_test_mixed_job/testMixedData.coffea"
    output: 
        f"{output_dir}/analysis_mixed_cutflow_job/test_dump_MixedData.yml"
    container: analysis_container
    shell: "source .ci-workflows/analysis-mixed-cutflow-job.sh"

rule skimmer_analysis_cutflow_job:    
    input: f"{output_dir}/skimmer_analysis_test_job/test_skimmer.coffea"
    output: 
        f"{output_dir}/skimmer_analysis_cutflow_job/test_dump_skimmer_cutflow.yml"
    container: analysis_container
    shell: "source .ci-workflows/skimmer-analysis-cutflow-job.sh"

rule analysis_systematics_cutflow_job:    
    input: f"{output_dir}/analysis_systematics_test_job/test_systematics.coffea"
    output: 
        f"{output_dir}/analysis_systematics_cutflow_job/test_dump_systematics_cutflow.yml"
    container: analysis_container
    shell: "source .ci-workflows/analysis-systematics-cutflow-job.sh"

rule analysis_cutflow_job_unsup:    
    input: f"{output_dir}/analysis_test_job_unsup/test_unsup.coffea"
    output: 
        f"{output_dir}/analysis_cutflow_job_unsup/test_dump_cutflow_unsup.yml"
    container: analysis_container
    shell: "source .ci-workflows/analysis-cutflow-job-unsup.sh"

rule synthetic_dataset_analyze_cutflow:
    input: f"{output_dir}/synthetic_dataset_analyze/test_synthetic_datasets.coffea"
    output: 
        f"{output_dir}/synthetic_dataset_analyze_cutflow/test_dump_cutflow_synthetic_datasets.yml"
    container: analysis_container
    shell: "source .ci-workflows/synthetic-dataset-analyze-cutflow.sh"

rule weights_trigger_analysis_cutflow_job:
    input: f"{output_dir}/weights_trigger_analysis_job/test_trigWeight.coffea"
    output: 
        f"{output_dir}/weights_trigger_cutflow_job/test_dump_cutflow_trigWeight.yml"
    container: analysis_container
    shell: "source .ci-workflows/weights-trigger-cutflow-job.sh"
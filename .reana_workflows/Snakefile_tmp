from datetime import datetime

TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')

#
# rule all sets the entire workflow. This is were you define the last output of the workflow.
# Snakemake will go backawrds and check what rules does the workflow need to get the output.
#
rule all:
    input:
        expand("output/histdatabkgs_{sample}-{iy}.coffea", sample=config['dataset'], iy=config['year'])
#        expand("output/histsyst_{samplesyst}-{iysyst}.coffea", samplesyst=config['dataset_systematics'], iysyst=config['year']),
#        expand("output/histmixed_{samplemixed}-{iymixed}.coffea", samplemixed=config['dataset_mixed'], iymixed=config['year_mixed']),
#        'output/histAll.coffea',
#        "output/RunII/passPreSel/fourTag/SB/nPVs.pdf",
#        "output/datacards/hists_SvB.root"

rule analysis_databkgs:
    output:
        "output/histdatabkgs_{sample}-{iy}.coffea"
    container:
        "docker://gitlab-registry.cern.ch/cms-cmu/coffea4bees:latest"
    resources:
        voms_proxy=True,
        kerberos=True,
        compute_backend="kubernetes",
        kubernetes_memory_limit="9.5Gi"
    shell:
        """
cd python/ 
echo "Running {wildcards.sample} {wildcards.iy} - output ../{output}"
mprof run -C -o mprofile_{wildcards.sample}_{wildcards.iy}.dat python runner.py -d {wildcards.sample} -p analysis/processors/processor_HH4b.py -y {wildcards.iy} -o ../{output} -op ../output/ -m metadata/datasets_HH4b_cernbox.yml #--dask
mprof plot -o mprofile_{wildcards.sample}_{wildcards.iy}.png ../output/mprofile_{wildcards.sample}_{wildcards.iy}.dat
#cp /tmp/coffea4bees-dask-report-* ../output/coffea4bees-dask-report_{wildcards.sample}_{wildcards.iy}.html
        """

rule analysis_systematics:
    output:
        "output/histsyst_{samplesyst}-{iysyst}.coffea"
    container:
        "docker://gitlab-registry.cern.ch/cms-cmu/coffea4bees:latest"
    resources:
        voms_proxy=True,
        kerberos=True,
        compute_backend="kubernetes",
        kubernetes_memory_limit="8Gi"
    shell:
        """
cd python/ 
echo "Running {wildcards.samplesyst} {wildcards.iysyst} - output ../{output}"
python runner.py -d {wildcards.samplesyst} -p analysis/processors/processor_HH4b.py -y {wildcards.iysyst} -o ../{output} -op ../output/ -m metadata/datasets_HH4b_cernbox.yml -c analysis/metadata/HH4b_systematics.yml -t #--dask
#cp /tmp/coffea4bees-dask-report-* ../output/coffea4bees-dask-report_{wildcards.samplesyst}_{wildcards.iysyst}.html
        """

        
rule analysis_mixed:
    output:
        "output/histmixed_{samplemixed}-{iymixed}.coffea"
    container:
        "docker://gitlab-registry.cern.ch/cms-cmu/coffea4bees:latest"
    resources:
        voms_proxy=True,
        kerberos=True,
        compute_backend="kubernetes",
        kubernetes_memory_limit="8Gi"
    shell:
        """
cd python/ 
echo "Running {wildcards.samplemixed} {wildcards.iymixed}"
python runner.py -d {wildcards.samplemixed} -p analysis/processors/processor_HH4b.py -y {wildcards.iymixed} -o ../{output} -op ../output/ -m metadata/datasets_HH4b_cernbox.yml -c analysis/metadata/HH4b.yml -t #--dask
#cp /tmp/coffea4bees-dask-report-* ../output/coffea4bees-dask-report_{wildcards.samplemixed}_{wildcards.iymixed}.html
        """

rule merging_coffea_files_databkgs:
    input:
        files = expand(['output/histdatabkgs_{idat}-{iyear}.coffea'], idat=config['dataset'], iyear=config['year'])
    output:
        "output/hist_databkgs.coffea"
    container:
        "docker://gitlab-registry.cern.ch/cms-cmu/coffea4bees:latest"
    resources:
        kerberos=True,
        compute_backend="kubernetes",
        kubernetes_memory_limit="8Gi"
    shell:
        """
python python/analysis/merge_coffea_files.py -f {input.files} -o {output}
        """

rule merging_coffea_files_syst:
    input:
        files = expand(['output/histsyst_{idatsyst}-{iyear}.coffea'], idatsyst=config['dataset_systematics'], iyear=config['year'])
    output:
        "output/hist_syst.coffea"
    container:
        "docker://gitlab-registry.cern.ch/cms-cmu/coffea4bees:latest"
    resources:
        kerberos=True,
        compute_backend="kubernetes",
        kubernetes_memory_limit="8Gi"
    shell:
        """
python python/analysis/merge_coffea_files.py -f {input.files} -o {output}
        """

rule merging_coffea_files_mixed:
    input:
        files = expand(['output/histmixed_{idatmix}-{iyear}.coffea'], idatmix=config['dataset_mixed'], iyear=config['year_mixed'])
    output:
        "output/hist_mixed.coffea"
    container:
        "docker://gitlab-registry.cern.ch/cms-cmu/coffea4bees:latest"
    resources:
        kerberos=True,
        compute_backend="kubernetes",
        kubernetes_memory_limit="8Gi"
    shell:
        """
python python/analysis/merge_coffea_files.py -f {input.files} -o {output}
        """

rule merging_coffea_files:
    input:
        files = expand(['output/hist_{itype}.coffea'], itype=['databkgs', 'syst', 'mixed']),
    output:
        "output/histAll.coffea"
    container:
        "docker://gitlab-registry.cern.ch/cms-cmu/coffea4bees:latest"
    resources:
        kerberos=True,
        compute_backend="kubernetes",
        kubernetes_memory_limit="8Gi"
    shell:
        """
python python/analysis/merge_coffea_files.py -f {input.files} -o {output}
xrdcp output/histAll.coffea root://eosuser.cern.ch//eos/user/a/algomez/tmpFiles/XX4b/reana/{TIMESTAMP}/histAll.coffea
cp output/histAll.coffea /eos/user/a/algomez/tmpFiles/XX4b/reana/{TIMESTAMP}/histAll.coffea
        """

rule make_plots:
    input:
        "output/histAll.coffea"
    output:
        "output/RunII/passPreSel/fourTag/SB/nPVs.pdf"
    container:
        "docker://gitlab-registry.cern.ch/cms-cmu/coffea4bees:latest"
    resources:
        kerberos=True,
        compute_backend="kubernetes",
        kubernetes_memory_limit="8Gi"
    shell:
        """
cd python/ 
python analysis/makePlots.py ../output/histAll.coffea -o ../output/ -m analysis/metadata/plotsAll.yml
python .php-plots/bin/pb_deploy_plots.py ../output/RunII/ /eos/user/a/algomez/work/HH4b/reana/{TIMESTAMP}/ -r -c
        """
        
rule convert_hist_to_yml:
    input:
        "output/histAll.coffea"
    output:
        "output/histAll.yml"
    container:
        "docker://gitlab-registry.cern.ch/cms-cmu/coffea4bees:latest"
    resources:
        compute_backend="kubernetes",
        kubernetes_memory_limit="8Gi"
    shell:
        """
python python/stats_analysis/convert_hist_to_yaml.py -o {output} -i {input}
        """

rule convert_yml_to_hist:
    input:
        "output/histAll.yml"
    output:
        "output/datacards/hists_SvB.root"
    container:
        "gitlab-registry.cern.ch/cms-cloud/combine-standalone:v9.2.0"
    resources:
        compute_backend="kubernetes"
    shell:
        """
python python/stats_analysis/convert_yml_to_root.py --classifier SvB_MA SvB -f output/histAll.yml --merge2016 --output_dir output/datacards/ --plot --make_combine_inputs
        """

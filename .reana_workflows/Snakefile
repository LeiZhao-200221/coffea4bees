from datetime import datetime

TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')

#
# rule all sets the entire workflow. This is were you define the last output of the workflow.
# Snakemake will go backawrds and check what rules does the workflow need to get the output.
#
rule all:
    input:
        expand("output/histdatabkgs_{sample}-{iy}.coffea", sample=config['dataset'], iy=config['year']),
        expand("output/histsyst_{samplesyst}-{iysyst}.coffea", samplesyst=config['dataset_systematics'], iysyst=config['year']),
        expand("output/histmixed_{samplemixed}-{iymixed}.coffea", samplemixed=config['dataset_for_mixed'], iymixed=config['year']),
        expand("output/histmixeddata_{samplemixed}-{iymixed}.coffea", samplemixeddata=config['dataset_mixeddata'], iymixeddata=config['year_mixed']),
        'output/histAll_syst.coffea',
        'output/histAll_mixeddata.coffea',
        'output/histAll_for_mixed.coffea',
        "output/RunII/passPreSel/fourTag/SB/nPVs.pdf",
        "output/datacards/hists_SvB.root"

rule analysis_databkgs:
    output:
        "output/histdatabkgs_{sample}-{iy}.coffea"
    container:
        "docker://gitlab-registry.cern.ch/cms-cmu/coffea4bees:latest"
    resources:
        voms_proxy=True,
        kerberos=True,
        compute_backend="kubernetes",
        kubernetes_memory_limit="9.5Gi"
    shell:
        """
cd python/ 
echo "Running {wildcards.sample} {wildcards.iy} - output ../{output}"
mprof run -C -o mprofile_{wildcards.sample}_{wildcards.iy}.dat python runner.py -d {wildcards.sample} -p analysis/processors/processor_HH4b.py -y {wildcards.iy} -o ../{output} -op ../output/ -m metadata/datasets_HH4b_cernbox.yml #--dask
mprof plot -o ../output/mprofile_{wildcards.sample}_{wildcards.iy}.png mprofile_{wildcards.sample}_{wildcards.iy}.dat
#cp /tmp/coffea4bees-dask-report-* ../output/coffea4bees-dask-report_{wildcards.sample}_{wildcards.iy}.html
        """

rule analysis_systematics:
    output:
        "output/histsyst_{samplesyst}-{iysyst}.coffea"
    container:
        "docker://gitlab-registry.cern.ch/cms-cmu/coffea4bees:latest"
    resources:
        voms_proxy=True,
        kerberos=True,
        compute_backend="kubernetes",
        kubernetes_memory_limit="9.5Gi"
    shell:
        """
cd python/ 
echo "Running {wildcards.samplesyst} {wildcards.iysyst} - output ../{output}"
mprof run -C -o mprofile_{wildcards.samplesyst}_{wildcards.iysyst}.dat python runner.py -d {wildcards.samplesyst} -p analysis/processors/processor_HH4b.py -y {wildcards.iysyst} -o ../{output} -op ../output/ -m metadata/datasets_HH4b_cernbox.yml -c analysis/metadata/HH4b_systematics.yml #--dask
mprof plot -o ../output/mprofile_{wildcards.samplesyst}_{wildcards.iysyst}.png mprofile_{wildcards.samplesyst}_{wildcards.iysyst}.dat
#cp /tmp/coffea4bees-dask-report-* ../output/coffea4bees-dask-report_{wildcards.samplesyst}_{wildcards.iysyst}.html
        """

rule analysis_for_mixed:
    output:
        "output/histmixed_{samplemixed}-{iymixed}.coffea"
    container:
        "docker://gitlab-registry.cern.ch/cms-cmu/coffea4bees:latest"
    resources:
        voms_proxy=True,
        kerberos=True,
        compute_backend="kubernetes",
        kubernetes_memory_limit="9.5Gi"
    shell:
        """
cd python/ 
echo "Running {wildcards.samplemixed} {wildcards.iymixed}"
mprof run -C -o mprofile_{wildcards.samplemixed}_{wildcards.iymixed}.dat python runner.py -d {wildcards.samplemixed} -p analysis/processors/processor_HH4b.py -y {wildcards.iymixed} -o ../{output} -op ../output/ -m metadata/datasets_HH4b_cernbox.yml -c analysis/metadata/HH4b.yml #--dask
mprof plot -o ../output/mprofile_{wildcards.samplemixed}_{wildcards.iymixed}.png mprofile_{wildcards.samplemixed}_{wildcards.iymixed}.dat
#cp /tmp/coffea4bees-dask-report-* ../output/coffea4bees-dask-report_{wildcards.samplemixed}_{wildcards.iymixed}.html
        """

rule analysis_mixeddata:
    output:
        "output/histmixeddata_{samplemixeddata}-{iymixeddata}.coffea"
    container:
        "docker://gitlab-registry.cern.ch/cms-cmu/coffea4bees:latest"
    resources:
        voms_proxy=True,
        kerberos=True,
        compute_backend="kubernetes",
        kubernetes_memory_limit="9.5Gi"
    shell:
        """
cd python/ 
echo "Running {wildcards.samplemixeddata} {wildcards.iymixeddata}"
mprof run -C -o mprofile_{wildcards.samplemixeddata}_{wildcards.iymixeddata}.dat python runner.py -d {wildcards.samplemixeddata} -p analysis/processors/processor_HH4b.py -y {wildcards.iymixeddata} -o ../{output} -op ../output/ -m metadata/datasets_HH4b_cernbox.yml -c analysis/metadata/HH4b.yml #--dask
mprof plot -o ../output/mprofile_{wildcards.samplemixeddata}_{wildcards.iymixeddata}.png mprofile_{wildcards.samplemixeddata}_{wildcards.iymixeddata}.dat
#cp /tmp/coffea4bees-dask-report-* ../output/coffea4bees-dask-report_{wildcards.samplemixeddata}_{wildcards.iymixeddata}.html
        """

rule merging_coffea_files_databkgs:
    input:
        files = expand(['output/histdatabkgs_{idat}-{iyear}.coffea'], idat=config['dataset'], iyear=config['year'])
    output:
        "output/histAll.coffea"
    container:
        "docker://gitlab-registry.cern.ch/cms-cmu/coffea4bees:latest"
    resources:
        kerberos=True,
        compute_backend="kubernetes",
        kubernetes_memory_limit="8Gi"
    shell:
        """
mprof run -C -o python/mprofile_merge_databkgs.dat python python/analysis/merge_coffea_files.py -f {input.files} -o {output}
mprof plot -o output/mprofile_merge_databkgs.png python/mprofile_merge_databkgs.dat
xrdcp {output} root://eosuser.cern.ch//eos/user/a/algomez/tmpFiles/XX4b/reana/{TIMESTAMP}/histAll.coffea
cp {output} /eos/user/a/algomez/tmpFiles/XX4b/reana/{TIMESTAMP}/histAll.coffea
        """

rule merging_coffea_files_syst:
    input:
        files = expand(['output/histsyst_{idatsyst}-{iyear}.coffea'], idatsyst=config['dataset_systematics'], iyear=config['year'])
    output:
        "output/histAll_syst.coffea"
    container:
        "docker://gitlab-registry.cern.ch/cms-cmu/coffea4bees:latest"
    resources:
        kerberos=True,
        compute_backend="kubernetes",
        kubernetes_memory_limit="9.5Gi"
    shell:
        """
mprof run -C -o python/mprofile_merge_syst.dat python python/analysis/merge_coffea_files.py -f {input.files} -o {output}
mprof plot -o output/mprofile_merge_syst.png python/mprofile_merge_syst.dat
xrdcp {output} root://eosuser.cern.ch//eos/user/a/algomez/tmpFiles/XX4b/reana/{TIMESTAMP}/histAll_syst.coffea
cp {output} /eos/user/a/algomez/tmpFiles/XX4b/reana/{TIMESTAMP}/histAll_syst.coffea
        """

rule merging_coffea_files_mixeddata:
    input:
        files = expand(['output/histmixeddata_mixeddata-{iyear}.coffea'], iyear=config['year_mixed'])
    output:
        "output/histAll_mixeddata.coffea"
    container:
        "docker://gitlab-registry.cern.ch/cms-cmu/coffea4bees:latest"
    resources:
        kerberos=True,
        compute_backend="kubernetes",
        kubernetes_memory_limit="9.5Gi"
    shell:
        """
mprof run -C -o python/mprofile_merge_mixeddata.dat python python/analysis/merge_coffea_files.py -f {input.files} -o {output}
mprof plot -o output/mprofile_merge_mixeddata.png python/mprofile_merge_mixeddata.dat
xrdcp {output} root://eosuser.cern.ch//eos/user/a/algomez/tmpFiles/XX4b/reana/{TIMESTAMP}/histAll_mixeddata.coffea
cp {output} /eos/user/a/algomez/tmpFiles/XX4b/reana/{TIMESTAMP}/histAll_mixeddata.coffea
        """

rule merging_coffea_files_for_mixed:
    input:
        files = expand(['output/histmixed_{idatmix}-{iyear}.coffea'], idatmix=config['dataset_mixed'], iyear=config['year_mixed'])
    output:
        "output/histAll_for_mixed.coffea"
    container:
        "docker://gitlab-registry.cern.ch/cms-cmu/coffea4bees:latest"
    resources:
        kerberos=True,
        compute_backend="kubernetes",
        kubernetes_memory_limit="8Gi"
    shell:
        """
mprof run -C -o python/mprofile_merge_for_mixed.dat python python/analysis/merge_coffea_files.py -f {input.files} -o {output}
mprof plot -o output/mprofile_merge_for_mixed.png python/mprofile_merge_for_mixed.dat
xrdcp {output} root://eosuser.cern.ch//eos/user/a/algomez/tmpFiles/XX4b/reana/{TIMESTAMP}/histAll_for_mixed.coffea
cp {output} /eos/user/a/algomez/tmpFiles/XX4b/reana/{TIMESTAMP}/histAll_for_mixed.coffea
        """

rule make_plots:
    input:
        "output/histAll.coffea"
    output:
        "output/RunII/passPreSel/fourTag/SB/nPVs.pdf"
    container:
        "docker://gitlab-registry.cern.ch/cms-cmu/coffea4bees:latest"
    resources:
        kerberos=True,
        compute_backend="kubernetes",
        kubernetes_memory_limit="8Gi"
    shell:
        """
cd python/ 
mprof run -C -o mprofile_makeplots.dat python analysis/makePlots.py ../output/histAll.coffea -o ../output/ -m analysis/metadata/plotsAll.yml
mprof plot -o mprofile_makeplots.png ../output/mprofile_makeplots.dat
python .php-plots/bin/pb_deploy_plots.py ../output/RunII/ /eos/user/a/algomez/work/HH4b/reana/{TIMESTAMP}/ -r -c
        """
        
rule convert_hist_to_yml:
    input:
        "output/histAll.coffea"
    output:
        "output/histAll.yml"
    container:
        "docker://gitlab-registry.cern.ch/cms-cmu/coffea4bees:latest"
    resources:
        compute_backend="kubernetes",
        kubernetes_memory_limit="8Gi"
    shell:
        """
python python/stats_analysis/convert_hist_to_yaml.py -o {output} -i {input}
        """

rule convert_yml_to_hist:
    input:
        "output/histAll.yml"
    output:
        "output/datacards/hists_SvB.root"
    container:
        "gitlab-registry.cern.ch/cms-cloud/combine-standalone:v9.2.0"
    resources:
        compute_backend="kubernetes"
    shell:
        """
python python/stats_analysis/convert_yml_to_root.py --classifier SvB_MA SvB -f output/histAll.yml --merge2016 --output_dir output/datacards/ --plot --make_combine_inputs
        """
